{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "NLP_Automated_Ticket_Assignment_SVC_Ensembles_LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "D0O_n6OIEVyL",
        "outputId": "d4be9b1a-c5ac-40d1-cf1d-3f15a78567bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "I24x8-gwTfq4",
        "outputId": "ed287d34-9916-40fc-f99a-b2b41283f41e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "# changing present working directory\n",
        "import os\n",
        "import sys\n",
        "\n",
        "os.chdir(\"/content/drive/My Drive/Capstone_Project/\")\n",
        "sys.path.append('/content/drive/My Drive/Capstone_Project/') # Add DataPreprocessor.py directory path to sys.path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "sns.set(style=\"ticks\", color_codes=True)\n",
        "sns.set_palette(\"Spectral\")\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from pprint import pprint\n",
        "from sklearn import preprocessing \n",
        "import string \n",
        "import re\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')\n",
        "\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import BaggingClassifier, ExtraTreesClassifier, RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from mlxtend.classifier import EnsembleVoteClassifier\n",
        "from sklearn.metrics import (confusion_matrix, precision_recall_curve, auc,roc_curve, recall_score, classification_report, f1_score,precision_recall_fscore_support)\n",
        "\n",
        "# NLTK Stop words\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('words')\n",
        "words = set(nltk.corpus.words.words())\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')\n",
        "stop_words.extend(['received from', 'hi', 'hello','i','am','cc','sir','good', 'morning','afternoon','gentles','dear','kind','best','please','kindly','immediately','receive'])\n",
        "from nltk.tokenize import word_tokenize \n",
        "from nltk.stem import PorterStemmer \n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from gensim.utils import tokenize\n",
        "\n",
        "# import required keras libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer as TK\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout, Input, TimeDistributed,LSTM, Embedding, Dropout, Activation, Flatten, Bidirectional, GlobalMaxPool1D, SpatialDropout1D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-gE_xtSyeJeY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "25add543-430f-4744-d500-31ed428f289d"
      },
      "source": [
        "# Constants Declared\n",
        "EXCLUDE_CALLER = False      # True : Exclude caller details from model\n",
        "Frequency_Threshold = 50    # Minimum number of records for a category to be considered for Automated Ticket Classification\n",
        "seed = 100  # random_state\n",
        "Generate_Data_Synthetically = True # Downsample majority class and upsample minority classes to attain balance\n",
        "\n",
        "# Reading Dataset\n",
        "file_name = \"Ticket_Data.xlsx\" \n",
        "df = pd.read_excel(file_name,encoding='cp1252')\n",
        "df = df.rename(columns = {\"Short description\": \"Short_description\",\n",
        "                          \"Assignment group\": \"Group\"})\n",
        "df.head()"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Short_description</th>\n",
              "      <th>Description</th>\n",
              "      <th>Caller</th>\n",
              "      <th>Group</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>login issue</td>\n",
              "      <td>-verified user details.(employee# &amp; manager na...</td>\n",
              "      <td>spxjnwir pjlcoqds</td>\n",
              "      <td>GRP_0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>outlook</td>\n",
              "      <td>\\r\\n\\r\\nreceived from: hmjdrvpb.komuaywn@gmail...</td>\n",
              "      <td>hmjdrvpb komuaywn</td>\n",
              "      <td>GRP_0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cant log in to vpn</td>\n",
              "      <td>\\r\\n\\r\\nreceived from: eylqgodm.ybqkwiam@gmail...</td>\n",
              "      <td>eylqgodm ybqkwiam</td>\n",
              "      <td>GRP_0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>unable to access hr_tool page</td>\n",
              "      <td>unable to access hr_tool page</td>\n",
              "      <td>xbkucsvz gcpydteq</td>\n",
              "      <td>GRP_0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>skype error</td>\n",
              "      <td>skype error</td>\n",
              "      <td>owlgqjme qhcozdfx</td>\n",
              "      <td>GRP_0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Short_description  ...  Group\n",
              "0                    login issue  ...  GRP_0\n",
              "1                        outlook  ...  GRP_0\n",
              "2             cant log in to vpn  ...  GRP_0\n",
              "3  unable to access hr_tool page  ...  GRP_0\n",
              "4                   skype error   ...  GRP_0\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7XlXn4i1f_W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "2d7c07e3-425b-424a-b24b-27a233165bfe"
      },
      "source": [
        "# Checking Shape of the data\n",
        "print(\"Data shape:\", df.shape)\n",
        "print(\"\\nData Description:\", df.describe())\n",
        "\n",
        "# Drop duplicate rows\n",
        "df_v1 = df.drop_duplicates(keep='first')\n",
        "print(\"\\nData shape after removing duplicate records :\", df_v1.shape)\n",
        "\n",
        "# Impute missing values\n",
        "df_v1['Short_description'].fillna('the', inplace=True) # replacing null values with stopword 'the'\n",
        "df_v1['Description'].fillna('the', inplace=True) # replacing null values with stopword 'the'"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data shape: (8500, 4)\n",
            "\n",
            "Data Description:        Short_description Description             Caller  Group\n",
            "count               8492        8499               8500   8500\n",
            "unique              7481        7817               2950     74\n",
            "top       password reset         the  bpctwhsn kzqsbmtp  GRP_0\n",
            "freq                  38          56                810   3976\n",
            "\n",
            "Data shape after removing duplicate records : (8417, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o_HWFFeYFvKz",
        "outputId": "3dbf166f-22e1-42d0-cea2-84e50dfd40cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        }
      },
      "source": [
        "# Merge groups with ticket count less than threshold into a \"Manual\" category and exclude them for automation model\n",
        "count = df_v1['Group'].value_counts(ascending=True)\n",
        "idx = count[count.lt(Frequency_Threshold)].index\n",
        "df_v1.loc[df_v1['Group'].isin(idx), 'Group'] = 'GRP_Manual'\n",
        "\n",
        "df_v1 = df_v1[df_v1['Group']!='GRP_Manual'] #Excluding records with GRP_Manual\n",
        "print(\"Updated Unique Group Types\",df_v1['Group'].nunique())\n",
        "df_v1['Group'].value_counts(ascending=False)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updated Unique Group Types 24\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GRP_0     3934\n",
              "GRP_8      645\n",
              "GRP_24     285\n",
              "GRP_12     257\n",
              "GRP_9      252\n",
              "GRP_2      241\n",
              "GRP_19     215\n",
              "GRP_3      200\n",
              "GRP_6      183\n",
              "GRP_13     145\n",
              "GRP_10     140\n",
              "GRP_5      128\n",
              "GRP_14     118\n",
              "GRP_25     116\n",
              "GRP_33     107\n",
              "GRP_4      100\n",
              "GRP_29      97\n",
              "GRP_18      88\n",
              "GRP_16      85\n",
              "GRP_31      69\n",
              "GRP_17      68\n",
              "GRP_7       68\n",
              "GRP_34      62\n",
              "GRP_26      56\n",
              "Name: Group, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ae2wO8-LLqJc"
      },
      "source": [
        "## Text Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5Ng9eWDgja_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Module to clean data\n",
        "def text_preprocessing(df_column):\n",
        "    data = df_column.values.tolist() # Convert to list\n",
        "    temp=[]    \n",
        "    for sentence in data:\n",
        "        sentence = re.sub(r\"can't|cant|can not\", \"cannot\", sentence)\n",
        "        sentence = re.sub(r\"log in\", \"login\", sentence)\n",
        "        sentence = re.sub(r\"i'm|I'm\", \"i am\", sentence)\n",
        "        sentence = re.sub(r\"it's\", \"it is\", sentence)\n",
        "        sentence = re.sub(r\"he's\", \"he is\", sentence)\n",
        "        sentence = re.sub(r\"i've\", \"i have\", sentence)\n",
        "        sentence = re.sub(r\"won't\", \"will not\", sentence)\n",
        "        sentence = re.sub(r\"let's\", \"let us\", sentence)\n",
        "        sentence = re.sub(r\"couldn't\", \"could not\", sentence)\n",
        "        sentence = re.sub(r\"don't\", \"do not\", sentence)\n",
        "        sentence = re.sub(r\"isn't\", \"is not\", sentence)\n",
        "        sentence = re.sub(r\"wasn't\", \"was not\", sentence)\n",
        "        sentence = re.sub(r\"doesn't\", \"does not\", sentence)\n",
        "        sentence = re.sub(r\"didn't\", \"did not\", sentence)\n",
        "        sentence = sentence.replace(\"select the following link to view the disclaimer in an alternate language\", '')  # remove disclaimer text      \n",
        "        sentence = re.sub(r\"\\[(.*?)\\]\",\" \", sentence)  # remove text in []\n",
        "        sentence = re.sub(r\"\\((.*?)\\)\",\" \", sentence)  # remove text in ()\n",
        "        sentence = re.sub(r\"[[h][t][t][p][\\S]+|[w][w][w][\\S]+|[\\S]+[@][\\S]+\",\" \", sentence)  # remove email addresses, web address and urls\n",
        "        sentence = re.sub(r\"[\\S]+[\\d]+[\\S]+\",\" \", sentence) # remove alphanumerics and numerics (dates, time, request id etc.)\n",
        "        sentence = re.sub(r\"\\W(?<!['. ])\",\" \", sentence)  # remove all non words with negative look back except ('. spaces) \n",
        "        sentence = re.sub(r\"[^a-zA-z.| ]+\",\" \", sentence) # remove non-alphabetic text\n",
        "        sentence = re.sub(r\"[\\_]+\",\" \", sentence) # remove underscores\n",
        "        sentence = re.sub(r\"[\\s]+\",\" \", sentence) # replace multiple spaces with single space\n",
        "        sentence = sentence.strip('\\n')\n",
        "        temp.append(sentence)    \n",
        "    return(temp) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-S9ePXHfU7ie",
        "colab_type": "code",
        "outputId": "3ed4c008-54aa-4ad8-9d8d-0557a090718e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "# Cleaned both - 'Short_Description & Description'\n",
        "df_v1.Short_description = text_preprocessing(df_v1.Short_description)\n",
        "df_v1.Description = text_preprocessing(df_v1.Description)\n",
        "df_v2 = df_v1\n",
        "\n",
        "# Concatenating \"Short Description\" and \"Description\" to get \"Summary\" Tickets\n",
        "df_v2[\"Summary\"] = df_v2['Short_description'].str.cat(df_v2['Description'], sep = \". \")\n",
        "df_v2.head() "
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Short_description</th>\n",
              "      <th>Description</th>\n",
              "      <th>Caller</th>\n",
              "      <th>Group</th>\n",
              "      <th>Summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>login issue</td>\n",
              "      <td>verified user details. checked the user name ...</td>\n",
              "      <td>spxjnwir pjlcoqds</td>\n",
              "      <td>GRP_0</td>\n",
              "      <td>login issue.  verified user details. checked t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>outlook</td>\n",
              "      <td>received from hello team my meetings skype me...</td>\n",
              "      <td>hmjdrvpb komuaywn</td>\n",
              "      <td>GRP_0</td>\n",
              "      <td>outlook.  received from hello team my meetings...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cannot login to vpn</td>\n",
              "      <td>received from hi i cannot log on to vpn best</td>\n",
              "      <td>eylqgodm ybqkwiam</td>\n",
              "      <td>GRP_0</td>\n",
              "      <td>cannot login to vpn.  received from hi i canno...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>unable to access hr tool page</td>\n",
              "      <td>unable to access hr tool page</td>\n",
              "      <td>xbkucsvz gcpydteq</td>\n",
              "      <td>GRP_0</td>\n",
              "      <td>unable to access hr tool page. unable to acces...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>skype error</td>\n",
              "      <td>skype error</td>\n",
              "      <td>owlgqjme qhcozdfx</td>\n",
              "      <td>GRP_0</td>\n",
              "      <td>skype error . skype error</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Short_description  ...                                            Summary\n",
              "0                    login issue  ...  login issue.  verified user details. checked t...\n",
              "1                        outlook  ...  outlook.  received from hello team my meetings...\n",
              "2            cannot login to vpn  ...  cannot login to vpn.  received from hi i canno...\n",
              "3  unable to access hr tool page  ...  unable to access hr tool page. unable to acces...\n",
              "4                   skype error   ...                         skype error . skype error \n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZRLJdvIXP8Vh",
        "colab": {}
      },
      "source": [
        "# word tokenisation & removal of stop words & gibberish word(by typos, anonymised names)\n",
        "\n",
        "# Remove stopwords\n",
        "stop_word = ['received from', 'hi', 'hello','i','am','cc','sir','good', 'morning','afternoon','gentles','dear','kind','best','please','kindly','immediately','receive','the','at']\n",
        "df_v2['Summary'] = df_v2['Summary'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_word)]))\n",
        "\n",
        "# Remove words not in Englsih Dictionary (typos, anonymised names)\n",
        "df_v2['Summary'] = df_v2['Summary'].apply(lambda x: ' '.join([word for word in x.split() if word in (words)]))\n",
        "\n",
        "# Tokenise 'Summary' column\n",
        "data = df_v2.Summary.values.tolist()\n",
        "data = [list(tokenize(sentences)) for sentences in data]\n",
        "\n",
        "# Remove duplicates\n",
        "temp = []\n",
        "unique_words_per_row = []\n",
        "for eachrow in data:\n",
        "    unique_words_per_row = list(dict.fromkeys(eachrow))\n",
        "    temp.append(unique_words_per_row)\n",
        "data = temp\n",
        "\n",
        "# lemmetise words\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "temp = []\n",
        "for eachrow in data:\n",
        "    lemma_words = []\n",
        "    for eachword in eachrow:\n",
        "        if len(eachword) > 1: # ensure single alphabet are skipped from refined text\n",
        "          eachword = wordnet_lemmatizer.lemmatize(eachword, pos = \"n\")\n",
        "          eachword = wordnet_lemmatizer.lemmatize(eachword, pos = \"v\")\n",
        "          eachword = wordnet_lemmatizer.lemmatize(eachword, pos = \"a\")\n",
        "          eachword = wordnet_lemmatizer.lemmatize(eachword, pos = \"r\")\n",
        "          lemma_words.append(eachword)\n",
        "    if len(lemma_words) > 15:  \n",
        "      lemma_words = lemma_words[:15]    \n",
        "    temp.append(lemma_words) \n",
        "data = temp \n",
        "\n",
        "data = [(\" \".join(sentence))  for sentence in data]\n",
        "df_v2['Summary'] = data\n",
        "\n",
        "df_v2['Summary'] = df_v2['Summary'].str.partition('.')[0] # take first sentence from Summary\n",
        "df_v2.drop(df_v2[df_v2['Summary']==''].index, inplace=True) # drop rows with blank summary resulting from deletion of non-English text\n",
        "\n",
        "# If EXCLUDE_CALLER is set to False then add Caller information to Summary (usernames/ids).\n",
        "if not(EXCLUDE_CALLER):\n",
        "  df_v2['Caller'] =  df_v2['Caller'].apply(lambda x: x.replace(\" \", \"_\"))\n",
        "  df_v2[\"Summary\"] = df_v2['Summary'].str.cat(df_v2['Caller'], sep = \". \")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckbgmRymlAax",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Label Encoding Classes    \n",
        "le = preprocessing.LabelEncoder() \n",
        "df_v2['Group']= le.fit_transform(df_v2['Group']) # LabelEncode 'Groups'\n",
        "\n",
        "# Creating Dataframe to save results for each model \n",
        "result_df = pd.DataFrame(columns=['Model', 'Test_Accuracy'])\n",
        "result_df['Model']=['SVM','Bagging_Ensemble','Boosting_Ensemble','LSTM']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZWi7rkf45Qb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "maxlen = 0\n",
        "for sentence in data: # get length of longest ticket description\n",
        "    if (maxlen < sentence.count(' ')+1 ):\n",
        "        maxlen = sentence.count(' ')+1\n",
        "\n",
        "# Creating TFIDF Word Embeddings\n",
        "tfidf_vectors = TfidfVectorizer(min_df=3,max_features= maxlen)\n",
        "tfidf_db = tfidf_vectors.fit_transform(df_v2['Summary']).toarray()\n",
        "tfidf_db = pd.DataFrame(tfidf_db)\n",
        "\n",
        "X = tfidf_db\n",
        "y = df_v2['Group']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.40, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rykqIfv5U33",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "584e45e1-055a-4623-d61e-fe8b713ac408"
      },
      "source": [
        "#SVM Model - Linear Kernel, C=10\n",
        "\n",
        "svm_model = SVC(kernel='linear',C=10)\n",
        "svm_model.fit(X_train, y_train)\n",
        "y_pred = svm_model.predict(X_test)\n",
        "print(\"SVM RESULTS ------>\")\n",
        "print(\"Training Accuracy: {0:.2f}\".format(svm_model.score(X_train, y_train)))\n",
        "test_accuracy = round(svm_model.score(X_test, y_test),2)\n",
        "print(\"Test Accuracy: {0:.2f}\".format(test_accuracy))\n",
        "\n",
        "# Update model results in result dataframe\n",
        "loc = result_df[result_df['Model']=='SVM'].index\n",
        "result_df['Test_Accuracy'][loc] = test_accuracy"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVM RESULTS ------>\n",
            "Training Accuracy: 0.60\n",
            "Test Accuracy: 0.60\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UY665jg7TIF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "3da7ddd3-1dfc-4985-802c-2140f4424b25"
      },
      "source": [
        "# Bagging Ensemble for Classifying tickets\n",
        "rf = RandomForestClassifier()\n",
        "et = ExtraTreesClassifier()\n",
        "knn = KNeighborsClassifier()\n",
        "svc = SVC()\n",
        "rg = RidgeClassifier()\n",
        "clf_array = [rf, et, knn, svc, rg]\n",
        "\n",
        "for clf in clf_array:\n",
        "    bagging_clf = BaggingClassifier(clf, max_samples=0.4, max_features=10, random_state=seed)\n",
        "    bagging_scores = cross_val_score(bagging_clf, X_train, y_train, cv=10, n_jobs=-1)\n",
        "    \n",
        "    test_accuracy = round(bagging_scores.mean(),2)\n",
        "    print (\"Mean of: {1:.3f} [Bagging {0}]\\n\".format(clf.__class__.__name__,test_accuracy))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean of: 0.600 [Bagging RandomForestClassifier]\n",
            "\n",
            "Mean of: 0.590 [Bagging ExtraTreesClassifier]\n",
            "\n",
            "Mean of: 0.600 [Bagging KNeighborsClassifier]\n",
            "\n",
            "Mean of: 0.590 [Bagging SVC]\n",
            "\n",
            "Mean of: 0.570 [Bagging RidgeClassifier]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ui8Kwa9c9S8T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "25151ee6-1ba9-4904-9398-21844f2fa674"
      },
      "source": [
        "# Ensemble of Bagging Classifiers\n",
        "clf = [rf, et, knn, svc, rg]\n",
        "eclf = VotingClassifier(estimators=[('Random Forests', rf), ('Extra Trees', et), ('KNeighbors', knn), ('SVC', svc), \n",
        "                                    ('Ridge Classifier', rg)], voting='hard')\n",
        "for clf, label in zip([rf, et, knn, svc, rg, eclf], ['Random Forest', 'Extra Trees', 'KNeighbors', 'SVC', \n",
        "                                                     'Ridge Classifier', 'Ensemble']):\n",
        "    scores = cross_val_score(clf, X_train, y_train, cv=10, scoring='accuracy')\n",
        "    test_accuracy = round(scores.mean(),2)\n",
        "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (test_accuracy, scores.std(), label))\n",
        "\n",
        "# Update model results in result dataframe\n",
        "loc = result_df[result_df['Model']=='Bagging_Ensemble'].index\n",
        "result_df['Test_Accuracy'][loc] = test_accuracy"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.58 (+/- 0.01) [Random Forest]\n",
            "Accuracy: 0.59 (+/- 0.01) [Extra Trees]\n",
            "Accuracy: 0.58 (+/- 0.02) [KNeighbors]\n",
            "Accuracy: 0.60 (+/- 0.01) [SVC]\n",
            "Accuracy: 0.58 (+/- 0.01) [Ridge Classifier]\n",
            "Accuracy: 0.60 (+/- 0.01) [Ensemble]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6sXziCh-Us6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "2ef26436-621e-45cb-c1c3-198dddf4bf59"
      },
      "source": [
        "# Ensemble of Boosting Classifiers\n",
        "ada_boost = AdaBoostClassifier()\n",
        "grad_boost = GradientBoostingClassifier()\n",
        "xgb_boost = XGBClassifier()\n",
        "\n",
        "boost_array = [ada_boost, grad_boost, xgb_boost]\n",
        "eclf = EnsembleVoteClassifier(clfs=[ada_boost, grad_boost, xgb_boost], voting='hard')\n",
        "labels = ['Ada Boost', 'Grad Boost', 'XG Boost', 'Ensemble']\n",
        "for clf, label in zip([ada_boost, grad_boost, xgb_boost, eclf], labels):\n",
        "    scores = cross_val_score(clf, X_train, y_train, cv=10, scoring='accuracy')\n",
        "    test_accuracy = round(scores.mean(),2)\n",
        "    print(\"Mean: {0:.2f} of [{1}]\".format(test_accuracy, label))\n",
        "\n",
        "# Update model results in result dataframe\n",
        "loc = result_df[result_df['Model']=='Boosting_Ensemble'].index\n",
        "result_df['Test_Accuracy'][loc] = test_accuracy"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean: 0.430 of [Ada Boost]\n",
            "Mean: 0.580 of [Grad Boost]\n",
            "Mean: 0.610 of [XG Boost]\n",
            "Mean: 0.600 of [Ensemble]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kuatf--zIZnb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Balancing Classes\n",
        "if Generate_Data_Synthetically:\n",
        "  df_maj = df_v2[df_v2.Group == 0]\n",
        "  df_maj = df_maj.sample(n=1000, random_state=seed) \n",
        "  df_new = pd.concat([df_v2[df_v2.Group != 0],df_maj])\n",
        "\n",
        "  X = np.array(df_new.Summary).reshape(-1, 1)\n",
        "  y = np.array(df_new.Group).reshape(-1, 1)\n",
        "\n",
        "  oversample = RandomOverSampler()\n",
        "  X_over, y_over = oversample.fit_sample(X, y)\n",
        "  X_over = X_over.ravel()\n",
        "  y_over = y_over.ravel()\n",
        "  df_temp = pd.DataFrame({'Summary':X_over, 'Group':y_over})\n",
        "  df_v2 = df_temp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgGY0PIh7MVm",
        "colab_type": "code",
        "outputId": "389d5445-3c62-4ba7-a31e-b712f5108145",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "# Parameters\n",
        "maxlen = df_v2['Summary'].str.split().str.len().max()\n",
        "print(\"Maxlen:\", maxlen)\n",
        "embedding_size = 100\n",
        "\n",
        "# Create tokens\n",
        "tokenizer = TK(num_words= vocabulary_size, filters='')\n",
        "X = tokenizer.fit_on_texts(df_v2['Summary'])\n",
        "X = tokenizer.texts_to_sequences(df_v2['Summary'])\n",
        "X = pad_sequences(X, maxlen= maxlen, padding='post') \n",
        "y = np.asarray(df_v2['Group'])\n",
        "token_size = len(tokenizer.word_index)+1\n",
        "vocabulary_size = token_size\n",
        "\n",
        "print(\"Shape of features:\", X.shape)\n",
        "print(\"Shape of label:\", y.shape)\n",
        "print(\"Word index:\", tokenizer.word_index)\n",
        "print(\"Vocab Size:\", token_size)\n",
        "\n",
        "# Split train and test data\n",
        "X_train,X_test, y_train, y_test =  train_test_split(X, y,test_size =0.20,random_state= 4, stratify=y)\n",
        "print(\"\\nSplit train and test data\")\n",
        "print(\"Training data size:\", X_train.shape[0])\n",
        "print(\"Test data size:\",     X_test.shape[0])"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Maxlen: 16\n",
            "Shape of features: (24000, 16)\n",
            "Shape of label: (24000,)\n",
            "Word index: {'to': 1, 'be': 2, 'in': 3, 'receive': 4, 'from': 5, 'for': 6, 'not': 7, 'job': 8, 'from.': 9, 'and': 10, 'bpctwhsn_kzqsbmtp': 11, 'on': 12, 'of': 13, 'it': 14, 'need': 15, 'tool': 16, 'access': 17, 'password': 18, 'with': 19, 'reset': 20, 'we': 21, 'have': 22, 'this': 23, 'unable': 24, 'user': 25, 'cannot': 26, 'help': 27, 'send': 28, 'you': 29, 'management': 30, 'error': 31, 'issue': 32, 'when': 33, 'get': 34, 'my': 35, 'team': 36, 'tool.': 37, 'work': 38, 'a': 39, 'system': 40, 'but': 41, 'no': 42, 'down': 43, 'company': 44, 'that': 45, 'can': 46, 'wa': 47, 'all': 48, 'since': 49, 'an': 50, 'name': 51, 'subject': 52, 'telephony': 53, 'see': 54, 'do': 55, 'collaboration': 56, 'server': 57, 'be.': 58, 'create': 59, 'new': 60, 'below': 61, 'try': 62, 'order': 63, 'check': 64, 'engineer': 65, 'customer': 66, 'zkbogxib_qsejzdzo': 67, 'network': 68, 'me': 69, 'platform': 70, 'to.': 71, 'delivery': 72, 'number': 73, 'or': 74, 'will': 75, 'there': 76, 'doe': 77, 'site': 78, 'up': 79, 'follow': 80, 'account': 81, 'message': 82, 'on.': 83, 'print': 84, 'request': 85, 'able': 86, 'change': 87, 'type': 88, 'provide': 89, 'out': 90, 'run': 91, 'in.': 92, 'could': 93, 'time': 94, 'folder': 95, 'open': 96, 'what': 97, 're': 98, 'outage': 99, 'outlook': 100, 'add': 101, 'id': 102, 'problem': 103, 'show': 104, 'phone': 105, 'our': 106, 'power': 107, 'attach': 108, 'update': 109, 'connect': 110, 'printer': 111, 'for.': 112, 'find': 113, 'login': 114, 'location': 115, 'material': 116, 'call': 117, 'which': 118, 'computer': 119, 'circuit': 120, 'now': 121, 'summary': 122, 'would': 123, 'service': 124, 'any': 125, 'go': 126, 'language': 127, 'enter': 128, 'process': 129, 'contact': 130, 'if': 131, 'and.': 132, 'employee': 133, 'by': 134, 'na': 135, 'payroll': 136, 'security': 137, 'die': 138, 'data': 139, 'of.': 140, 'status': 141, 'august': 142, 'screen': 143, 'connection': 144, 'he': 145, 'this.': 146, 'new.': 147, 'ticket': 148, 'other': 149, 'explorer': 150, 'ship': 151, 'mail': 152, 'drive': 153, 'log': 154, 'one': 155, 'after': 156, 'make': 157, 'rkupnshb_gsmzfojw': 158, 'note': 159, 'due': 160, 'urgent': 161, 'plant': 162, 'into': 163, 'browser': 164, 'oldrctiu_bxurpsyi': 165, 'remove': 166, 'link': 167, 'your': 168, 'application': 169, 'use': 170, 'office': 171, 'production': 172, 'set': 173, 'setup': 174, 'manager': 175, 'install': 176, 'code': 177, 'dell': 178, 'full': 179, 'item': 180, 'file': 181, 'same': 182, 'telephone': 183, 'da': 184, 'with.': 185, 'top': 186, 'jyoqwxhz_clhxsoqy': 187, 'warehouse': 188, 'also': 189, 'report': 190, 'come': 191, 'jloygrwh_acvztedi': 192, 'not.': 193, 'interface': 194, 'while': 195, 'multiple': 196, 'support': 197, 'miss': 198, 'some': 199, 'device': 200, 'ist': 201, 'so': 202, 'under': 203, 'business': 204, 'work.': 205, 'disk': 206, 'through': 207, 'very': 208, 'ich': 209, 'address': 210, 'long': 211, 'they': 212, 'spxqmiry_zpwgoqju': 213, 'monitor': 214, 'why': 215, 'it.': 216, 'internal': 217, 'post': 218, 'possible': 219, 'look': 220, 'wrong': 221, 'only': 222, 'stock': 223, 'still': 224, 'start': 225, 'lock': 226, 'po': 227, 'like': 228, 'have.': 229, 'check.': 230, 'information': 231, 'switch': 232, 'field': 233, 'help.': 234, 'last': 235, 'den': 236, 'write': 237, 'complete': 238, 'confirm': 239, 'when.': 240, 'issue.': 241, 'dkmcfreg_anwmfvlg': 242, 'again': 243, 'available': 244, 'space': 245, 'high': 246, 'address.': 247, 'phone.': 248, 'outlook.': 249, 'group': 250, 'list': 251, 'backup': 252, 'several': 253, 'slow': 254, 'display': 255, 'over': 256, 'generate': 257, 'give': 258, 'read': 259, 'two': 260, 'warn': 261, 'notification': 262, 'via': 263, 'transaction': 264, 'just': 265, 'his': 266, 'source': 267, 'should': 268, 'price': 269, 'search': 270, 'line': 271, 'today': 272, 'back': 273, 'delete': 274, 'total': 275, 'both': 276, 'return': 277, 'id.': 278, 'hard': 279, 'bill': 280, 'close': 281, 'review': 282, 'ben': 283, 'a.': 284, 'system.': 285, 'shop': 286, 'error.': 287, 'tax': 288, 'page': 289, 'contact.': 290, 'where': 291, 'per': 292, 'day': 293, 'finance': 294, 'gzhapcld_fdigznbk': 295, 'date': 296, 'view': 297, 'volume': 298, 'center': 299, 'more': 300, 'client': 301, 'cannot.': 302, 'message.': 303, 'unlock': 304, 'tablet': 305, 'save': 306, 'pick': 307, 'during': 308, 'advise': 309, 'en.': 310, 'we.': 311, 'fdmaluyo_tvecikxn': 312, 'fix': 313, 'interaction': 314, 'but.': 315, 'effective': 316, 'down.': 317, 'let': 318, 'know': 319, 'already': 320, 'desk': 321, 'global': 322, 'than': 323, 'block': 324, 'meet': 325, 'free': 326, 'mnlazfsr_mtqrkhnx': 327, 'automatically': 328, 'cost': 329, 'load': 330, 'since.': 331, 'profile': 332, 'afkstcev_utbnkyop': 333, 'external': 334, 'extend': 335, 'face': 336, 'correct': 337, 'traffic': 338, 'assist': 339, 'these': 340, 'vendor': 341, 'even': 342, 'refer': 343, 'assign': 344, 'company.': 345, 'resolve': 346, 'event': 347, 'approval': 348, 'wktesmbp_lorjymef': 349, 'e': 350, 'supply': 351, 'see.': 352, 'every': 353, 'transfer': 354, 'top.': 355, 'no.': 356, 'rhinvtua_aquyjfbs': 357, 'sync': 358, 'leave': 359, 'action': 360, 'node': 361, 'termination': 362, 'bank': 363, 'want': 364, 'south': 365, 'rxoynvgi_ntgdsehl': 366, 'take': 367, 'u': 368, 'currently': 369, 'purchase': 370, 'batch': 371, 'um': 372, 'forward': 373, 'because': 374, 'bad': 375, 'tqfnalpj_qyoscnge': 376, 'user.': 377, 'quality': 378, 'nach': 379, 'share': 380, 'find.': 381, 'who': 382, 'then': 383, 'project': 384, 'repeat': 385, 'station': 386, 'response': 387, 'form': 388, 'one.': 389, 'alert': 390, 'ie.': 391, 'about': 392, 'authentication': 393, 'my.': 394, 'copy': 395, 'kbnfxpsy_gehxzayq': 396, 'approve': 397, 'customer.': 398, 'off': 399, 'name.': 400, 'me.': 401, 'she': 402, 'available.': 403, 'jionmpsf_wnkpzcmv': 404, 'old': 405, 'good': 406, 'hear': 407, 'output': 408, 'support.': 409, 'attach.': 410, 'expense': 411, 'average': 412, 'partner': 413, 'vzqomdgt_jwoqbuml': 414, 'rad': 415, 'local': 416, 'able.': 417, 'shipment': 418, 'ad': 419, 'how': 420, 'someone': 421, 'uvrbhlnt_bjrmalzi': 422, 'vbwszcqn_nlbqsuyv': 423, 'number.': 424, 'recently': 425, 'model': 426, 'click': 427, 'point': 428, 'outbound': 429, 'certificate': 430, 'an.': 431, 'login.': 432, 'lose': 433, 'stop': 434, 'german': 435, 'floor': 436, 'between': 437, 'txkgmwbc_qohmgwrp': 438, 'domain': 439, 'product': 440, 'personal': 441, 'wa.': 442, 'aw': 443, 'failure': 444, 'request.': 445, 'next': 446, 'owner': 447, 'threshold': 448, 'quote': 449, 'machine': 450, 'option': 451, 'financial': 452, 'wireless': 453, 'below.': 454, 'room': 455, 'reference': 456, 'get.': 457, 'urgent.': 458, 'need.': 459, 'de': 460, 'configure': 461, 'recall': 462, 'summary.': 463, 'sure': 464, 'you.': 465, 'link.': 466, 'portal': 467, 'turn': 468, 'en': 469, 'server.': 470, 'forget': 471, 'payment': 472, 'aofextgk_tugywidl': 473, 'restart': 474, 'gjtyswkb_dpvaymxr': 475, 'requisition': 476, 'raise': 477, 'printer.': 478, 'account.': 479, 'her': 480, 'active': 481, 'primary': 482, 'xwirzvda_okhyipgr': 483, 'boot': 484, 'person': 485, 'performance': 486, 'install.': 487, 'die.': 488, 'port': 489, 'relate': 490, 'lot': 491, 'do.': 492, 'reset.': 493, 'home': 494, 'lock.': 495, 'investigate': 496, 'excel': 497, 'incident': 498, 'route': 499, 'audio': 500, 'wir': 501, 'ist.': 502, 'attachment': 503, 'reason': 504, 'sie': 505, 'telephony.': 506, 'all.': 507, 'put': 508, 'um.': 509, 'shoot': 510, 'battery': 511, 'yesterday': 512, 'rout': 513, 'many': 514, 'daily': 515, 'ce.': 516, 'another': 517, 'whenever': 518, 'web': 519, 'document': 520, 'select': 521, 'pwksivmq_dbxajims': 522, 'da.': 523, 'zcdirjeq_azokfsdi': 524, 'sender': 525, 'therefore': 526, 'prod': 527, 'any.': 528, 'charge': 529, 'monthly': 530, 'little': 531, 'per.': 532, 'first': 533, 'hub': 534, 'week': 535, 'however': 536, 'recipient': 537, 'ytzpxhql_ntfxgpms': 538, 'mac': 539, 'bwfhtumx_japznrvb': 540, 'seit': 541, 'scanner': 542, 'quantity': 543, 'refresh': 544, 'yes': 545, 'their': 546, 'too': 547, 'text': 548, 'well': 549, 'amount': 550, 'plant.': 551, 'up.': 552, 'scan': 553, 'bozdftwx_smylqejw': 554, 'ovhtgsxd_dcqhnrmy': 555, 'latitude': 556, 'kaguhxwo_uoyipxqg': 557, 'network.': 558, 'license': 559, 'always': 560, 'credit': 561, 'tag': 562, 'material.': 563, 'gkwcxzum_answkqpe': 564, 'above': 565, 'before': 566, 'dizquolf_hlykecxa': 567, 'critical': 568, 'wird': 569, 'base': 570, 'team.': 571, 'activity': 572, 'size.': 573, 'that.': 574, 'end': 575, 'net': 576, 'password.': 577, 'doe.': 578, 'antivirus': 579, 'value': 580, 'follow.': 581, 'vfrdxtqw_jfbmsenz': 582, 'attachment.': 583, 'router': 584, 'fen.': 585, 'something': 586, 'light': 587, 'adobe': 588, 'welcome': 589, 'sometimes': 590, 'destination': 591, 'qcehailo_wqynckxg': 592, 'iavozegx_jpcudyfi': 593, 'connect.': 594, 'input': 595, 'few': 596, 'incorrect': 597, 'assistance': 598, 'tige': 599, 'notice': 600, 'ie': 601, 'move': 602, 'caller': 603, 'can.': 604, 'communication': 605, 'control': 606, 'balance': 607, 'also.': 608, 'yet': 609, 'note.': 610, 'lan': 611, 'xszoedmc_gmhkdsnw': 612, 'manager.': 613, 'ugyothfz_ugrmkdhx': 614, 'amar': 615, 'release': 616, 'insert': 617, 'right': 618, 'upgrade': 619, 'conference': 620, 'reverse': 621, 'blank': 622, 'each': 623, 'engineer.': 624, 'yevirgnl_ylhogjct': 625, 'overview': 626, 'lwgytuxq_qspdztiw': 627, 'remote': 628, 'replacement': 629, 'izwtdnfq_xptuoaid': 630, 'instead': 631, 'permission': 632, 'chain': 633, 'agent': 634, 'iwazgesl_ydgqtpbo': 635, 'keep': 636, 'status.': 637, 'button': 638, 'cisco': 639, 'bin': 640, 'or.': 641, 'screen.': 642, 'update.': 643, 'facility': 644, 'task': 645, 'uxgrdjfc_kqxdjeov': 646, 'utyeofsk_rdyzpwhi': 647, 'requester': 648, 'nuhfwplj_ojcwxser': 649, 'them': 650, 'vthuzanc_fqdgotvx': 651, 'title': 652, 'condition': 653, 'once': 654, 'submit': 655, 'lose.': 656, 'vwpxjtof_vmidzswj': 657, 'enable': 658, 'calendar': 659, 'rozsyfai_zncajubh': 660, 'setup.': 661, 'describe.': 662, 'description.': 663, 'arrange': 664, 'khvzugxm_yqfrcjwl': 665, 'monitor.': 666, 'yfmaqovp_wdonhbez': 667, 'label': 668, 'component': 669, 'ughzilfm_cfibdamq': 670, 'ticqvhal_vgokzesi': 671, 'within': 672, 'platform.': 673, 'mail.': 674, 'xqoljzbh_aydcwkxt': 675, 'infection': 676, 'wckrxovs_aunsgzmd': 677, 'creation': 678, 'hat': 679, 'reply': 680, 'example': 681, 'audit': 682, 'tjlgzkbp_iervwjzg': 683, 'method': 684, 'additional': 685, 'ihfkwzjd_erbxoyqk': 686, 'go.': 687, 'xkmvpaei_fizqoprk': 688, 'travel': 689, 'xsjqhdgp_ymstzudl': 690, 'mill': 691, 'fi': 692, 'fumkcsji_sarmtlhy': 693, 'our.': 694, 'template': 695, 'qgopxabz_xnuieqjr': 696, 'utilization': 697, 'gvxfymjk_euioadyf': 698, 'choose': 699, 'qidgvtwa_qvbutayx': 700, 'very.': 701, 'site.': 702, 'part': 703, 'analysis': 704, 'previous': 705, 'hybiaxlk_lawptzir': 706, 'format': 707, 'hardware': 708, 'host': 709, 'ikerxqwz_prkyuitl': 710, 'allow': 711, 'remove.': 712, 'inform': 713, 'xnqzhtwu_hivumtfz': 714, 'step': 715, 'train': 716, 'trouble': 717, 'slow.': 718, 'delegation': 719, 'quarantine': 720, 'ensure': 721, 'twice': 722, 'application.': 723, 'kiqrvwat_gwkpxzyt': 724, 'lwbchnga_axpqctfr': 725, 'controller.': 726, 'observe': 727, 'onto': 728, 'ben.': 729, 'area': 730, 'terminate': 731, 'solution': 732, 'paper': 733, 'state': 734, 'miro': 735, 'atlwdyej_vtlhzbix': 736, 'service.': 737, 'revenue': 738, 'lanigpkq_qzhakunx': 739, 'consignment': 740, 'lzspyjki_smdbqnef': 741, 'sinkhole': 742, 'zxopwyak_zrbfkimx': 743, 'st': 744, 'will.': 745, 'zmkitbsh_bxsyaipz': 746, 'qasdhyzm_yuglsrwx': 747, 'unit': 748, 'computer.': 749, 'reminder': 750, 'ntsowaem_jfgslyde': 751, 'azxhejvq_fyemlavd': 752, 'interaction.': 753, 'confirmation': 754, 'vkezwolt_fgnqzeai': 755, 'intercompany': 756, 'pjxclyhs_fcniljtu': 757, 'zmgsfner_caltmgoe': 758, 'production.': 759, 'description': 760, 'tckyrinp_vbzqslco': 761, 'ad.': 762, 'ckitashy_dnqojbwi': 763, 'juaxnvwz_reampilj': 764, 'memo': 765, 'sign': 766, 'lan.': 767, 'reach': 768, 'nemzycxb_xpsgkahw': 769, 'fohvgnkd_stfmcapj': 770, 'key': 771, 'access.': 772, 'correctly': 773, 'north': 774, 'ipwjorsc_uboapexr': 775, 'some.': 776, 'assignment': 777, 'sholvcmf_bjtpomrl': 778, 'ayrhcfxi_zartupsw': 779, 'fmjeaoih_ndyezlkb': 780, 'unlock.': 781, 'current': 782, 'what.': 783, 'temperature': 784, 'uisewznr_ewtmkphs': 785, 'office.': 786, 'different': 787, 'driver': 788, 'frzjtmyk_wzacvhki': 789, 'wgothrzl_iokdftgn': 790, 'seem': 791, 'unite': 792, 'solve': 793, 'cyvdluja_oxrkfpbz': 794, 'out.': 795, 'dmexgspl_mruzqhac': 796, 'least': 797, 'visible': 798, 'movement': 799, 'connectivity': 800, 'wrcktgbd_wzrgyunp': 801, 'abort': 802, 'restore': 803, 'soldfnbq_uhnbsvqd': 804, 'full.': 805, 'month': 806, 'exist': 807, 'build': 808, 'art': 809, 'kingdom': 810, 'sdxjiwlq_ynowzqfh': 811, 'serious': 812, 'vrjwyqtf_qoxkapfw': 813, 'former': 814, 'start.': 815, 'however.': 816, 'rbozivdq_gmlhrtvp': 817, 'send.': 818, 'local.': 819, 'assume': 820, 'mal.': 821, 'yes.': 822, 'fix.': 823, 'wvngzrca_sfmrzdth': 824, 'may.': 825, 'code.': 826, 'cubdsrml_znewqgop': 827, 'include': 828, 'frequent': 829, 'pur': 830, 'cause': 831, 'niptbwdq_csenjruz': 832, 'inventory': 833, 'specifically': 834, 'csotmdiw_yfeqcbti': 835, 'mlckvyfq_aonlxvwb': 836, 'maintenance': 837, 'his.': 838, 'future': 839, 'nach.': 840, 'pxsghrjd_wiehqmka': 841, 'sound': 842, 'mouse': 843, 'power.': 844, 'antigvjx_zekluqim': 845, 'bcefayom_lzhwcgvb': 846, 'ahydmrbu_fjymgtvo': 847, 'mir': 848, 'kcnosyae_zlpmfxgs': 849, 'portal.': 850, 'reinstall': 851, 'rate': 852, 'under.': 853, 'qkedpfyj_qechgaty': 854, 'drop': 855, 'load.': 856, 'administrator.': 857, 'default': 858, 'lpoebzsc_grknswyo': 859, 'erckhtzj_tdmkgoie': 860, 'should.': 861, 'mal': 862, 'client.': 863, 'partial': 864, 'explorer.': 865, 'hlrmufzx_qcdzierm': 866, 'ugephfta_hrbqkvij': 867, 'conduct': 868, 'corp': 869, 'oetlgbfw_bsctrnwp': 870, 'everything': 871, 'demand': 872, 'self': 873, 'cancel': 874, 'wczegmok_bgqoclvs': 875, 'refer.': 876, 'functionality': 877, 'without': 878, 'both.': 879, 'xawlkiey_demjqrfl': 880, 'carrier': 881, 'record': 882, 'prgewfly_ndtfvple': 883, 'deletion': 884, 'fill': 885, 'byclpwmv_esafrtbh': 886, 'pfjwinbg_ljtzbdqg': 887, 'statistic': 888, 'mpihysnw_wrctgoan': 889, 'last.': 890, 'conversion': 891, 'grind': 892, 'st.': 893, 'ohdrnswl_rezuibdt': 894, 'today.': 895, 'neokfwiy_ufriscym': 896, 'bejcxvis_anxmhwis': 897, 'situation': 898, 'fgsmwvcp_uoxkzwes': 899, 'kick': 900, 'rectify': 901, 'es': 902, 'qmwhlnev_ixtmkwdc': 903, 'permission.': 904, 'pop': 905, 'register': 906, 'they.': 907, 'blue': 908, 'hbmwlprq_ilfvyodx': 909, 'take.': 910, 'po.': 911, 'basis': 912, 'bxeagsmt_zrwdgsco': 913, 'behalf': 914, 'gtfdvnry_nxsaqrfh': 915, 'dank.': 916, 'pa': 917, 'moment.': 918, 'session': 919, 'open.': 920, 'fan': 921, 'ethic.': 922, 'mismatch': 923, 'raifstow_gfeymtql': 924, 'say': 925, 'supervisor': 926, 'newly': 927, 'affect': 928, 'now.': 929, 'xnlapdeq_wupaeqlv': 930, 'ekvtdcyq_grncjlho': 931, 'unzfykar_osxmbhav': 932, 'china': 933, 'jmfvwrek_pqwehmzg': 934, 'suspicious': 935, 'run.': 936, 'ethwnzfb_roqytnjk': 937, 'news': 938, 'kxsceyzo_naokumlb': 939, 'smpijawb_eawkpgqf': 940, 'slzhuipc_sqntcber': 941, 'subject.': 942, 'mobile': 943, 'plug': 944, 'press': 945, 'o': 946, 'reader.': 947, 'edit': 948, 'crackle': 949, 'jvhqyamt_wodzrcjg': 950, 'ljxzyriq_zqxkrcev': 951, 'so.': 952, 'launch': 953, 'bulk': 954, 'only.': 955, 'ring': 956, 'log.': 957, 'headset': 958, 'mailbox': 959, 'reimage': 960, 'standard': 961, 'sbgvrncj_idfhtoqv': 962, 'original': 963, 'far': 964, 'detail': 965, 'resolve.': 966, 'complete.': 967, 'calculate': 968, 'connection.': 969, 'them.': 970, 'stall': 971, 'seit.': 972, 'uazkjifp_dhtnevcq': 973, 'installation': 974, 'into.': 975, 'yellow': 976, 'professional': 977, 'impossible': 978, 'describe': 979, 'ythucdjx_mujfrsyl': 980, 'direct': 981, 'uxndyfrs_vahxnfgl': 982, 'catalogue': 983, 'video': 984, 'shut': 985, 'reactivate': 986, 'state.': 987, 'distributor': 988, 'sind': 989, 'jcmxerol_nbfyczqr': 990, 'advance': 991, 'male': 992, 'zlqfptjx_xnklbfua': 993, 'warm.': 994, 'bug': 995, 'ring.': 996, 'secondary': 997, 'russia': 998, 'naruedlk_mpvhakdq': 999, 'xvwchsdg_pladjmxt': 1000, 'qmhikdzl_zatcorjd': 1001, 'adapter': 1002, 'repair': 1003, 'cthaborg_cahbxlmr': 1004, 'though': 1005, 'department': 1006, 'dpuifqeo_eglwsfkn': 1007, 'pfzxecbo_ptygkvzl': 1008, 'he.': 1009, 'failure.': 1010, 'kuemonqi_rtexzlvh': 1011, 'tier': 1012, 'voucher': 1013, 'day.': 1014, 'window': 1015, 'come.': 1016, 'draw': 1017, 'massage': 1018, 'set.': 1019, 'zupifghd_vdqxepun': 1020, 'true': 1021, 'compensation': 1022, 'disable': 1023, 'elt': 1024, 'gzawrocy_shbgwxep': 1025, 'ctvaejbo_mjcerqwo': 1026, 'receipt': 1027, 'object': 1028, 'replace': 1029, 'location.': 1030, 'manually': 1031, 'hctajofe_qgrkcxyt': 1032, 'rugphfdi_trlshejc': 1033, 'ybhazlqp_zfghsxiw': 1034, 'ybjgecfx_nxzuseac': 1035, 'scrap': 1036, 'may': 1037, 'case': 1038, 'extract': 1039, 'er': 1040, 'chat': 1041, 'library': 1042, 'jhwgydeb_ufiatosg': 1043, 'nrugzxkl_lohqkvry': 1044, 'mein': 1045, 'lean': 1046, 'gmwdvrou_aupnvems': 1047, 'pick.': 1048, 'loesgbfh_tknsuhvw': 1049, 'zuxcfonv_nyhpkrbe': 1050, 'sale': 1051, 'wszbxlpu_dsujiozp': 1052, 'count': 1053, 'goaxzsql_qpjnbgsa': 1054, 'skmdgnuh_utgclesd': 1055, 'punch': 1056, 'show.': 1057, 'invoke': 1058, 'jxphgfmb_gjbtuwek': 1059, 'xielgjvr_sqjxewmh': 1060, 'cable': 1061, 'foreign': 1062, 'trade': 1063, 'activation': 1064, 'category': 1065, 'translation': 1066, 'lkrfndev_kztlojin': 1067, 'rekpvblc_ufysatml': 1068, 'fljhvdsn_kiyzclao': 1069, 'hdfcwmag_plxstkad': 1070, 'each.': 1071, 'myself': 1072, 'reroute': 1073, 'th': 1074, 'fbvpcytz_nokypgvx': 1075, 'past': 1076, 'tell': 1077, 'grtaoivq_dwjvfkqe': 1078, 'wvdxnkhf_jirecvta': 1079, 'touch': 1080, 'rdfjsawg_zpmxgdcw': 1081, 'hadbkvwt_touedfyr': 1082, 'gen': 1083, 'hupnceij_hyozjakb': 1084, 'multiple.': 1085, 'fine': 1086, 'tfazwrdv_upwonzvd': 1087, 'non': 1088, 'fygrwuna_gomcekzi': 1089, 'projector': 1090, 'sever': 1091, 'pending': 1092, 'ref': 1093, 'rnueobcz_lwhcbati': 1094, 'until': 1095, 'molihtdq_auprogsj': 1096, 'big': 1097, 'over.': 1098, 'print.': 1099, 'sorry': 1100, 'night': 1101, 'main': 1102, 'picture': 1103, 'result': 1104, 'position': 1105, 'qycgdfhz_iqshzdru': 1106, 'sygionua_szunhced': 1107, 'bayxwszc_oiedajqz': 1108, 'wi': 1109, 'parent': 1110, 'uqrbzknc_snvimeqt': 1111, 'about.': 1112, 'clip.': 1113, 'ptvdxwla_tlevwmzo': 1114, 'technical': 1115, 'houcdelq_wnypackq': 1116, 'total.': 1117, 'bejvhsfx_dmvsclhp': 1118, 'turkey': 1119, 'hanna': 1120, 'calculation': 1121, 'him': 1122, 'format.': 1123, 'gdkiehbr_kdithjsr': 1124, 'horeduca_ogrhivnm': 1125, 'industrial': 1126, 'perhaps': 1127, 'refuse': 1128, 'jltebswi_zmvohjws': 1129, 'doc': 1130, 'possibly': 1131, 'again.': 1132, 'gnasmtvx_cwxtsvkm': 1133, 'mu': 1134, 'directly': 1135, 'delegate': 1136, 'recipient.': 1137, 'return.': 1138, 'environment': 1139, 'list.': 1140, 'nxloukai_cpbzkrel': 1141, 'figure': 1142, 'auto': 1143, 'tracker': 1144, 'wqfzjycu_omleknjd': 1145, 'clear': 1146, 'indicator': 1147, 'daisy': 1148, 'lzaqjxgi_lzfycegm': 1149, 'configuration': 1150, 'dock': 1151, 'guest': 1152, 'iauqlrjk_nijdaukz': 1153, 'if.': 1154, 'hkrecpfv_kgwpbexv': 1155, 'index': 1156, 'control.': 1157, 'document.': 1158, 'vwaliogd_dviwuzhm': 1159, 'group.': 1160, 'campo': 1161, 'rtpmlwnk_unpambrv': 1162, 'lhycpqra_fdhyxqrw': 1163, 'vrfpyjwi_nzhvgqiw': 1164, 'jctnelqs_lansuiwe': 1165, 'feature': 1166, 'engine': 1167, 'lagqkmto_xqtldrcs': 1168, 'special': 1169, 'upiyobvj_lwohuizr': 1170, 'review.': 1171, 'bottom': 1172, 'static': 1173, 'red.': 1174, 'report.': 1175, 'analyst': 1176, 'because.': 1177, 'dtrvxiuq_bwuqdtfo': 1178, 'tmyeqika_hfudpeot': 1179, 'enter.': 1180, 'sxhqfaoe_evobwgiy': 1181, 'mvwiygou_rpkscnlv': 1182, 'hgcrtxez_azoeingw': 1183, 'transport': 1184, 'discount': 1185, 'xjvubmlq_vyamhjip': 1186, 'memory': 1187, 'round': 1188, 'ehfvwltg_eakjbtoi': 1189, 'people': 1190, 'net.': 1191, 'ftgvlneh_aitsgqwo': 1192, 'trail': 1193, 'null': 1194, 'eu': 1195, 'ebkmczgy_pbzfgcoa': 1196, 'language.': 1197, 'area.': 1198, 'ekjobdiz_ktelzwvg': 1199, 'event.': 1200, 'directory': 1201, 'kgqpwvzu_rkexzwlh': 1202, 'steel': 1203, 'drive.': 1204, 'zsulhnxd_gexdzoqy': 1205, 'rphoiduv_hfbevpir': 1206, 'custom': 1207, 'sao': 1208, 'ping': 1209, 'froajhdb_ijetmkuc': 1210, 'aqourvgz_mkehgcdu': 1211, 'verify': 1212, 'try.': 1213, 'rhwsmefo_tvphyura': 1214, 'nibaotpy_vmxathog': 1215, 'dqplrwoy_cutpwjie': 1216, 'ferxqvsm_esmwxqlf': 1217, 'xioapjvd_yiqubxmz': 1218, 'might': 1219, 'zhvrtnom_waedkqzj': 1220, 'lkmhgiwv_omkfxdcq': 1221, 'single': 1222, 'force': 1223, 'modify': 1224, 'qekyowtv_qdjixvkh': 1225, 'ship.': 1226, 'jaeuqbvt_orlhenfj': 1227, 'uaevikhj_uazfcwgm': 1228, 'ahlqgjwx_wbsfavhg': 1229, 'itylnjqw_kqiurhbt': 1230, 'cwuospin_nbhoxqpe': 1231, 'aikejxpb_xdavwocg': 1232, 'bom': 1233, 'scedxqur_pocxqtrl': 1234, 'ozphysqw_pgcmwqze': 1235, 'dkxstwfq_eljczgbn': 1236, 'riuhxcab_jcsavihq': 1237, 'wtxvqngf_nxjivlmr': 1238, 'bios': 1239, 'double': 1240, 'hymjicru_ckrxqfes': 1241, 'lmsxcvoz_vzhkdpfn': 1242, 'egklxsoy_hivwzjcf': 1243, 'ynmcplev_qpgctajz': 1244, 'mitgckqf_ewourgcx': 1245, 'ethic': 1246, 'bjtguqne_xthqrzpc': 1247, 'bujiesrg_zopcrshl': 1248, 'investigate.': 1249, 'ort': 1250, 'against': 1251, 'authorization': 1252, 'din': 1253, 'such': 1254, 'quotation': 1255, 'wgqkkupl_esgahtqn': 1256, 'scanner.': 1257, 'storage': 1258, 'express': 1259, 'txjwyami_fhlgpsim': 1260, 'xdtiwshm_ijyrtulh': 1261, 'tmufgokq_qtzavows': 1262, 'recent': 1263, 'khrflgcj_zxojidhe': 1264, 'regard': 1265, 'export': 1266, 'consultant': 1267, 'completely': 1268, 'she.': 1269, 'wxdvjoct_ckxwtoam': 1270, 'idlupnzr_nkxylwrc': 1271, 'uyrpdvoq_mbzevtcx': 1272, 'book': 1273, 'series': 1274, 'organizer': 1275, 'march': 1276, 'telephone.': 1277, 'entry': 1278, 'machine.': 1279, 'until.': 1280, 'phvkowml_azbtkqwx': 1281, 'zcokibmd_xnrthsmj': 1282, 'okebwncv_zyxvwkpn': 1283, 'knowledge': 1284, 'apply': 1285, 'dxgyefir_rczsatqu': 1286, 'attendance': 1287, 'iso': 1288, 'query.': 1289, 'change.': 1290, 'her.': 1291, 'believe': 1292, 'zebra.': 1293, 'talk.': 1294, 'zelunfcq_yimdwjrp': 1295, 'here': 1296, 'djpwfxzt_cfkwxlmq': 1297, 'cpmaidhj_elbaqmtp': 1298, 'vhzxkjet_lkufgrhq': 1299, 'pfiyvdea_uwbdsfmr': 1300, 'threshold.': 1301, 'mailbox.': 1302, 'intermittent': 1303, 'regional': 1304, 'repyzajo_lxfwopyq': 1305, 'select.': 1306, 'oncidblt_ucewizyd': 1307, 'long.': 1308, 'avurmegj_pxgmjynu': 1309, 'damuphws_arkulcoi': 1310, 'mcytlpva_jutxbdor': 1311, 'trigger': 1312, 'warehouse.': 1313, 'cwrikael_oanmsecr': 1314, 'which.': 1315, 'wird.': 1316, 'rednkluh_lrpyvcxs': 1317, 'lady': 1318, 'fwypxqcs_twsqoimy': 1319, 'data.': 1320, 'stay': 1321, 'low': 1322, 'bnoupaki_cpeioxdz': 1323, 'contract': 1324, 'faulty': 1325, 'present.': 1326, 'lmqysdec_ljvbnpqw': 1327, 'tkbuhcnq_kdheauqo': 1328, 'action.': 1329, 'jofvunqs_uwigjmzv': 1330, 'join': 1331, 'cash': 1332, 'mfeyouli_ndobtzpw': 1333, 'button.': 1334, 'pxvzohlu_hwyijpgd': 1335, 'scjxobhd_ldypjkmf': 1336, 'disconnect.': 1337, 'distribution.': 1338, 'ma': 1339, 'ibtvlfah_dtlwscma': 1340, 'slkxgzdj_wxpytevu': 1341, 'qpiojxcl_dxkcljew': 1342, 'poor': 1343, 'unable.': 1344, 'implementation': 1345, 'suppose': 1346, 'level': 1347, 'rlhuwmve_krcfhoxj': 1348, 'variable': 1349, 'license.': 1350, 'other.': 1351, 'import': 1352, 'tdsmnuib_entgzrhy': 1353, 'pereira': 1354, 'grateful.': 1355, 'ufawcgob_aowhxjky': 1356, 'virtual': 1357, 'section': 1358, 'unavailable': 1359, 'land': 1360, 'nobwzdvh_yqjugexl': 1361, 'activate': 1362, 'tab': 1363, 'desk.': 1364, 'vsbtygin_oufhtbas': 1365, 'ncasrpvx_fijwprtv': 1366, 'win.': 1367, 'bin.': 1368, 'avglmrts_vhqmtiua': 1369, 'koqntham_sqiuctfl': 1370, 'ticket.': 1371, 'fgdsvija_qvixmubh': 1372, 'lokiwfhg_udkoqrcg': 1373, 'sample': 1374, 'kslhobgj_cyhvefna': 1375, 'yorgbnpa_ndigthpj': 1376, 'tige.': 1377, 'think': 1378, 'after.': 1379, 'svdefgwl_sgtmurfh': 1380, 'attempt': 1381, 'design': 1382, 'vfjsubao_yihelxgp': 1383, 'define': 1384, 'breach': 1385, 'packet': 1386, 'acqpinyd_ecygimqd': 1387, 'uezonywf_rldbvipu': 1388, 'aorthyme_rnsuipbk': 1389, 'kehtxprg_uekapfzt': 1390, 'fmqubnvs_kcxpeyiv': 1391, 'important': 1392, 'file.': 1393, 'optimization': 1394, 'ktghvuwr_uwtakcmj': 1395, 'ahmgtlyf_ofgxcrys': 1396, 'sin': 1397, 'mvhcoqed_konjdmwq': 1398, 'above.': 1399, 'example.': 1400, 'ryculmsd_wofgvkrb': 1401, 'tell.': 1402, 'asset': 1403, 'ce': 1404, 'qfetblky_iwflmhuc': 1405, 'eqrknylx_nqpsjhwc': 1406, 'yalntgcz_vaqjknsw': 1407, 'wqzarvhx_hfsojckw': 1408, 'vrdjzswx_rlweqdhs': 1409, 'ncjispka_wspgujxm': 1410, 'tsicojkp_kghaozew': 1411, 'reseat': 1412, 'valid': 1413, 'wit': 1414, 'pone': 1415, 'ualvjicz_vtywmapl': 1416, 'wer': 1417, 'aedzqlvj_mkosyxgh': 1418, 'far.': 1419, 'bank.': 1420, 'ae': 1421, 'lhejbwkc_xbmyvnqf': 1422, 'card': 1423, 'qnxfegjw_rljdhmwb': 1424, 'hpqjaory_gfrwmije': 1425, 'qkgnwxto_dwtivjrp': 1426, 'phedsjct_lyphanue': 1427, 'cowsvzel_ryhkefwv': 1428, 'head': 1429, 'axcbfuqo_yiagubvh': 1430, 'here.': 1431, 'disconnect': 1432, 'bswlorek_yhdrlgbs': 1433, 'aqrhwjgo_cyelqkvs': 1434, 'while.': 1435, 'pu': 1436, 'infrastructure': 1437, 'recognize': 1438, 'revision': 1439, 'oracle': 1440, 'rest': 1441, 'buyoipdj_fceymwtz': 1442, 'bite': 1443, 'clgfntoe_rhtmnzsk': 1444, 'break': 1445, 'mdvlkbac_uhefoqtg': 1446, 'unreachable.': 1447, 'toeibhlp_gukqjwnr': 1448, 'inter': 1449, 'urhpnlaf_agmsfqil': 1450, 'ago': 1451, 'fbyusmxz_kxvmcbly': 1452, 'master': 1453, 'couple': 1454, 'how.': 1455, 'communicate': 1456, 'advise.': 1457, 'laser': 1458, 'outbreak': 1459, 'jrdafplx_fcnjmvts': 1460, 'precision': 1461, 'htvepyua_izgulrcf': 1462, 'layout': 1463, 'trainee': 1464, 'function': 1465, 'latency.': 1466, 'second.': 1467, 'wvqgbdhm_fwchqjor': 1468, 'addition': 1469, 'hmjdrvpb_komuaywn': 1470, 'employee.': 1471, 'glnfyoqe_fexlisau': 1472, 'hgyvopct_dhckfmbq': 1473, 'installation.': 1474, 'noscwdpm_akiowsmp': 1475, 'assist.': 1476, 'august.': 1477, 'acteiqdu_bferalus': 1478, 'ber': 1479, 'hgufmidr_mfobkyun': 1480, 'icon.': 1481, 'gas': 1482, 'disconnection.': 1483, 'hdqfgbei_rnybhzve': 1484, 'normal': 1485, 'center.': 1486, 'colleague': 1487, 'port.': 1488, 'kflqpite_gbeoqsnc': 1489, 'appear': 1490, 'repair.': 1491, 'percent.': 1492, 'common': 1493, 'bqyfwclo_osjklifb': 1494, 'commercial': 1495, 'iksqbuxf_muzxgwvk': 1496, 'btvmxdfc_yfahetsc': 1497, 'melhduty_gqchtedl': 1498, 'tbvpkjoh_wnxzhqoa': 1499, 'trgqbeax_hfyzudql': 1500, 'retention': 1501, 'oxkhntpl_xwszgidt': 1502, 'jwqyxbzs_adpvilqu': 1503, 'bfnvjgxd_trqmnpvu': 1504, 'stick': 1505, 'urgently': 1506, 'vpnraqfk_pgocqjbu': 1507, 'by.': 1508, 'hwxqoijt_cotsgwrj': 1509, 'lqdpfamz_mqitfrcv': 1510, 'wlhxrogv_yawtxuod': 1511, 'cltszugw_tgzbklec': 1512, 'fen': 1513, 'favor': 1514, 'budighfl_izbxvary': 1515, 'effective.': 1516, 'zneyrlhg_bfiwanze': 1517, 'red': 1518, 'xagyhbio_jvrdnpkh': 1519, 'xziwkgeo_gdiraveu': 1520, 'especially': 1521, 'eglavnhx_uprodleq': 1522, 'match': 1523, 'soft': 1524, 'accountant.': 1525, 'jam': 1526, 'tcoyfeph_cqrdaunw': 1527, 'dqgjxhrt_kydnpacx': 1528, 'hnyeajrw_ctxjsolz': 1529, 'provision': 1530, 'away.': 1531, 'jcgzqndm_hukibzqa': 1532, 'box': 1533, 'fyzceglp_vfnraqxc': 1534, 'iqcylpok_ascpqvni': 1535, 'documentation': 1536, 'nkthumgf_mwgdenbs': 1537, 'asxmeruj_drqufvgj': 1538, 'difference': 1539, 'maintain': 1540, 'logic': 1541, 'ijmabvlz_vosuedkm': 1542, 'schedule': 1543, 'image': 1544, 'use.': 1545, 'kbyivdfz_zwutmehy': 1546, 'idea': 1547, 'notwkdgr_zvmesjpt': 1548, 'call.': 1549, 'qdbfemro_mcsqzlvd': 1550, 'isuclrnw_hxrtkiws': 1551, 'loop': 1552, 'agzswjku_kqwofdjl': 1553, 'mus': 1554, 'controller': 1555, 'napijrez_xhpqkojc': 1556, 'jerydwbn_gdylnaue': 1557, 'wacxhqvs_nxdythgc': 1558, 'doesnt': 1559, 'campus': 1560, 'zyblacuk_mvjqwgzn': 1561, 'ncuwyeib_plnzhxvc': 1562, 'nqdyowsm_yqerwtna': 1563, 'ymoeqrsx_rbctdsyi': 1564, 'lkfzibrx_ljnabpgx': 1565, 'deliver': 1566, 'ugawcoye_jcfqgviy': 1567, 'tonight': 1568, 'pdvjanwx_oprdiygs': 1569, 'kcldufqe_xghvrzoi': 1570, 'kiwyjtpu_wzjqcnfy': 1571, 'troxyekl_lzdvgwut': 1572, 'stamp': 1573, 'little.': 1574, 'igkqpndy_swqndxhl': 1575, 'esntuago_kwxrdhuv': 1576, 'hpmwliog_kqtnfvrl': 1577, 'fail': 1578, 'jkmeusfq_vjpckzsa': 1579, 'cytohwau_qfunricw': 1580, 'wptbgchj_jutpdcqf': 1581, 'kilrghwc_ykjrbivs': 1582, 'agent.': 1583, 'qfnthlam_lxvnwuja': 1584, 'table.': 1585, 'kgytujhe_bonhwzrx': 1586, 'icvulkwh_udnyietg': 1587, 'nealxjbc_owjduxai': 1588, 'retire': 1589, 'relevant.': 1590, 'cockpit': 1591, 'give.': 1592, 'even.': 1593, 'excel.': 1594, 'ljpgedia_bzqcwsgf': 1595, 'mistake': 1596, 'save.': 1597, 'transaction.': 1598, 'mdfugwzt_wbcaqkgr': 1599, 'waste': 1600, 'helper': 1601, 'flow': 1602, 'remind': 1603, 'creojvdh_ciblyskg': 1604, 'polish': 1605, 'kydirtgu_idwzeojv': 1606, 'qnstifeb_hybrjfex': 1607, 'nwlhcfpa_zdlfmthq': 1608, 'fdyietau_dvsyxwbu': 1609, 'auditor': 1610, 'pull': 1611, 'pmweoxyq_zrkjnydi': 1612, 'adaptor': 1613, 'whether': 1614, 'vaniegrz_dbocqmpt': 1615, 'human': 1616, 'hip': 1617, 'ersatz.': 1618, 'qavdrpfu_ylfwnbkr': 1619, 'zebra': 1620, 'mqbxwpfn_uclrqfxa': 1621, 'know.': 1622, 'slowly': 1623, 'vgmbxkji_jukplihz': 1624, 'dealer': 1625, 'uwofavej_hxyatnjc': 1626, 'tvmlrwkz_rsxftjep': 1627, 'lckagtry_xcrmzgli': 1628, 'tape': 1629, 'drucken': 1630, 'exchange': 1631, 'stdezpqw_bkmeuhfz': 1632, 'convert': 1633, 'duplicate': 1634, 'browser.': 1635, 'cell': 1636, 'fault': 1637, 'vaigycet_jtgmpdcr': 1638, 'mnxbeuso_rfmdlwuo': 1639, 'due.': 1640, 'ungoxpdc_hmxwuyog': 1641, 'many.': 1642, 'mode': 1643, 'order.': 1644, 'background': 1645, 'specification.': 1646, 'inventory.': 1647, 'eh': 1648, 'plzsntqj_ujdyobsk': 1649, 'moeyphif_zfweijcb': 1650, 'hkjfmcqo_gpcxltar': 1651, 'dtwuqpmo_otupcawz': 1652, 'battery.': 1653, 'pnroqajb_psbyfhkg': 1654, 'mstnjfai_xcobykhl': 1655, 'zjwecphr_swhkzyfq': 1656, 'look.': 1657, 'average.': 1658, 'przndfbo_pldqbhtn': 1659, 'always.': 1660, 'weight': 1661, 'letter': 1662, 'hmutkgze_ngilcqky': 1663, 'approve.': 1664, 'love': 1665, 'lewis': 1666, 'calander': 1667, 'ymapungc_kzaintyu': 1668, 'dinner.': 1669, 'lead.': 1670, 'back.': 1671, 'recover': 1672, 'necessary': 1673, 'yjofqlrx_aqvxfhmn': 1674, 'analytics': 1675, 'sa': 1676, 'weekly': 1677, 'freeze': 1678, 'zlpkfdox_gzlciskf': 1679, 'time.': 1680, 'vat': 1681, 'ujxvrlzg_pkaegicn': 1682, 'vciknubg_wdlkabms': 1683, 'cmifnspg_icauzxfh': 1684, 'precision.': 1685, 'wlsazrce_uwehsqbk': 1686, 'cross': 1687, 'ldmwqubi_sovqeynk': 1688, 'hkfipags_sdilxrfk': 1689, 'extra': 1690, 'accept': 1691, 'expire': 1692, 'wrongful': 1693, 'lhyrskmn_zbovukqm': 1694, 'kmnsvzuq_euyvihzc': 1695, 'rolcgqhx_ehndjmlv': 1696, 'meet.': 1697, 'fylrosuk_kedgmiul': 1698, 'saw': 1699, 'never.': 1700, 'tghrloks_jbgcvlmf': 1701, 'npfkbdxo_vdyltfzx': 1702, 'root': 1703, 'madam': 1704, 'hvskpglx_bpsfxmon': 1705, 'zngpmjue_qvyzposw': 1706, 'xjazwpmd_sjirdnam': 1707, 'volume.': 1708, 'hzpmalgo_xpvugeyr': 1709, 'agreement': 1710, 'qgrbdnoc_dgupnhxv': 1711, 'reinstall.': 1712, 'accurate': 1713, 'zbxljotu_cbunzrak': 1714, 'periodically': 1715, 'thing': 1716, 'alenrdvz_mhglqndp': 1717, 'item.': 1718, 'workbook': 1719, 'excise': 1720, 'release.': 1721, 'notion': 1722, 'akisjtzm_uvbmysgc': 1723, 'esguiazn_pqdjtzin': 1724, 'half': 1725, 'cad': 1726, 'mpjoszqg_wurpohmf': 1727, 'member': 1728, 'version': 1729, 'flash': 1730, 'yolktfas_fyoxqgvh': 1731, 'belt': 1732, 'sdbcpvtx_hzpctsla': 1733, 'majority': 1734, 'finish': 1735, 'step.': 1736, 'arjpdohf_mrqwdtil': 1737, 'vulnerability': 1738, 'wrong.': 1739, 'imzctxhr_odmawbij': 1740, 'visible.': 1741, 'xplwmiyr_pifoldxr': 1742, 'se': 1743, 'hnpbcfsz_qmvbycax': 1744, 'rerun': 1745, 'xmlbfjpg_yegzbvru': 1746, 'ezrsdgfc_hofgvwel': 1747, 'gylicjpx_owlrismj': 1748, 'svuxizgr_mkynswqd': 1749, 'volunteer': 1750, 'beneath.': 1751, 'jdynzuim_uapkdvgr': 1752, 'gsotqxfi_lidunfjg': 1753, 'efgoawct_vwniefok': 1754, 'saver': 1755, 'al': 1756, 'hckvpary_emxbpkwy': 1757, 'aljbtwsh_lepkbgix': 1758, 'yafxlpwi_lhxvatkb': 1759, 'mfvkxghn_mzjasxqd': 1760, 'ownership': 1761, 'restart.': 1762, 'recurrent': 1763, 'dtlmbcrx_mwuateyx': 1764, 'tzmewbdv_zjbuwmkn': 1765, 'hdungfsc_znuhyjkx': 1766, 'interface.': 1767, 'menu': 1768, 'mxzcjhpi_pnelahdw': 1769, 'ongumpdz_pjkrfmbc': 1770, 'count.': 1771, 'shoot.': 1772, 'jfteqgyc_ncazxobk': 1773, 'corrupt': 1774, 'pkfvoucw_yhmicuba': 1775, 'almost': 1776, 'fhzeoyws_gudfnirz': 1777, 'path': 1778, 'usalikfj_lfmpxbcn': 1779, 'temporary': 1780, 'pro': 1781, 'qfcxbpht_oiykfzlr': 1782, 'qcfmxgid_jvxanwre': 1783, 'ersatz': 1784, 'hall': 1785, 'assign.': 1786, 'alarm': 1787, 'th.': 1788, 'lxfnwyuv_bqmjyprz': 1789, 'ongoing': 1790, 'qwijaspo_ukynmfig': 1791, 'delay': 1792, 'information.': 1793, 'zanivrec_capbfhur': 1794, 'designer': 1795, 'blink': 1796, 'bxgiwfhp_hyixrzaw': 1797, 'soon': 1798, 'petljhxi_bocxgins': 1799, 'ntuhoafg_bzwefjvk': 1800, 'director': 1801, 'boxrlpec_fnkhwytl': 1802, 'second': 1803, 'dshferby_houtnzdi': 1804, 'priority': 1805, 'gqcyomwf_opjaiwcu': 1806, 'fkuqjwit_jgcsaqzi': 1807, 'disconnection': 1808, 'silent': 1809, 'guest.': 1810, 'jrzpcesm_oznigwvj': 1811, 'nightly': 1812, 'omufjcxr_ahypftjx': 1813, 'pvlxjizg_xzvlwqjc': 1814, 'country': 1815, 'oe': 1816, 'xtfniscy_ecoyksda': 1817, 'concern': 1818, 'baker': 1819, 'rxqtvanc_kthqwxvb': 1820, 'more.': 1821, 'eokwrjcx_qxzkboeg': 1822, 'ustvaifg_hmzfewks': 1823, 'behind': 1824, 'ypdhesrq_eotjzyxm': 1825, 'ability.': 1826, 'cowqyjzm_fzsxgapt': 1827, 'zwirhcol_narzlmfw': 1828, 'wyotidgu_nydzrtuw': 1829, 'anhang': 1830, 'scroll': 1831, 'qpixeudn_rjlziysd': 1832, 'yvjdluhk_hmcpvtdj': 1833, 'sbtvploj_mwtrouyl': 1834, 'navigate.': 1835, 'pnwcubqr_qdlocnzt': 1836, 'wjpncyef_tspnaimc': 1837, 'nrlhywbm_sxhtogly': 1838, 'u.': 1839, 'pzjelyxg_vstyaouc': 1840, 'utilization.': 1841, 'sup': 1842, 'although': 1843, 'kerbmgdu_yhbcquwd': 1844, 'poll': 1845, 'ha.': 1846, 'qdxyifhj_zbwtunpy': 1847, 'inform.': 1848, 'kyagjxdh_dmtjpbnz': 1849, 'gsnuhpji_qpyfctwl': 1850, 'pifyudbo_tagsfbny': 1851, 'bosch': 1852, 'paqrentz_gcnyaxsb': 1853, 'rmegscqu_juksmtho': 1854, 'jxgobwrm_qkugdipo': 1855, 'whom': 1856, 'provide.': 1857, 'affect.': 1858, 'czwgmjhn_rdnyckft': 1859, 'enterprise': 1860, 'mgvpoyqd_tnlshpwb': 1861, 'wo': 1862, 'er.': 1863, 'most': 1864, 'bdeplqyj_fewovrcq': 1865, 'high.': 1866, 'svelutaj_nguzrmec': 1867, 'cope': 1868, 'okmhzgcq_wzvetbqa': 1869, 'sind.': 1870, 'ublisodp_qydfvpgw': 1871, 'book.': 1872, 'tigwlquj_evynjiar': 1873, 'authorize': 1874, 'push': 1875, 'ctzykflo_evzbhgru': 1876, 'behalf.': 1877, 'ztnpeshl_vmdyglqn': 1878, 'yhmwxsqj_ugnthxky': 1879, 'vendor.': 1880, 'stoppage': 1881, 'brief': 1882, 'impact': 1883, 'jay': 1884, 'dqovxreg_qswvlctg': 1885, 'either': 1886, 'never': 1887, 'eaodcgsw_trmzwbyc': 1888, 'hmrtxkfb_otykaqpc': 1889, 'htsnaodb_adjtmlzn': 1890, 'marc': 1891, 'original.': 1892, 'xmjwanes_astmvqhc': 1893, 'put.': 1894, 'busy': 1895, 'unavailable.': 1896, 'salesperson': 1897, 'quantity.': 1898, 'oydlehun_svnfrxdk': 1899, 'problem.': 1900, 'mhikeucr_quaixnbe': 1901, 'hzmxwdrs_tcbjyqps': 1902, 'uxpytsdk_kyamilds': 1903, 'signal': 1904, 'hcuixqgj_mavxgqbs': 1905, 'properly': 1906, 'gzjtweph_mnslwfqv': 1907, 'sgnubadl_gpkovbah': 1908, 'motor': 1909, 'lease.': 1910, 'their.': 1911, 'pumjbcna_scluvtyj': 1912, 'wrqxmfan_fsizndjb': 1913, 'hey': 1914, 'epaysqnx_rakudnxg': 1915, 'cart': 1916, 'ytwmgpbk_cpawsihk': 1917, 'processor': 1918, 'sa.': 1919, 'kwyozxgd_gasxctph': 1920, 'strange': 1921, 'basically': 1922, 'field.': 1923, 'delta': 1924, 'period.': 1925, 'riqmdnzs_mtlghwex': 1926, 'glwtihcj_lymcgjhd': 1927, 'agree': 1928, 'important.': 1929, 'ber.': 1930, 'fiwaltqr_utykjmwi': 1931, 'along': 1932, 'additional.': 1933, 'automatic': 1934, 'fight': 1935, 'sxzuctga_qnwhyapd': 1936, 'replacement.': 1937, 'prod.': 1938, 'first.': 1939, 'blktuiae_jzakfmhw': 1940, 'pbfscenq_qvaylkne': 1941, 'range': 1942, 'znqlmjvt_uhyokzlt': 1943, 'desowkrh_sciejzne': 1944, 'selection': 1945, 'pyamiwvx_terscahn': 1946, 'quarantine.': 1947, 'banwdfcu_uhlyqwrt': 1948, 'zaeduhlt_jdgsamtv': 1949, 'metric': 1950, 'fniqhjtg_qrfuetpw': 1951, 'arrange.': 1952, 'reddy': 1953, 'hurricane.': 1954, 'vujymcls_sgpmyviq': 1955, 'rebate': 1956, 'wild.': 1957, 'element': 1958, 'span': 1959, 'tab.': 1960, 'mnsejpby_xsrdtvkw': 1961, 'than.': 1962, 'indirect': 1963, 'wont': 1964, 'remain': 1965, 'together': 1966, 'uycravzn_feqlznyg': 1967, 'tjzohmve_wusgaozx': 1968, 'assurance.': 1969, 'specification': 1970, 'holiday': 1971, 'qctdugsi_bfqlgvos': 1972, 'imcknxos_ucyfkaxg': 1973, 'abiuclvj_brziktno': 1974, 'mfyivqes_cpihaxbs': 1975, 'efbwiadp_dicafxhv': 1976, 'akhdmgwt_yhgpafqx': 1977, 'azure': 1978, 'ucawbivs_ountxzir': 1979, 'ex': 1980, 'professional.': 1981, 'win': 1982, 'qbewrpfu_lwibmxzo': 1983, 'inqogkxz_rgmslhjn': 1984, 'acmglkti_cwgxrabu': 1985, 'query': 1986, 'jqhtkfsm_xoehtbnl': 1987, 'unzfipac_opwzmlbc': 1988, 'morgen': 1989, 'ipeajlvk_idmbyztf': 1990, 'initial': 1991, 'video.': 1992, 'alarm.': 1993, 'jefguyza_mkhwcnes': 1994, 'ilbkhgxd_hirsqytd': 1995, 'mcphgvnb_bdegqtyj': 1996, 'proper': 1997, 'ajdcnwtb_bvijwxko': 1998, 'eagvusbr_nguqityl': 1999, 'streng': 2000, 'zdgxtfqs_tibmhxcs': 2001, 'limit': 2002, 'front': 2003, 'chassis': 2004, 'fhcmnxat_geazkjcs': 2005, 'coat': 2006, 'cal': 2007, 'sec.': 2008, 'cut': 2009, 'qwfztdvc_czmndgti': 2010, 'analyzer': 2011, 'sort': 2012, 'enhjdypo_rsbxiepn': 2013, 'wfzgituk_rxvqzopt': 2014, 'ge': 2015, 'organization': 2016, 'lmwohkbd_ucziatex': 2017, 'safe': 2018, 'inconsistent.': 2019, 'petgvwch_zevpkogu': 2020, 'commodity': 2021, 'miecoszw_mhvbnodw': 2022, 'past.': 2023, 'bmixaeon_mtaguhed': 2024, 'pose': 2025, 'onto.': 2026, 'safe.': 2027, 'way': 2028, 'often': 2029, 'fbgetczn_jlsvxura': 2030, 'color': 2031, 'bwgldaoe_aczyfqjr': 2032, 'specialist.': 2033, 'iwqfelcu_gsubfiml': 2034, 'mknoeicg_aziptqvu': 2035, 'lkecfram_tweaokch': 2036, 'dcqsolkx_kmsijcuz': 2037, 'personnel': 2038, 'joiner.': 2039, 'schyepwd_ykatfphc': 2040, 'kabel.': 2041, 'word': 2042, 'trial': 2043, 'divestiture': 2044, 'size': 2045, 'deactivate': 2046, 'subcontract.': 2047, 'titanium': 2048, 'outstanding': 2049, 'dwujlnhs_ecxvrpyl': 2050, 'hitakmbs_fvhmkntq': 2051, 'dctvfjrn_oypnxftq': 2052, 'xbkucsvz_gcpydteq': 2053, 'directory.': 2054, 'aqtcmxuf_kuxsnimy': 2055, 'rbkvofgu_jthclzow': 2056, 'nawkpdtx_gwcvmbhn': 2057, 'ijsptgkh_giojsnqz': 2058, 'intermittently': 2059, 'flap': 2060, 'specify.': 2061, 'mbkxwcav_wsfvmpzg': 2062, 'mwegknsq_xzgskryv': 2063, 'alert.': 2064, 'xjzcbgnp_vfkwscao': 2065, 'copier': 2066, 'zreijwsb_jnrxugpd': 2067, 'effect': 2068, 'propose': 2069, 'szfaidhy_sivyugjd': 2070, 'finally': 2071, 'olckhmvx_pcqobjnd': 2072, 'rjanhbde_owfkyjcp': 2073, 'accidentally': 2074, 'cjnlsbkq_ocxnrewb': 2075, 'xweclugf_qmhbjsyi': 2076, 'box.': 2077, 'reactive': 2078, 'encounter': 2079, 'homsxpyw_qgcsaymo': 2080, 'medium': 2081, 'really': 2082, 'yhmzxcia_heszapvl': 2083, 'model.': 2084, 'clock.': 2085, 'employment': 2086, 'temp': 2087, 'pxvjczdt_kizsjfpq': 2088, 'physical': 2089, 'htnvbwxs_gwfrzuex': 2090, 'vkzwafuh_tcjnuswg': 2091, 'confidential': 2092, 'everyone': 2093, 'disk.': 2094, 'freight': 2095, 'pound.': 2096, 'expiry': 2097, 'actively.': 2098, 'dslamtcb_ezbmonjr': 2099, 'xahuklgm_dqvkfjlb': 2100, 'ypladjeu_wzfryxav': 2101, 'defect': 2102, 'sept': 2103, 'development': 2104, 'depute': 2105, 'etvendormhd_xpslzunb': 2106, 'ojhiaubp_lovgirtm': 2107, 'hip.': 2108, 'role': 2109, 'collaboration.': 2110, 'frydqbgs_ugmnzfik': 2111, 'tgafnyzb_hnevrcuj': 2112, 'mxawhbun_siyqthel': 2113, 'around': 2114, 'koiapqbg_teyldpkw': 2115, 'archive': 2116, 'tnywkdpl_gnjmazuo': 2117, 'jet': 2118, 'tcepzdhi_ymbirlod': 2119, 'jtwykasf_elkhcjqn': 2120, 'mobaidfx_gviwlsrm': 2121, 'uarnkqps_gufcjxma': 2122, 'final': 2123, 'universal': 2124, 'ebikdrqw_empubwxo': 2125, 'ulmctsvi_lbvrdika': 2126, 'permanently.': 2127, 'xmeytziq_dcgwuvfk': 2128, 'ejvkzobl_yijgokrn': 2129, 'clothe': 2130, 'experience': 2131, 'cfajzero_vlygoksi': 2132, 'execute': 2133, 'xwertljy_zrmlhkyq': 2134, 'drmusvny_yvsmtgid': 2135, 'charger': 2136, 'lwizucan_zvnxlobq': 2137, 'orvwshat_acpgvixj': 2138, 'zsqabokr_xbtsaodr': 2139, 'qxmujhwg_rsgqidxw': 2140, 'outside': 2141, 'duration': 2142, 'qvtlcbyg_lbnjhysc': 2143, 'leave.': 2144, 'replicate.': 2145, 'two.': 2146, 'process.': 2147, 'obtain': 2148, 'bmudkpie_qolrvbip': 2149, 'gasbfqvp_fmvqgjih': 2150, 'ogasxnpw_cfvqrhap': 2151, 'already.': 2152, 'rtnzvplq_erhmuncq': 2153, 'throw': 2154, 'dob': 2155, 'ar': 2156, 'ghaltiek_lsuepvyx': 2157, 'mean': 2158, 'kbclinop_vsczklfp': 2159, 'resolution': 2160, 'zjawqgcs_tohqcxla': 2161, 'laser.': 2162, 'whole': 2163, 'byfskuni_mhvnqodk': 2164, 'recruit': 2165, 'post.': 2166, 'side': 2167, 'search.': 2168, 'zlxcsqdg_ckpojwir': 2169, 'subcontract': 2170, 'rough': 2171, 'correspond.': 2172, 'cache': 2173, 'reader': 2174, 'cwfzldts_dlmukhyn': 2175, 'tuqrvowp_fxmzkvqo': 2176, 'deliverable.': 2177, 'mtwzniyh_orbjskip': 2178, 'qnvjhgmc_nicvbrzg': 2179, 'memory.': 2180, 'your.': 2181, 'wxstfouy_isjzcotm': 2182, 'deployment': 2183, 'chain.': 2184, 'seiner': 2185, 'weszfyok_fbadnjhu': 2186, 'ubiqcrvy_mxjcnqfs': 2187, 'ludhvmro_okdbwcsu': 2188, 'qwreamdz_pmarxvtk': 2189, 'boirqctx_bkijgqry': 2190, 'nckihpba_czrdksex': 2191, 'pjzhkbus_mpcyxvdj': 2192, 'sigfdwcj_reofwzlm': 2193, 'aofnvyzt_eqiyskhm': 2194, 'pi': 2195, 'xrmvbenu_pynjmqci': 2196, 'mvaxhzks_kyzvflth': 2197, 'zip': 2198, 'detail.': 2199, 'rcpghuqb_bxrqamng': 2200, 'ufgkybsh_ijswtdve': 2201, 'instruction': 2202, 'ipydfcqo_kdxsquzn': 2203, 'puxsvfwr_cwkjruni': 2204, 'rwmeuzvy_bpstvajw': 2205, 'pchjidaq_pvtxjaml': 2206, 'involve': 2207, 'gqkedvzu_czoniyra': 2208, 'directly.': 2209, 'rcbdyslq_zuspjbtw': 2210, 'distribute': 2211, 'gkzedilm_tkpfumeb': 2212, 'still.': 2213, 'sny': 2214, 'suddenly': 2215, 'must': 2216, 'horrible': 2217, 'ruhvqcwz_kdqzlijw': 2218, 'gakceqyb_edrjthvo': 2219, 'large': 2220, 'jwhmqnye_xlpvdwre': 2221, 'ko': 2222, 'role.': 2223, 'bzxljkoy_rvoiqthl': 2224, 'would.': 2225, 'despite': 2226, 'xwcpkysq_jydxhczm': 2227, 'halo': 2228, 'accessible': 2229, 'nothing': 2230, 'renew': 2231, 'needful.': 2232, 'previously': 2233, 'buff.': 2234, 'requirement': 2235, 'storm': 2236, 'lixjduso_upanbtxg': 2237, 'swap': 2238, 'fox': 2239, 'legal': 2240, 'sample.': 2241, 'ger': 2242, 'vwaufgxr_nvdyhlqk': 2243, 'administration': 2244, 'divide': 2245, 'shipment.': 2246, 'ginjmaxk_zumkvfeb': 2247, 'peer': 2248, 'main.': 2249, 'city': 2250, 'protocol': 2251, 'qoybxkfh_dwcmxuea': 2252, 'gwrkhufx_gsfrlqwi': 2253, 'briefly': 2254, 'certify': 2255, 'content.': 2256, 'kwehgxts_agdsqbwv': 2257, 'imaginal.': 2258, 'region': 2259, 'good.': 2260, 'regularly': 2261, 'lag': 2262, 'particularly': 2263, 'upfthmjx_fdxrpqat': 2264, 'administrator': 2265, 'currency': 2266, 'vkzwibco_pueyvhoi': 2267, 'away': 2268, 'insufficient': 2269, 'yjkalmbr_jsdyzivq': 2270, 'fyuqhlcx_fjiuhxae': 2271, 'snapshot': 2272, 'hotwlygp_afukzhnm': 2273, 'settlement': 2274, 'qzbxfncr_kysuqema': 2275, 'same.': 2276, 'jmoqelbc_fbzsyjne': 2277, 'cjklxmhi_hmrkzbxu': 2278, 'qgilmtyc_gmscovxa': 2279, 'resource': 2280, 'complaint.': 2281, 'xyodfqhk_wgymhail': 2282, 'wonder': 2283, 'noise': 2284, 'fbhyeksq_caexmols': 2285, 'realm': 2286, 'anything.': 2287, 'near': 2288, 'gvtbduyf_gdblxiva': 2289, 'rekmqxfn_jctgwmyi': 2290, 'iso.': 2291, 'become': 2292, 'ujsyzrvw_vjuyzcih': 2293, 'qtrmxlgv_dfruzvam': 2294, 'construct': 2295, 'azovgeck_zuwnxdbt': 2296, 'severity': 2297, 'blade': 2298, 'hibernation': 2299, 'value.': 2300, 'mfixrouy_dyifhcjt': 2301, 'jvxmzteb_vsdcnfyr': 2302, 'inactive': 2303, 'uwiqchfp_hnsukjma': 2304, 'international': 2305, 'fico': 2306, 'couskjgd_uzojtkmh': 2307, 'phase': 2308, 'va': 2309, 'aqgphjbc_utjrsedy': 2310, 'filter': 2311, 'ubqjihpt_pzrjxmgd': 2312, 'tag.': 2313, 'mynfoicj_riuvxdas': 2314, 'just.': 2315, 'profile.': 2316, 'oinqckds_qieswrfu': 2317, 'ing': 2318, 'transportation': 2319, 'approximately': 2320, 'dev': 2321, 'interruption': 2322, 'amunklhx_bvrachko': 2323, 'lndypaqg_dhqwtcsr': 2324, 'defense.': 2325, 'backup.': 2326, 'wgpimkle_kijhcwur': 2327, 'morgen.': 2328, 'ucdwyxko_apktrsyq': 2329, 'disable.': 2330, 'kxmidsga_zokivdfa': 2331, 'general': 2332, 'tap': 2333, 'batter': 2334, 'wqxzleky_uwjchqor': 2335, 'owfecbnx_gfloariu': 2336, 'automatical': 2337, 'anything': 2338, 'award': 2339, 'breakdown': 2340, 'skocrqdw_pexcdfao': 2341, 'lpnzjimy_mwtvondq': 2342, 'drucken.': 2343, 'feel': 2344, 'late': 2345, 'face.': 2346, 'xwyrvcbj_bmqfszjg': 2347, 'create.': 2348, 'jevckify_sbnohwiv': 2349, 'kzybxher_prjaswhe': 2350, 'makiosjc_kxapdhnm': 2351, 'dell.': 2352, 'wgmnjxft_zeyhasdj': 2353, 'ygkzwsud_cvjgkxws': 2354, 'consult.': 2355, 'accord': 2356, 'zidcxslw_clyfdaki': 2357, 'hldifrbv_gadyktfz': 2358, 'whoyizfp_gclnfkis': 2359, 'qubywmgf_jouickqx': 2360, 'xkegcqov_drctxjqi': 2361, 'week.': 2362, 'player': 2363, 'howfanzi_siavgtby': 2364, 'jdocyzgq_gdvmjnso': 2365, 'party': 2366, 'sender.': 2367, 'header': 2368, 'cfokqnhz_notxygdz': 2369, 'conversion.': 2370, 'duplex': 2371, 'jyrzqhgt_xwasiehc': 2372, 'anuxbyzg_bvsqcjkw': 2373, 'duwvesim_cixqbmfr': 2374, 'proposal.': 2375, 'accrual': 2376, 'small': 2377, 'modification': 2378, 'prove': 2379, 'qfwnbutk_jtenbvkq': 2380, 'rep': 2381, 'convention': 2382, 'zero': 2383, 'bi': 2384, 'proposal': 2385, 'relationship.': 2386, 'siqobhlz_vwljuize': 2387, 'sar': 2388, 'establish': 2389, 'oinlxfak_ojlyanhs': 2390, 'sure.': 2391, 'nouivdea_boiypjvx': 2392, 'xmysiufa_emfdltqz': 2393, 'june': 2394, 'distribution': 2395, 'vmtwoadp_ohjvlcmb': 2396, 'iqbyrtop_izpmvgfq': 2397, 'koahsriq_wdugqatr': 2398, 'xdswhrif_ludsxncq': 2399, 'mill.': 2400, 'xaqzisrk_ahbgjrqz': 2401, 'aexbclqv_zvapcslb': 2402, 'icnjlzas_cvphuknj': 2403, 'well.': 2404, 'qomancfz_esafqznm': 2405, 'through.': 2406, 'vradzimk_xvmcoskl': 2407, 'advice': 2408, 'dmlnpgkv_ophsnmbr': 2409, 'dctviemg_muapxkns': 2410, 'structure': 2411, 'wifevnpm_bkcixfjd': 2412, 'utgszjrf_pacfvxzk': 2413, 'regardless': 2414, 'unrbafjx_reyshakw': 2415, 'sghamujc_shompueb': 2416, 'flicker': 2417, 'cqargubj_krdxbfqh': 2418, 'vpnxjtyz_wmakhpci': 2419, 'qvncizuf_ueiybanz': 2420, 'swfdvezh_fpjybetd': 2421, 'watcher.': 2422, 'till': 2423, 'robot': 2424, 'lkwspqce_knxaipyj': 2425, 'occurrence': 2426, 'zcxfngeq_gwczibrq': 2427, 'dumovtpj_ahgjsvoq': 2428, 'stable': 2429, 'pmwuotcq_oiuybwzg': 2430, 'speed': 2431, 'stwpzxbf_bjehirkx': 2432, 'fnqelwpk_ahrskvln': 2433, 'gest.': 2434, 'tblmnxez_ulcmryaf': 2435, 'inhekdol_anvqzdif': 2436, 'low.': 2437, 'aedwrpvo_qbpafrsx': 2438, 'nwqktzlx_vnlqkgpb': 2439, 'purchase.': 2440, 'fonjtyhr_wnclfztv': 2441, 'critical.': 2442, 'cgqfdotb_wtefjknd': 2443, 'air': 2444, 'duplication': 2445, 'part.': 2446, 'yisohglr_uvteflgb': 2447, 'probably': 2448, 'connectivity.': 2449, 'view.': 2450, 'min.': 2451, 'kfirsmxn_dieluyra': 2452, 'ge.': 2453, 'bgflmyar_xgufkidq': 2454, 'too.': 2455, 'zbmhdaru_zhaupwno': 2456, 'job.': 2457, 'inxsupmy_zhwmifvx': 2458, 'urgently.': 2459, 'across': 2460, 'xzcwlqrv_fjrdhiqt': 2461, 'mgpfntcl_mjoigcdb': 2462, 'zvjwleuo_tdfqgcal': 2463, 'ydvmibwn_eljtsdar': 2464, 'bag': 2465, 'adopter': 2466, 'hand': 2467, 'em': 2468, 'court': 2469, 'joiner': 2470, 'gain': 2471, 'mfizgpoy_akbvznci': 2472, 'cieagtub_vwyzjlqm': 2473, 'ctixyzku_jitrahgx': 2474, 'soft.': 2475, 'pyrtfdxu_nxfkqmoy': 2476, 'edqylkio_ykomciav': 2477, 'ejmdqfbl_xuqkwdfa': 2478, 'course': 2479, 'qgvbalix_smehqkyj': 2480, 'mine': 2481, 'umykjweg_jpwrfuhk': 2482, 'solid': 2483, 'paternoster.': 2484, 'alfa': 2485, 'hwfckjzs_abxdmyho': 2486, 'gdsjrxwl_pzhyxdiq': 2487, 'dow.': 2488, 'maybe.': 2489, 'zektaqof_cgxlqtiz': 2490, 'dcxjngaf_zquoewhp': 2491, 'obvjhlsa_jxnlwspq': 2492, 'juxitrbf_vebckrgh': 2493, 'across.': 2494, 'point.': 2495, 'ylitqvaj_ljxdfhus': 2496, 'seek': 2497, 'before.': 2498, 'drill.': 2499, 'eakhgxbw_pfyadjmb': 2500, 'jkpwisnf_lgpdyncm': 2501, 'tqrlikex_moxaebfq': 2502, 'zarlgjes_nxjvzcta': 2503, 'sufficient': 2504, 'don': 2505, 'pwotudlf_wpjlxfke': 2506, 'wrongly.': 2507, 'command': 2508, 'plug.': 2509, 'jczwxvdn_pexuklry': 2510, 'cuytdmhv_yeqdmwvt': 2511, 'beyond': 2512, 'gwmspqeo_vwfetaqg': 2513, 'ivcygqta_qiovrcal': 2514, 'datum': 2515, 'revert': 2516, 'kdjfhwua_arfpnhbj': 2517, 'iqtynrbf_fyvjpbui': 2518, 'wimozrdc_iodvtuaz': 2519, 'immediate.': 2520, 'jzksvdtb_czvlsmqx': 2521, 'wjkzgyxh_pktcqbxu': 2522, 'bay': 2523, 'awsqjfkm_dejmuhlg': 2524, 'israel': 2525, 'horzelqj_ujyzldmh': 2526, 'trigger.': 2527, 'buyer': 2528, 'ckmnouwi_nxmtkubc': 2529, 'pltkqrfd_bfohnjmz': 2530, 'cute.': 2531, 'vgptfdqw_yjqeridp': 2532, 'maiklcjz_ltwrfysm': 2533, 'svlcqmnb_qlwerhxt': 2534, 'weak': 2535, 'extension': 2536, 'xgpqsihu_xcswovzi': 2537, 'nrmjhuox_ktuyqewp': 2538, 'wrench': 2539, 'dump': 2540, 'zfliqpxm_dgfvaqlh': 2541, 'conversation': 2542, 'yodgaxsp_ucjynprt': 2543, 'huqvpyli_ucrtkvyl': 2544, 'le': 2545, 'herself': 2546, 'fybwjzhx_ojgrpafb': 2547, 'awcgpyeh_hlavbsjf': 2548, 'ecfbdmwt_dgnoqymj': 2549, 'reason.': 2550, 'qscdktvl_rihendxu': 2551, 'asthifne_baehplqt': 2552, 'procedure': 2553, 'consider': 2554, 'beneficial': 2555, 'gpabsizh_txldupyk': 2556, 'eocvkuxw_eqfsphnd': 2557, 'chkmejsn_lvidgknc': 2558, 'vrmdtcal_agythfow': 2559, 'instruct': 2560, 'permanently': 2561, 'column': 2562, 'approver': 2563, 'ross': 2564, 'tiefszyh_sfujdlgv': 2565, 'domestic': 2566, 'display.': 2567, 'urfdkvei_bfiulzto': 2568, 'kilywpuo_dcksxjeq': 2569, 'tycludks_cjofwigv': 2570, 'copyright.': 2571, 'nlearzwi_ukdzstwi': 2572, 'flat': 2573, 'these.': 2574, 'eastern': 2575, 'daylight': 2576, 'eternal': 2577, 'assurance': 2578, 'ospmbweg_peswfcbj': 2579, 'ewylacup_jlibymtw': 2580, 'decommission': 2581, 'xezjvnyr_hmjwknxs': 2582, 'iba': 2583, 'oewshlmd_azjfshry': 2584, 'modern': 2585, 'possible.': 2586, 'msrxjfdz_ncsaryod': 2587, 'altogether': 2588, 'juelbpyf_ozvgnuwb': 2589, 'crkdjbot_qiztrxne': 2590, 'claim': 2591, 'money.': 2592, 'alto': 2593, 'hugcadrn_ixhlwdgt': 2594, 'external.': 2595, 'invoke.': 2596, 'ewiakvmz_tufwrhaj': 2597, 'ijeqpkrz_nwtehsyx': 2598, 'pbrmgyzo_hzoxdijn': 2599, 'regional.': 2600, 'flush': 2601, 'talk': 2602, 'those.': 2603, 'edit.': 2604, 'circuit.': 2605, 'wbqtfzdv_aectbluw': 2606, 'device.': 2607, 'lfikjasz_tjbqcmvl': 2608, 'currently.': 2609, 'plus': 2610, 'cwivnxuk_izmxqfud': 2611, 'mir.': 2612, 'lhmxposv_lnpgjhus': 2613, 'uicjxvng_jcoshmbf': 2614, 'vwaejqrh_kmtvyesb': 2615, 'hear.': 2616, 'fu.': 2617, 'xsnrlygw_nmqyraec': 2618, 'apt': 2619, 'pxbqkfgm_qexvrmcn': 2620, 'neoarmgd_meodvbxu': 2621, 'unsuccessful': 2622, 'ucphibmr_dfvkbtsj': 2623, 'host.': 2624, 'oujvmgeq_spobcflw': 2625, 'equipment.': 2626, 'limit.': 2627, 'gjisfonb_odwfhmze': 2628, 'vykbweum_hpvctbse': 2629, 'uhiekyjz_mflihxpq': 2630, 'currency.': 2631, 'coffee': 2632, 'executive': 2633, 'zgemhkby_lgwkstcb': 2634, 'history': 2635, 'con': 2636, 'trxsychl_xamcuong': 2637, 'rujteoza_mcoswhju': 2638, 'gacfhedw_iqustfzh': 2639, 'clock': 2640, 'operate': 2641, 're.': 2642, 'basic.': 2643, 'technology': 2644, 'correctly.': 2645, 'him.': 2646, 'helical': 2647, 'vcedphrq_yajdpgnz': 2648, 'neither.': 2649, 'happen': 2650, 'three': 2651, 'hoyevanb_ruwvniet': 2652, 'specialist': 2653, 'zqrnveyx_hajtfmcd': 2654, 'edanpfzl_qyrfndkp': 2655, 'footer': 2656, 'lmwfdnri_joplxizv': 2657, 'sie.': 2658, 'wnorzsyv_mdflqwxg': 2659, 'fksahqzc_cdwhznbo': 2660, 'home.': 2661, 'upon': 2662, 'thro': 2663, 'colleague.': 2664, 'zfhqxjms_ztfcobhy': 2665, 'maybe': 2666, 'yjwivxsh_fcetobrj': 2667, 'mdkbjzrt_qaxhznvy': 2668, 'phqwmniy_kjucgqom': 2669, 'dan': 2670, 'tally': 2671, 'exist.': 2672, 'cbupnjzo_daflthkw': 2673, 'bfqnvezs_vwkasnxe': 2674, 'subsystem': 2675, 'kit.': 2676, 'origin': 2677, 'viewer': 2678, 'differential': 2679, 'respectively': 2680, 'topic.': 2681, 'usqrpicf_dfmxaliz': 2682, 'bur.': 2683, 'jvpkulxw_ovuweygj': 2684, 'assumption.': 2685, 'ncksqfmz_fzcjunai': 2686, 'alt': 2687, 'click.': 2688, 'require': 2689, 'fill.': 2690, 'nmpworvu_upgtrvnj': 2691, 'ask': 2692, 'vfyuldps_kjgcaphx': 2693, 'line.': 2694, 'xjmpacye_qgxrptnf': 2695, 'nfayqjhg_kyswcpei': 2696, 'tskwevno_sjhpoakl': 2697, 'wear': 2698, 'module.': 2699, 'floor.': 2700, 'ivkhegjw_gquflzse': 2701, 'fasirxzo_xlvnhptm': 2702, 'oirxvhbp_zltpgvbk': 2703, 'fmjwzstr_yjotleqg': 2704, 'xdabnget_wryuikgd': 2705, 'bfckamsg_tzdkbmfe': 2706, 'reallocate': 2707, 'qasouhlc_xkhsirtd': 2708, 'migration': 2709, 'proceed': 2710, 'gbtshxqn_nbvmceyx': 2711, 'sihtvocw_yspnqxgw': 2712, 'master.': 2713, 'mgcivbtx_bshmfxya': 2714, 'own': 2715, 'source.': 2716, 'zrpemyab_xvzwcbha': 2717, 'usage': 2718, 'urgqkinl_zpcokgbj': 2719, 'mandatory': 2720, 'lediwjvb_tqijrdgw': 2721, 'ylhptzmd_owslfzqi': 2722, 'separate': 2723, 'simple': 2724, 'incomplete': 2725, 'alternate': 2726, 'bonus': 2727, 'fail.': 2728, 'rmdtqfxa_fwpnqdxo': 2729, 'renewal': 2730, 'dzjxrkae_grqczsmx': 2731, 'laeusvjo_fvaihgpx': 2732, 'warden': 2733, 'egbziufw_syzpgchf': 2734, 'vfoyenlw_ntpbdeyf': 2735, 'zuangtpq_xpnscghk': 2736, 'respect': 2737, 'wnvlmsjr_znbvlygd': 2738, 'dfetvmzq_brxavtzp': 2739, 'plot': 2740, 'expedite': 2741, 'recovery.': 2742, 'kabel': 2743, 'hkruyqfc_aouezihl': 2744, 'ctbsupdy_auhocbli': 2745, 'ndyrowef_biwecrgx': 2746, 'xfdkwusj_gyklresa': 2747, 'campo.': 2748, 'venue': 2749, 'detachable': 2750, 'severe': 2751, 'dxwuovgs_lmuxizht': 2752, 'manipulate': 2753, 'aunkpchr_qsyvrmjl': 2754, 'para': 2755, 'zfebmujk_mtdzqjue': 2756, 'oqbstujm_sutjvker': 2757, 'ewsybazi_otkuaxhw': 2758, 'stick.': 2759, 'dknejifu_dljvtebc': 2760, 'hrqvkemg_dmcxbrqj': 2761, 'ilypdtno_mkdfetuq': 2762, 'beyond.': 2763, 'verification': 2764, 'deqmzotr_zhrjngbi': 2765, 'otpkzifh_gywinoml': 2766, 'vpityxbu_qktwepmz': 2767, 'finish.': 2768, 'tmqfjard_qzhgdoua': 2769, 'streng.': 2770, 'rnajgdmb_fioznltc': 2771, 'wvtsiucg_bfpemgol': 2772, 'malfunction.': 2773, 'zovfeyjp_xflunkim': 2774, 'reybfnmc_jentcopr': 2775, 'man': 2776, 'ilhcgoqf_xlibynvc': 2777, 'gxuvbcpr_libcktnm': 2778, 'off.': 2779, 'validity': 2780, 'similar': 2781, 'previous.': 2782, 'none': 2783, 'yrhnxpvi_drlbzqpi': 2784, 'driver.': 2785, 'wsomjhce_afjkuwih': 2786, 'wjslkzfr_jxlbzwrp': 2787, 'spell': 2788, 'iytebhvd_coerxklt': 2789, 'vhlepcta_lqbgcxpt': 2790, 'perform': 2791, 'maintenance.': 2792, 'bare': 2793, 'executable': 2794, 'metal': 2795, 'ready': 2796, 'zjihgovn_cqxahony': 2797, 'law': 2798, 'fjciqgav_ybkqvazh': 2799, 'skrxopnw_zjasxphv': 2800, 'pwvmkeza_mzwqgejy': 2801, 'dkinobsv_wymgzcrh': 2802, 'revise': 2803, 'dwafrmth_oabwzitv': 2804, 'ksgytjqr_ojdukgzc': 2805, 'jfgkmauh_wfrgkejq': 2806, 'roll': 2807, 'zlemowkf_hamtklux': 2808, 'obuwfnkm_ufpwmybi': 2809, 'hmgbwyce_sacuoyfe': 2810, 'kfhnmtgi_boxmklnp': 2811, 'cyxulwmi_lygbewdi': 2812, 'partner.': 2813, 'udhsyljz_cogbript': 2814, 'branch': 2815, 'basic': 2816, 'duty.': 2817, 'deal': 2818, 'scievjwr_cdlsvoif': 2819, 'various': 2820, 'geylvotd_msadrzkj': 2821, 'ejfgzqyk_wpbujczy': 2822, 'highlight': 2823, 'live.': 2824, 'vwdghyai_pjehycoz': 2825, 'permanent': 2826, 'cflrqoew_qbgjwaye': 2827, 'canner.': 2828, 'anpocezt_qturbxsg': 2829, 'mnrgpfqh_mblavfti': 2830, 'weekend.': 2831, 'technician.': 2832, 'xfznctqa_xstndbwa': 2833, 'carve': 2834, 'fabijhsd_ocsnugeh': 2835, 'orjszque_lukegwam': 2836, 'macro': 2837, 'kyzhcsrq_fwyltvpd': 2838, 'loaner': 2839, 'studio': 2840, 'cause.': 2841, 'pkdavqwt_tafrmxsh': 2842, 'qtovukbc_jumqcvti': 2843, 'orange': 2844, 'tor': 2845, 'braze': 2846, 'badge.': 2847, 'epjwqaru_mikoszpv': 2848, 'vrbdqjwk_uwxmbztl': 2849, 'seat': 2850, 'puxiomgy_ndjorwab': 2851, 'warn.': 2852, 'planner': 2853, 'money': 2854, 'complaint': 2855, 'cdbhoxir_vlpkithu': 2856, 'attend.': 2857, 'patch': 2858, 'cqrmewsi_xypfqhid': 2859, 'lpfzasmv_cleoprzq': 2860, 'crash': 2861, 'four': 2862, 'yjcxvrhu_mlqfuapc': 2863, 'tam': 2864, 'incorrectly': 2865, 'inner': 2866, 'fqxnplkb_cqhnavfp': 2867, 'nhixruet_elnjqdwg': 2868, 'iljahycm_cknjzewf': 2869, 'aero': 2870, 'doxemspb_utabejmq': 2871, 'loan': 2872, 'newly.': 2873, 'biwcuadk_pvrgtzox': 2874, 'ztdgvclp_gzcalstq': 2875, 'prim': 2876, 'dom': 2877, 'ne.': 2878, 'afwzehqs_jfbxegac': 2879, 'arkmtcig_adpsrxjc': 2880, 'restriction.': 2881, 'bmhxwvys_tdmgolwn': 2882, 'vdylwkbo_hzlnrgat': 2883, 'yjxuqdto_sivnzgok': 2884, 'zqordbct_lnspykfu': 2885, 'feeder': 2886, 'probe': 2887, 'ftsqkvre_bqzrupic': 2888, 'corporate': 2889, 'thermal': 2890, 'completion': 2891, 'thnsguzj_utwijzag': 2892, 'dkrbwceu_aiqkycwp': 2893, 'delivery.': 2894, 'shi': 2895, 'routinely': 2896, 'wyighrjl_xcwavhyu': 2897, 'jgxclrzp_jzeantui': 2898, 'ger.': 2899, 'repository': 2900, 'analyser': 2901, 'nqlertog_bshidqox': 2902, 'ckflmqoj_fojkrlmw': 2903, 'sabufdcz_rbkvlhpo': 2904, 'tpqhevdg_zluijfwv': 2905, 'every.': 2906, 'business.': 2907, 'oqvwgnkc_gkjylpzx': 2908, 'caller.': 2909, 'activation.': 2910, 'nor': 2911, 'xdvwitpm_zscxqdho': 2912, 'map': 2913, 'arexjftu_ohxdwngl': 2914, 'vsmffxaj_ouahwpds': 2915, 'gzmafoiv_spqjlbar': 2916, 'administrative': 2917, 'lvxakohq_tsfnhowj': 2918, 'hdetqcpj_ehsjitcy': 2919, 'ywlbctfr_yvkhcwip': 2920, 'crack': 2921, 'gokluswt_qlvzreyb': 2922, 'vaqsmniw_dtgnkzvp': 2923, 'powder': 2924, 'anyone': 2925, 'lead': 2926, 'quick': 2927, 'tfesaxip_cvorpnth': 2928, 'technician': 2929, 'vcnjqfta_islabdft': 2930, 'rgpvdhcm_mgvpabsj': 2931, 'zujpycos_pogmachd': 2932, 'like.': 2933, 'uninstalled': 2934, 'ojgfmvep_zbatowgi': 2935, 'jgautdmk_fpurxzew': 2936, 'ray': 2937, 'gdpxqyhj_iapghvke': 2938, 'maximum': 2939, 'jghqolyd_cydthpjv': 2940, 'vwhkldyp_efblthqc': 2941, 'vumbyikw_kqsiougd': 2942, 'xbhqcayd_smkbuphw': 2943, 'sxnzacoj_lwvqgfby': 2944, 'ajlbguzn_fxrwivyg': 2945, 'dhoalycb_yopvwrjq': 2946, 'assistant': 2947, 'loader': 2948, 'qkmgtnla_buraxcij': 2949, 'measure': 2950, 'lockout': 2951, 'randomly': 2952, 'daily.': 2953, 'qedxiryu_mdupjolb': 2954, 'speak.': 2955, 'rack': 2956, 'rhaycqjg_arcgonvy': 2957, 'segvwfyn_mogtrevn': 2958, 'wtgbdjzl_coliybmq': 2959, 'umdyvbxo_qwzstijr': 2960, 'oclock': 2961, 'jehlsagi_dhkfuswg': 2962, 'constantly': 2963, 'jvxtfhkg_heptuizn': 2964, 'labor': 2965, 'rclqfpgt_tbnovxdp': 2966, 'overall': 2967, 'cqwtksbu_tgxockrn': 2968, 'kblpmanr_yxqilvua': 2969, 'utoegyqx_lhosidqg': 2970, 'spillage': 2971, 'fwgdbatq_qgownfkv': 2972, 'kdhztcva_smpynjae': 2973, 'temporarily': 2974, 'qkmvosen_opundxsk': 2975, 'stop.': 2976, 'ywbnzxud_qzwrynux': 2977, 'lunch.': 2978, 'wire': 2979, 'leyvdwjt_biaklozn': 2980, 'early': 2981, 'window.': 2982, 'arhjlgdz_pxtsjnlk': 2983, 'wykigmnz_wvdgopyb': 2984, 'avoid': 2985, 'lqvdoijm_yntmlehu': 2986, 'settle': 2987, 'negative': 2988, 'nzpfadir_swzpfnlj': 2989, 'tcbonyes_gpfacron': 2990, 'aztqelgy_fqnkuxvw': 2991, 'function.': 2992, 'rxuobtjg_grcmqaxd': 2993, 'gpdywmbt_pmxfiqkl': 2994, 'target': 2995, 'move.': 2996, 'kexcsbgw_lzabjxwf': 2997, 'exclusion': 2998, 'dxyvfuhr_uyfqgomx': 2999, 'operator': 3000, 'evolution': 3001, 'campaign': 3002, 'handy.': 3003, 'sept.': 3004, 'fecdszvm_ovtsxqnl': 3005, 'nobody': 3006, 'knabwtox_ksbzjdrn': 3007, 'wrongly': 3008, 'juqpaxry_ulqfbiog': 3009, 'awa': 3010, 'frtwncbv_yvxrspqo': 3011, 'browse': 3012, 'tfaweyjd_mdzrgxij': 3013, 'permit': 3014, 'ziwkespl_dyehbrst': 3015, 'ljyfsaox_paxockls': 3016, 'decide': 3017, 'vertical': 3018, 'tgseqfni_ehlabdtf': 3019, 'ifblxjmc_dyrgfwbm': 3020, 'vfuytnwp_fyzhntag': 3021, 'moment': 3022, 'mtgvfzwc_cdabfghv': 3023, 'continuously': 3024, 'fitness': 3025, 'digital': 3026, 'hire.': 3027, 'speaker': 3028, 'jrigdbox_bgyluoqn': 3029, 'uadkqcsj_xtmjlari': 3030, 'ware': 3031, 'plastic': 3032, 'portion': 3033, 'groove': 3034, 'public': 3035, 'lab': 3036, 'yzbqwpat_fdjrctbu': 3037, 'cabinet': 3038, 'mainly': 3039, 'acwoflmg_lvwmshcr': 3040, 'depreciation': 3041, 'gap': 3042, 'continue': 3043, 'qkprzfew_poliamdb': 3044, 'chart': 3045, 'thevrxbo_makhtjcu': 3046, 'visual': 3047, 'rmezbnqt_ntbmkpuh': 3048, 'uylomcrx_nfvjsgze': 3049, 'entire.': 3050, 'table': 3051, 'intern': 3052, 'cool': 3053, 'jiclynfv_gwvzxdcj': 3054, 'xzupryaf_vlbikhsm': 3055, 'viyglzfo_ajtfzpkb': 3056, 'gxibtzek_fgkpqjsb': 3057, 'bctypmjw_cbhnxafz': 3058, 'kuiglfqa_rwutnibm': 3059, 'janivrtg_hstolemu': 3060, 'swnjocmk_etpuhnwg': 3061, 'carrier.': 3062, 'kiosk': 3063, 'csyigtrb_gkvbjuto': 3064, 'guru': 3065, 'apply.': 3066, 'immediate': 3067, 'pzrskcon_pobsajnx': 3068, 'qwynjdbk_eamnvwyh': 3069, 'reimage.': 3070, 'nwhurdte_bldifgck': 3071, 'simulation': 3072, 'beacon': 3073, 'usage.': 3074, 'mtkpwcxz_vxouhram': 3075, 'attend': 3076, 'quadra': 3077, 'nwgcbfdt_ahmbnsoi': 3078, 'snap': 3079, 'rslvwpnh_emkfpqiy': 3080, 'sqlmtixr_urhbvfgd': 3081, 'qrnusygw_amiebrlf': 3082, 'except': 3083, 'nkiopevt_gufwhdky': 3084, 'cxfrvtyn_rapoejyb': 3085, 'kybgepnj_idszleru': 3086, 'jdlxkygf_wlzqaivr': 3087, 'e.': 3088, 'zslugaxq_dtwlrofu': 3089, 'benefit': 3090, 'solver': 3091, 'rvsbtxue_cdrwsymj': 3092, 'fhdgytup_oxugrqeb': 3093, 'brand': 3094, 'valid.': 3095, 'zevqkaxh_gkmohwdb': 3096, 'classification': 3097, 'irrespective': 3098, 'criterion': 3099, 'operation': 3100, 'wsimyhro_omhnjqbw': 3101, 'incident.': 3102, 'zlpdkqsw_jxabdocs': 3103, 'synchronization': 3104, 'enhancement': 3105, 'ihmbfeoy_exbgcfsk': 3106, 'wrxikemh_uqblenpc': 3107, 'quxwtbcr_imdwuhbz': 3108, 'kmubdazp_qmxwszko': 3109, 'njdrcagt_shourxyp': 3110, 'clean': 3111, 'pldtreob_fznbeusj': 3112, 'sam': 3113, 'buzz': 3114, 'xzwlnbfo_plstfydx': 3115, 'drill': 3116, 'pnwbkitv_phbnwmkl': 3117, 'utvpkdgi_oznqyvmp': 3118, 'subscribe': 3119, 'designation': 3120, 'elevate': 3121, 'bvlcarfe_aztlkeif': 3122, 'mason.': 3123, 'confirm.': 3124, 'welztypu_yseckbvf': 3125, 'pvbomqht_smfkuhwi': 3126, 'inquiry': 3127, 'importance': 3128, 'batsxwnl_ashkzvnr': 3129, 'icqleypr_kneoblzd': 3130, 'kcwqdeob_jwtpkzub': 3131, 'publish': 3132, 'bjrtfeyi_fuqapwtv': 3133, 'rjfmpgdq_outipdcm': 3134, 'tender': 3135, 'procurement': 3136, 'qalyeunp_eiyrcxog': 3137, 'symieovf_tjrwmcfg': 3138, 'associate': 3139, 'fully': 3140, 'acceptance': 3141, 'hsbfiako_iylbrwpa': 3142, 'knlrgsiv_cqvuexjz': 3143, 'reactivation': 3144, 'xidbvzsk_yrlsnxio': 3145, 'yzugpdco_nsyapewg': 3146, 'uaclgmeq_hyxzmwdi': 3147, 'hang': 3148, 'mount': 3149, 'fulfill.': 3150, 'kxcawjet_xmybdwfh': 3151, 'es.': 3152, 'lrhfoxen_hlqsumgx': 3153, 'svhuewoy_dluchbfg': 3154, 'aiprzulo_lzvmgqwy': 3155, 'hope': 3156, 'eirkpyfv_zdipasul': 3157, 'gar.': 3158, 'efjzbtcm_mdpviqbf': 3159, 'solution.': 3160, 'rtpcnyhq_ceqmwkhi': 3161, 'explore.': 3162, 'ydgasebx_ceuyrjhs': 3163, 'qdztknml_hpcxnyrq': 3164, 'shake': 3165, 'ybxsujwi_yzwanorl': 3166, 'hell': 3167, 'bob': 3168, 'pgacouel_mpgfkxwr': 3169, 'distance': 3170, 'cad.': 3171, 'wsboedtj_yvlswgxb': 3172, 'izhyoqms_wecyhadn': 3173, 'sitmzuje_ckrpsabm': 3174, 'hot': 3175, 'spot': 3176, 'sanoibgk_zpuawcbl': 3177, 'vpksyfco_chosuygq': 3178, 'ey': 3179, 'proceed.': 3180, 'originally': 3181, 'nehxmtpg_xepltzqf': 3182, 'staff': 3183, 'clarification': 3184, 'dntxagwc_whfdqxcs': 3185, 'urgapyzt_tnxiuram': 3186, 'cutter': 3187, 'ovxrzwac_clhxuzgy': 3188, 'vacation': 3189, 'latitude.': 3190, 'amount.': 3191, 'ukqoiswv_unjarfoq': 3192, 'gfjqrsxz_bcyhezsl': 3193, 'qpkbiwzl_urypnjvq': 3194, 'okycwstu_tvrnbgfs': 3195, 'village': 3196, 'outlet': 3197, 'ugyawsjv_ypgjirlm': 3198, 'difozlav_dgbfptos': 3199, 'remotely.': 3200, 'department.': 3201, 'mfrsgwnk_wremyjlo': 3202, 'hence': 3203, 'xyculgav_cuqptoah': 3204, 'bixvmnar_glakoprc': 3205, 'jvshydix_rzpmnylt': 3206, 'boot.': 3207, 'response.': 3208, 'determine': 3209, 'jgmlbxns_pxjsdwrk': 3210, 'cluster': 3211, 'correct.': 3212, 'gvdkupew_waphsuen': 3213, 'truck': 3214, 'apparently': 3215, 'aeiljfxg_hzwxtyjr': 3216, 'plfwoagd_chtpiazu': 3217, 'kpogxqvn_sfzjbhet': 3218, 'font.': 3219, 'ovxwqybe_gevzkrlp': 3220, 'psbulrdt_jxkvzmnf': 3221, 'recur': 3222, 'invalid': 3223, 'incompletion': 3224, 'without.': 3225, 'hoi': 3226, 'ugtzkvps_crnmtjsv': 3227, 'anybody': 3228, 'revenue.': 3229, 'phfduvwl_yqnaucep': 3230, 'csmhykge_mpxbjudw': 3231, 'pxcvrjfq_wkdaevfn': 3232, 'excessive': 3233, 'length': 3234, 'txinpadm_dluxikjn': 3235, 'present': 3236, 'compatible.': 3237, 'least.': 3238, 'cwhyboek_axljywpf': 3239, 'mzdkgnvs_svhkgyqb': 3240, 'carry': 3241, 'whomever': 3242, 'folder.': 3243, 'jobxpkrg_klonypzr': 3244, 'ulroqsyf_wctpnarb': 3245, 'den.': 3246, 'externe.': 3247, 'edspmloy_fxnkzaqu': 3248, 'dot': 3249, 'inbound': 3250, 'inspection': 3251, 'pofkwlui_joteryma': 3252, 'efficiency': 3253, 'column.': 3254, 'entuakhp_xrnhtdmk': 3255, 'rob': 3256, 'ripple.': 3257, 'eastern.': 3258, 'sgaczfvo_wxmkrzfu': 3259, 'wherein': 3260, 'hjkyqecw_ixdsbwoz': 3261, 'mass': 3262, 'duplicate.': 3263, 'shloyakw_jztsxdln': 3264, 'side.': 3265, 'jcdewsuv_mdipqhzx': 3266, 'ujtmipzv_cwdzunxs': 3267, 'owhuxbnf_sxbgyrou': 3268, 'vice': 3269, 'president': 3270, 'segment.': 3271, 'tivbxojn_gorlajmp': 3272, 'raosetuv_hmgwrkzb': 3273, 'else': 3274, 'xosdfhbu_gtbfkisl': 3275, 'cartridge': 3276, 'ipqgrnxk_acxedqjm': 3277, 'avkotjzx_hmntobws': 3278, 'jxpmkhay_ruvnpyqb': 3279, 'uagqromi_sqgtkmci': 3280, 'reinstallation': 3281, 'jrxsdcna_iyhktobe': 3282, 'lunch': 3283, 'south.': 3284, 'white': 3285, 'ufixygtn_yuoxcmek': 3286, 'wrelsfqa_qfwosjkh': 3287, 'qjiutmel_fgvtxeoy': 3288, 'josh': 3289, 'anpwcmdh_tjsgualn': 3290, 'te.': 3291, 'pjrhqkne_ewruqyds': 3292, 'core': 3293, 'cube': 3294, 'dsyzveju_ivmprauh': 3295, 'damage': 3296, 'correlation': 3297, 'rule': 3298, 'erase': 3299, 'shpnkgir_mpsycbxl': 3300, 'assembly': 3301, 'place': 3302, 'presently': 3303, 'cyxzfvtj_yklmvqxf': 3304, 'minute': 3305, 'identify': 3306, 'specific.': 3307, 'mabstwkd_ytmuwicv': 3308, 'obqridjk_ugelctsz': 3309, 'hgrvubzo_wgyhktic': 3310, 'odfimpjg_ptfoiake': 3311, 'tbloeczi_gxlmeyph': 3312, 'zifujpvr_vxfkwaqh': 3313, 'xovczlad_fkicawph': 3314, 'jpufgorh_xltfrpcy': 3315, 'chkzbeav_ykeilmog': 3316, 'random': 3317, 'unsaved': 3318, 'nwdlefxk_epzrghnv': 3319, 'tomorrow.': 3320, 'cgvhxjay_znyuopqk': 3321, 'successful': 3322, 'carbide.': 3323, 'nwbhomqe_ejavblzu': 3324, 'division': 3325, 'aiobpkzm_rmfjwtpl': 3326, 'beosjgxt_mdevcqjk': 3327, 'manual': 3328, 'condition.': 3329, 'kebogxzp_difnjlkp': 3330, 'umzcxfah_aoshpjiu': 3331, 'aqstdryv_flbnyqzc': 3332, 'heat': 3333, 'jborwynt_gidxbfrq': 3334, 'imoelsap_gxdwkimv': 3335, 'hefiuwvo_lcgadsef': 3336, 'reflect': 3337, 'owtlmpuv_oicrjsfh': 3338, 'live': 3339, 'jycshmvf_uewramti': 3340, 'bitdmacs_kumdiywz': 3341, 'hmnuiltc_cqpzgvym': 3342, 'badge': 3343, 'active.': 3344, 'station.': 3345, 'dglwxfzu_sgbnpvql': 3346, 'vmeljsfb_ymxejsbd': 3347, 'retrieve.': 3348, 'jkelxorm_uwqjlzfm': 3349, 'steel.': 3350, 'rvdtagmf_klbnhydo': 3351, 'vbmzgsdk_jdmyazti': 3352, 'global.': 3353, 'fence': 3354, 'toolroom': 3355, 'documentation.': 3356, 'bkscnoqz_umaojbci': 3357, 'retrieve': 3358, 'hjokrfpv_fhpaxsqc': 3359, 'suddenly.': 3360, 'ydigzqbu_xdgjizek': 3361, 'instrument': 3362, 'turn.': 3363, 'supply.': 3364, 'na.': 3365, 'ijplstng_juybetlo': 3366, 'raid': 3367, 'zbhfrsto_vhgtoxib': 3368, 'kglnimxw_nhdqaupz': 3369, 'szockfpj_izohlgcq': 3370, 'reprint': 3371, 'hone': 3372, 'equipment': 3373, 'vtwxaefm_ljisafue': 3374, 'uyhceqzr_tpbdwiyv': 3375, 'uaeqlxro_rzsdalyc': 3376, 'hjcpyxtq_okycpbsz': 3377, 'osjqfbvw_hlmgrfpx': 3378, 'snkeuizv_gsjndfuk': 3379, 'mysterious': 3380, 'qxhdcnmj_caflvjrn': 3381, 'sponsor.': 3382, 'thesis': 3383, 'pkjhmfgc_zuvjqgwa': 3384, 'mgahlpwx_jwtfpaxh': 3385, 'require.': 3386, 'investor': 3387, 'relation': 3388, 'bqjvxsaf_aupdonjy': 3389, 'totally': 3390, 'cubicle': 3391, 'wish': 3392, 'eh.': 3393, 'poor.': 3394, 'whavkycs_unihdlfy': 3395, 'actual': 3396, 'life': 3397, 'rubber': 3398, 'kauozcir_jlyqxise': 3399, 'safety': 3400, 'dmqxwkfr_olmwqzpu': 3401, 'allow.': 3402, 'developer': 3403, 'unbale': 3404, 'clyauqjw_cxwrsflt': 3405, 'o.': 3406, 'jmrukcfq_rdyuxomp': 3407, 'zlnfpuam_aktplhre': 3408, 'mae': 3409, 'vmthcrkf_iceyusnd': 3410, 'relevant': 3411, 'anyway.': 3412, 'zqpyrxsn_zihmunyb': 3413, 'sur': 3414, 'surname': 3415, 'hnkwirgv_wdgebvpz': 3416, 'slubnjry_qcrabvoe': 3417, 'nozahtbr_ubznqpsy': 3418, 'cam': 3419, 'sidecar': 3420, 'onvpjxei_uiolhpjq': 3421, 'gel.': 3422, 'presentation': 3423, 'fiber': 3424, 'hqyfebtd_pkmyrdga': 3425, 'unknown': 3426, 'wohzmlib_fxwjhapo': 3427, 'dank': 3428, 'possibility': 3429, 'spend': 3430, 'xabkyoug_wdkyiqfx': 3431, 'wxievyng_lfecyzik': 3432, 'pen': 3433, 'administration.': 3434, 'srpkmdcg_skdubtnr': 3435, 'yjcrdmin_jmizcfso': 3436, 'accidentally.': 3437, 'qcxivzag_vyucbagx': 3438, 'security.': 3439, 'paternoster': 3440, 'grus.': 3441, 'remotely': 3442, 'qtiyzjaw_rxtpbqvu': 3443, 'lbqgystk_uezmfhsn': 3444, 'axesnghb_cyzuomxa': 3445, 'nil': 3446, 'sepbdtou_noredzyx': 3447, 'shutdown': 3448, 'prepare': 3449, 'ufesrwmz_egujslwx': 3450, 'till.': 3451, 'aymgdoqt_eoxphqas': 3452, 'oxrnpuys_oxizkwmq': 3453, 'lager.': 3454, 'qnigujek_kopqcjdh': 3455, 'spindle': 3456, 'yxliakph_soucfnqe': 3457, 'hygiajzb_ajvmhbsr': 3458, 'unfortunately': 3459, 'wcupoaty_fqnzwphj': 3460, 'lance': 3461, 'sagfvdeb_kfqtvgxl': 3462, 'anivdcor_rbmfhiox': 3463, 'lynrwzfj_fvijyeta': 3464, 'integrity.': 3465, 'cysbkonu_mzutvwir': 3466, 'cord': 3467, 'suspect': 3468, 'tqrylspg_ijzghqwy': 3469, 'migration.': 3470, 'erratum': 3471, 'liedzaft_lvnbzktj': 3472, 'brjkmwvo_odxwcpie': 3473, 'accident': 3474, 'hinge': 3475, 'accidental': 3476, 'fell': 3477, 'flight': 3478, 'photo.': 3479, 'jtqaplhs_yjmpiqcu': 3480, 'momentarily': 3481, 'qulnmvxa_gznxlcts': 3482, 'null.': 3483, 'tzrekwqf_homwadbs': 3484, 'kmtpzyre_mqlsfkre': 3485, 'dead': 3486, 'nyrjkctu_tbhkenlo': 3487, 'welcome.': 3488, 'wjzvabrl_bmcfrlyz': 3489, 'ti': 3490, 'inactive.': 3491, 'fduinmtw_yofhirjs': 3492, 'bzekndcu_ivhnpdbu': 3493, 'ifsrenpq_lkembgtd': 3494, 'pahdlbnw_nycrtsom': 3495, 'wphqnxly_htvrbxmd': 3496, 'yucgfmiq_jamgpnqe': 3497, 'locky': 3498, 'zscohabw_qorvugzf': 3499, 'tlowkghn_jcefuzit': 3500, 'outside.': 3501, 'roanoke': 3502, 'reachable': 3503, 'restore.': 3504, 'bxspwfyo_vzystwor': 3505, 'graphic': 3506, 'enhance': 3507, 'decision': 3508, 'mobile.': 3509, 'gdnwlkit_jokidavy': 3510, 'keinyujo_torvxeda': 3511, 'distributor.': 3512, 'sprzgqyv_uxpjtgaw': 3513, 'vxzahrlc_frtkpehy': 3514, 'loud': 3515, 'noise.': 3516, 'visitor': 3517, 'conversation.': 3518, 'wait': 3519, 'mdbegvct_dbvichlg': 3520, 'hub.': 3521, 'dynamic': 3522, 'tqpbazxm_jhbkycgd': 3523, 'eqzibjhw_ymebpoih': 3524, 'qftpazns_fxpnytmk': 3525, 'xtqbjieu_uablitwr': 3526, 'gaiopkun_bvcdpxrt': 3527, 'curser': 3528, 'obsolete': 3529, 'lenxvcbq_vwnhjtoi': 3530, 'membership': 3531, 'mathes': 3532, 'waekugzo_dwzfghqo': 3533, 'qdtywmkv_aolijwnx': 3534, 'stage.': 3535, 'yrwvnsxq_wqlfarny': 3536, 'nvawmlch_ubyjolnc': 3537, 'pvjdtrya_oevyhtdx': 3538, 'inlet': 3539, 'ambient': 3540, 'spdczoth_vajtodny': 3541, 'could.': 3542, 'youfzmgp_xvysrnmb': 3543, 'within.': 3544, 'jypowefv_yzgsldrx': 3545, 'wqybuifo_qlwfajcb': 3546, 'hratikvm_sbwefglc': 3547, 'bright': 3548, 'sensor': 3549, 'allocate': 3550, 'outdated.': 3551, 'otlqwuks_bncsierm': 3552, 'xyoiutep_znpegflv': 3553, 'ioafmupg_gnmqfrve': 3554, 'mjvfxnka_zvjxuahe': 3555, 'correction': 3556, 'ploxzuts_utvimnwo': 3557, 'qksrtvzb_vjkftuai': 3558, 'continually': 3559, 'fgaulydz_crswlkev': 3560, 'zdcheloy_aevzsogn': 3561, 'proxy.': 3562, 'vuxdrbng_owqplduj': 3563, 'sbvlxuwm_yanbikrx': 3564, 'switch.': 3565, 'unfreeze': 3566, 'target.': 3567, 'product.': 3568, 'qdilorms_feayhdmu': 3569, 'tkhaymqg_cwuqzyvm': 3570, 'tavsikpl_dcrkwuny': 3571, 'huge': 3572, 'different.': 3573, 'mi': 3574, 'frequently': 3575, 'xgcnzwsh_rwyctfzk': 3576, 'furnace': 3577, 'mask': 3578, 'supplier.': 3579, 'dfiyvmec_wxioadpt': 3580, 'cold.': 3581, 'six.': 3582, 'kmbfhyxi_cuwgmiop': 3583, 'yszdlwph_kwvtrjxm': 3584, 'cudgevmx_waqslrbd': 3585, 'retrieval': 3586, 'pol': 3587, 'munxvfhw_texsbopi': 3588, 'date.': 3589, 'shjbrutf_iknuqswm': 3590, 'xnzfsmue_kwsazpeu': 3591, 'qohfjpna_exphkims': 3592, 'xpmgtlcq_ksaefihz': 3593, 'virus.': 3594, 'ging.': 3595, 'whykbjdq_gfqlnysm': 3596, 'tha': 3597, 'hardness': 3598, 'dymwulbi_dkbvqhna': 3599, 'qhvspezr_fvluqczd': 3600, 'unrestricted': 3601, 'fdqjsygx_aivdjqtr': 3602, 'ecwtrjnq_jpecxuty': 3603, 'exploit': 3604, 'nvxkdqfi_slkojtcg': 3605, 'thank': 3606, 'nxlzpgfr_rlqowmyt': 3607, 'traffic.': 3608, 'project.': 3609, 'svuxjkpg_tpurnjvi': 3610, 'wjbtlxry_gdbqzjyw': 3611, 'increase': 3612, 'wnicojsd_evwplcxy': 3613, 'stand': 3614, 'tablet.': 3615, 'script': 3616, 'unexpected': 3617, 'telephonic': 3618, 'hook': 3619, 'microscope': 3620, 'qfgtalec_mwpqfbxk': 3621, 'rlgmiuwt_dfpqxbgm': 3622, 'rcvyfkzo_hstgdfyx': 3623, 'import.': 3624, 'nlrfzxsd_ecibvgxr': 3625, 'let.': 3626, 'kbdljsxf_kcmqtjgf': 3627, 'ndsyovil_pymzvdqa': 3628, 'tomorrow': 3629, 'yiramjqc_qtrcepsa': 3630, 'mobility': 3631, 'luxdnsvk_qmnyzcfs': 3632, 'senior': 3633, 'fueiklyv_jargqpkm': 3634, 'krynlisw_dqfeglkc': 3635, 'afplnyxb_eiomnuba': 3636, 'elixsfvu_pxwbjofl': 3637, 'qicmfaoe_hdrysife': 3638, 'pay.': 3639, 'wrdmxloh_dshplynj': 3640, 'oiudarbk_ezhnjwdt': 3641, 'ztrpuvdf_jlahkmdv': 3642, 'synch': 3643, 'iygsxftl_hysrbgad': 3644, 'fcpnodsr_nbrdxscg': 3645, 'eflahbxn_ltdgrvkz': 3646, 'djlpawmc_nyzwqofu': 3647, 'upcgxthj_lnsvemxy': 3648, 'encryption': 3649, 'wbtrvdsi_gdbuvszx': 3650, 'qaohugxw_kdeqjncw': 3651, 'ypuaejsc_yoxrqtsn': 3652, 'obanjrhg_rnafleys': 3653, 'epivntxc_fdrxmuga': 3654, 'launch.': 3655, 'aguxobqs_upgtdafh': 3656, 'aqjdvexo_lmedazjo': 3657, 'jnktafrs_ytxiowbh': 3658, 'android': 3659, 'uajiymhe_qyrwfkvz': 3660, 'vupmctne_ylnsweao': 3661, 'close.': 3662, 'hzagqxbf_fckwrsdq': 3663, 'hvgdafke_mnowgefz': 3664, 'dynamic.': 3665, 'question': 3666, 'snip': 3667, 'irqpwgtn_dpautgeh': 3668, 'ewvugfcy_nxbdajgh': 3669, 'rjsulvat_uanigkqc': 3670, 'font': 3671, 'icon': 3672, 'gbwviklo_ukwijqtm': 3673, 'zylaexnv_pvkzbduh': 3674, 'incoming': 3675, 'crjhotyk_pxslorbe': 3676, 'peuckbvr_tjihmgsv': 3677, 'irpvzhym_kayqlbuh': 3678, 'hduzwpio_wrcgunso': 3679, 'fpbmtxei_jtqbcnfs': 3680, 'brhlcpqv_sfozwkyx': 3681, 'udetjzmn_ayueswcm': 3682, 'validate': 3683, 'jcxwgslk_szvgufir': 3684, 'nesmdkpr_dcaqoxsy': 3685, 'vxhyftae_tbkyfdli': 3686, 'delete.': 3687, 'gcaktshf_kpgfrotd': 3688, 'zxobmreq_udikorhv': 3689, 'vkpwnqay_rmwxqoba': 3690, 'aeophctw_nvjyhizu': 3691, 'ftnijxup_sbltduco': 3692, 'hzetqwba_tmsbnfkh': 3693, 'indicate': 3694, 'block.': 3695, 'junior': 3696, 'gvderpbx_udrzjxkm': 3697, 'stvpxkbf_gqchobaj': 3698, 'qekdgaim_wagshrzl': 3699, 'respond': 3700, 'shift': 3701, 'uvjpaeli_bnphqsxr': 3702, 'ptljghyk_qhtvlrxe': 3703, 'zywoxerf_paqxtrfk': 3704, 'kvqtzayg_ehjrviak': 3705, 'dskcobqa_tujrvsbc': 3706, 'xmunoklw_bnmswalv': 3707, 'oebrjdqc_nhuqmskw': 3708, 'gbirhjat_fptbrhwv': 3709, 'cell.': 3710, 'lockout.': 3711, 'giumxwvh_lfvwjtin': 3712, 'mtcywlxv_cklzmxyr': 3713, 'zdnqowag_cdtyonhw': 3714, 'unchecked': 3715, 'ave': 3716, 'trunk': 3717, 'entire': 3718, 'mention': 3719, 'bcaxeuvh_rgiqfavb': 3720, 'gjbcengineering_tooll_gidsekfo': 3721, 'difficulty': 3722, 'ykcvjwax_cfigbjuo': 3723, 'toll': 3724, 'mo.': 3725, 'validation': 3726, 'latency': 3727, 'ti.': 3728, 'canada': 3729, 'authenticate': 3730, 'soap': 3731, 'rxoluzhy_pnutohms': 3732, 'router.': 3733, 'barcelona': 3734, 'whose': 3735, 'notebook': 3736, 'kvtchbus_tqrehbsd': 3737, 'un': 3738, 'eqcudbks_zbjeqruy': 3739, 'door.': 3740, 'nrbgctwm_kfwdhrmt': 3741, 'djilqgmw_bidchqsg': 3742, 'director.': 3743, 'mqzirjkb_umbgreyq': 3744, 'apologize': 3745, 'mechanic': 3746, 'lap': 3747, 'surely': 3748, 'sorry.': 3749, 'queue': 3750, 'refinery': 3751, 'rxpjomyf_hvolsgqn': 3752, 'mailer.': 3753, 'spoof': 3754, 'hqbxstoy_mdjftxli': 3755, 'ivohcdpw_ixcanwbm': 3756, 'kreis': 3757, 'byltiakh_vinqkxzm': 3758, 'dial': 3759, 'certificate.': 3760, 'vgatnfjl_sghcfzqp': 3761, 'urwqxgdp_twepkmis': 3762, 'zkgfcyvx_sgxeatyb': 3763, 'keqldvig_hmiyeobl': 3764, 'leaf.': 3765, 'ktsulemz_wsgoykba': 3766, 'lixwgnto_krutnylz': 3767, 'fgehvwxb_ckxegsqv': 3768, 'lzapwbnc_yrjekzqv': 3769, 'rkimfqta_oepigwmr': 3770, 'rzglsoma_qkjfwmnz': 3771, 'acrobat': 3772, 'aetvprsf_ewmcrqja': 3773, 'policy': 3774, 'sheet': 3775, 'xklpahsd_nyxtoazm': 3776, 'buyer.': 3777, 'gkerqucv_bqumyrea': 3778, 'ioulqtmk_dqevzrsg': 3779, 'xgjkafcn_uijphdyx': 3780, 'pstlrmvf_jokbeqnp': 3781, 'ylfqrzxg_jmakitug': 3782, 'gzqijaoc_rfywvloa': 3783, 'serckxqb_mljnkgze': 3784, 'eligibility': 3785, 'smhepfdn_aypgzieh': 3786, 'svuboezf_wegtszum': 3787, 'sayrmutj_txwhimlj': 3788, 'savin.': 3789, 'dzrbwhco_frmhpwda': 3790, 'exchange.': 3791, 'hourly': 3792, 'appropriate': 3793, 'eruzljih_epclbgmi': 3794, 'peojqgvm_qayeptuo': 3795, 'prompt': 3796, 'unauthorized.': 3797, 'yxsermtd_vloueirh': 3798, 'bkzcfmse_naslrwdb': 3799, 'cache.': 3800, 'insbceoa_czgpyrtb': 3801, 'qbevnaot_shrqicog': 3802, 'portfolio': 3803, 'zlnxswvp_ptmzsbhk': 3804, 'utrvshcp_bjlwcovt': 3805, 'gljrdmnu_yfnbkcmp': 3806, 'soon.': 3807, 'wpdxlbhz_etvzjmhx': 3808, 'cmplfihy_tajmzhfl': 3809, 'unblock': 3810, 'gest': 3811, 'jxlekivs_fwakmztv': 3812, 'mohryldw_meutqjzy': 3813, 'xwzstlgj_tzkbmgan': 3814, 'aytjedki_rucfxpla': 3815, 'nbcyhjxg_czawdryt': 3816, 'svmkobqj_sgqtdubv': 3817, 'rzikhjae_tzekbfjx': 3818, 'itjzudor_ybtmorxp': 3819, 'sndaofyw_jetcxpda': 3820, 'bmhrsxlf_ukatbwyi': 3821, 'cpsybwla_snymigat': 3822, 'wireless.': 3823, 'olzsuean_sojwhbrv': 3824, 'oefitbmy_gcubyszd': 3825, 'przcxbml_vnjdghui': 3826, 'afbcmwsu_tjgciswl': 3827, 'pdvrieys_wxvsltia': 3828, 'wzbqmhdf_gxsiadqw': 3829, 'night.': 3830, 'rmxqfivn_pfgcirlh': 3831, 'michigan.': 3832, 'ixwymcbz_yxmoihjg': 3833, 'vtbqgwnk_tamfbgjy': 3834, 'jacgtfxo_vlbeuxif': 3835, 'next.': 3836, 'rmzlvqjf_eaqyxljb': 3837, 'then.': 3838, 'shkwgxln_ikpvtjgn': 3839, 'assume.': 3840, 'uijxpazn_gvtzlphs': 3841, 'qufjnslk_bvtfrwnu': 3842, 'facrghdv_velfjros': 3843, 'nmftrwvi_rchywvmz': 3844, 'alfqhigv_zofjibkr': 3845, 'pojhkxua_frpxtsca': 3846, 'mhxzdygu_qwdjfgbl': 3847, 'psikzmba_stumdcqp': 3848, 'fdbgoamk_hygxzkla': 3849, 'fpedscxo_acuvyqnx': 3850, 'unfortunate': 3851, 'cuzhydjl_fugwxdqh': 3852, 'page.': 3853, 'usdhpatm_icgmphjk': 3854, 'town': 3855, 'adgvefwp_dwasygtb': 3856, 'xyiktbla_gralexfc': 3857, 'lduqxywt_wcydjgvl': 3858, 'kjeqxayu_bpwkdazl': 3859, 'educate': 3860, 'afijkocw_rjtxslpa': 3861, 'vgtpkjhn_flwsytik': 3862, 'lsnpgqea_hzeausvl': 3863, 'ne': 3864, 'thema': 3865, 'nizholae_bjnqikym': 3866, 'vazmgjxu_nmsycblo': 3867, 'particular.': 3868, 'iwqjyzph_nhmjyzrw': 3869, 'qdgcilzf_cpzlmesa': 3870, 'around.': 3871, 'btuqmzvs_wscahikd': 3872, 'rstjupxe_yjlgsiah': 3873, 'hajworze_jqpisura': 3874, 'deaokmqp_oruitnmx': 3875, 'seep': 3876, 'fourth': 3877, 'dismypxe_zkwcmgsr': 3878, 'grade.': 3879, 'zrbxcndu_lxrsoenp': 3880, 'wipzvlug_urmdkgpa': 3881, 'adobe.': 3882, 'jdeoycaq_geqctmlh': 3883, 'wbilvncd_idavhsxy': 3884, 'reopen.': 3885, 'fragmentation': 3886, 'similar.': 3887, 'phqgtfbn_lzdntwpr': 3888, 'fsvnjexu_yxaevupi': 3889, 'vyjmlain_hvjbmdgi': 3890, 'jsmhzqpo_bpexofya': 3891, 'there.': 3892, 'kpnzvsuw_lwmqyjbv': 3893, 'kzbrimwx_dconpwbu': 3894, 'lxgtvwyh_jnkchfap': 3895, 'jhxwiply_midhcnze': 3896, 'qoiyjcah_zxevofwn': 3897, 'iowkrcpd_snrvlhyc': 3898, 'ubdihsop_ahyeqpmx': 3899, 'ebkfwhgt_flapokym': 3900, 'mcysxfjw_pcrdoewx': 3901, 'qmgspxkf_mckfysdh': 3902, 'iewnguxv_bufwxeiy': 3903, 'pvtiqgsh_orlzgfsx': 3904, 'ynsqjehx_kqgrsawl': 3905, 'nkademwy_ihsepkwz': 3906, 'xgtyasdp_xniowugc': 3907, 'hit': 3908, 'gduilrqe_oxrivnwe': 3909, 'hcplzsxg_qkujnapl': 3910, 'kbcedtiq_jxnzpgwe': 3911, 'xkisaybg_fykpoxhu': 3912, 'wyxqkzmf_urigtqnp': 3913, 'envoy': 3914, 'capture': 3915, 'orvsydzf_rbqtpdaz': 3916, 'efmzltnx_uehqbaxo': 3917, 'undeliverable': 3918, 'pdujfybc_bvfdnale': 3919, 'tvirflky_febluink': 3920, 'iczltbdf_cmvjhyxl': 3921, 'visit': 3922, 'jcfignaz_tyguzslr': 3923, 'tfnzwycd_bicohjga': 3924, 'luagmhds_iymwcelx': 3925, 'balance.': 3926, 'dnlhsgyo_newducsl': 3927, 'vomtbcej_lyiwqrct': 3928, 'rhwvpmlq_zuwhpqrc': 3929, 'mtgujlcb_kczyvpqr': 3930, 'hawrkqnp_sjwrgakp': 3931, 'ockwafib_wftboqry': 3932, 'vjwdyanl_knfsjdgz': 3933, 'sdvlxbfe_ptnahjkw': 3934, 'forget.': 3935, 'miss.': 3936, 'hpeknoam_yrfowmva': 3937, 'ribbon': 3938, 'player.': 3939, 'xzbhmfpg_bhqxesym': 3940, 'jwoiyzfp_zlftrkpq': 3941, 'weaver': 3942, 'saqbgcpl_ybfzcjiq': 3943, 'oybwdsgx_oxyhwrfz': 3944, 'specify': 3945, 'those': 3946, 'gmneclxj_czqthmrs': 3947, 'zcyueotq_ehvpaqnf': 3948, 'flyqjavm_knlzewqs': 3949, 'srqyfjxz_lnagtjzi': 3950, 'authentication.': 3951, 'gcdptqae_angojbil': 3952, 'sjhrytwn_yakzbslm': 3953, 'icyxtqej_lqsjrgzt': 3954, 'qyfrgeop_loimdzgs': 3955, 'xeocpjsu_hqwxumfb': 3956, 'uskydftv_sgwbfkjz': 3957, 'unlook': 3958, 'nsoikcyf_jhybqael': 3959, 'unplanned': 3960, 'lyfrphmz_ahidnfmb': 3961, 'pjkmtfeg_wnrcyaks': 3962, 'nhjpxoct_ewngozhx': 3963, 'dxtulsik_xizungmt': 3964, 'intelligence': 3965, 'lid': 3966, 'xpugzdvk_xiawvmfp': 3967, 'badnzyue_nxuqmdwl': 3968, 'mfkvlxph_bodikqcx': 3969, 'owlgqjme_qhcozdfx': 3970, 'clue': 3971, 'bar': 3972, 'mpvasqwy_rotkyeja': 3973, 'tqemuawj_mvcqrbaz': 3974, 'wjbanovh_mohgutiw': 3975, 'weupycai_epqhduro': 3976, 'qmglkaru_qiwhfkdv': 3977, 'invite': 3978, 'zhpwcdea_cboefuis': 3979, 'fjetbklw_oeuawsbq': 3980, 'zmnhfcbv_azdnkmul': 3981, 'current.': 3982, 'pblitjvq_yqpjcfgx': 3983, 'zolnubvq_ehrqifxp': 3984, 'xbjrphgk_unbzmyhk': 3985, 'impact.': 3986, 'dwflzqyn_uinpgbym': 3987, 'bcxfhekz_bplfrnis': 3988, 'mdrguhox_qczwadyx': 3989, 'supervisor.': 3990, 'bihfazru_bhjqvtzm': 3991, 'zgdvhfop_kbrmfcog': 3992, 'wcnfvajb_kxylsamv': 3993, 'vsiemxgh_lgeciroy': 3994, 'yawbtfjc_krypjxnd': 3995, 'windy': 3996, 'add.': 3997, 'expiry.': 3998, 'seutrkhn_jvdtilek': 3999, 'say.': 4000, 'gpevdzct_txconyhd': 4001, 'xhjmzyis_bsduwrix': 4002, 'inconsistent': 4003, 'dcsaiweo_qvstjlem': 4004, 'sdlixwmb_zvygmnco': 4005, 'mrczxwje_ocasryzq': 4006, 'iqmhjlwr_jqmxaybi': 4007, 'rtjwbuev_gfpwdetq': 4008, 'qjfgkvln_wzbngayp': 4009, 'outgo': 4010, 'jusenflm_sufbehom': 4011, 'nyjvwsxf_npwoglzf': 4012, 'ldgyxbrm_cdporkfj': 4013, 'contract.': 4014, 'xwlcqfsr_lbcqfnie': 4015, 'fatal.': 4016, 'nyscufdq_wjtcsahz': 4017, 'against.': 4018, 'hctduems_znalhivf': 4019, 'tjlizqgc_ngvwoukp': 4020, 'flhkxeqd_gwidroap': 4021, 'wmsaxylo_tyqgpkxz': 4022, 'tzradpnj_izlotycb': 4023, 'msarjyhi_fpxdbeno': 4024, 'gzhjstxr_mdnsfipg': 4025, 'himself': 4026, 'insurance': 4027, 'gxvhauic_zogmauli': 4028, 'ahead': 4029, 'zrcfyiea_gynbmopr': 4030, 'sponsor': 4031, 'yhroaeqj_djtyroha': 4032, 'apylmhrq_gyncwpim': 4033, 'rcfwnpbi_kvhedyrc': 4034, 'ever': 4035, 'qpbwfvdm_ytlnodrv': 4036, 'dmqjhrso_gzbunwie': 4037, 'tfzlohik_esibqtvy': 4038, 'ueqoimkc_mhqyzklv': 4039, 'invite.': 4040, 'rvdwyapu_fubjamlr': 4041, 'rcmziuob_xhblozqe': 4042, 'recjqtbg_xcyuetmj': 4043, 'itslpwra_vybdkuoa': 4044, 'vmbltjsf_gwryhfbe': 4045, 'ikgrtwhz_tmqdiwge': 4046, 'ohnimgtv_nmqyuolh': 4047, 'crqonkxm_ipyazqjx': 4048, 'speak': 4049, 'ciszbkoh_xozqjavr': 4050, 'jyzkbgpm_vxmjcbdw': 4051, 'wsxhlagq_rqejbwfu': 4052, 'yhzdtkla_ncobgtdm': 4053, 'ctepaurs_igrazhwo': 4054, 'chance': 4055, 'gvsabjhq_cgwsbiep': 4056, 'rep.': 4057, 'idkfgcnq_vjwhmzor': 4058, 'yrzvhbic_rechmoiy': 4059, 'vxlymbpz_tysnumva': 4060, 'dchzofyt_kecxjvwq': 4061, 'dalhjmcn_fisvztuy': 4062, 'legitimate': 4063, 'scam.': 4064, 'zjkqxsye_bcsdlfuj': 4065, 'zehrwlbt_sdyltvnp': 4066, 'qnvkwalx_dfjtxigl': 4067, 'arsbtkvd_qieagkos': 4068, 'entry.': 4069, 'yabnljgs_cjlgetqz': 4070, 'chrome': 4071, 'snapshot.': 4072, 'watch': 4073, 'wvaksnpy_vnixhytj': 4074, 'ubqiygva_zdkfxyel': 4075, 'bgohnwer_ybinfojr': 4076, 'gvktqfrj_uawjnfel': 4077, 'lbtverxc_ymgljuqn': 4078, 'savwzktn_huqxbfot': 4079, 'oxkghdbr_dsyvalof': 4080, 'ayktfvjr_soghziec': 4081, 'bujghvne_cnpdhfmi': 4082, 'worry': 4083, 'utdlmzyb_dvfpraeg': 4084, 'yvfrgiba_kezghiqa': 4085, 'phvgbire_ekbhqcap': 4086, 'kingdom.': 4087, 'tgynoqcs_uxfyzrma': 4088, 'regular': 4089, 'oebcqfli_zvbxasky': 4090, 'sxhcapoe_kbluefip': 4091, 'efulzico_epgfbhmt': 4092, 'configuration.': 4093, 'kzjtvbaf_nskfwlvo': 4094, 'synchronize': 4095, 'lzycofut_mzbovhpd': 4096, 'wrlzneit_ayqutwgh': 4097, 'insurance.': 4098, 'ahuztyxg_zlrwshfb': 4099, 'plqbesvo_uopaexic': 4100, 'zpsoifea_wvhilrpz': 4101, 'jnlzsubr_cfgustlo': 4102, 'wcrbmgon_kcudbnrw': 4103, 'hold': 4104, 'music': 4105, 'virus': 4106, 'lomzfqns_htznsgdf': 4107, 'nritedlm_ihaufdol': 4108, 'ana': 4109, 'quxtnlgd_tqnjyzsm': 4110, 'vtrwyeku_gisxlqvt': 4111, 'bvwepigr_ekmarvgd': 4112, 'rwiykpuc_ckrmjqlx': 4113, 'vkjdgtxb_pkinmjqs': 4114, 'importance.': 4115, 'recsynqt_byoezmla': 4116, 'agjzikpf_nhfrbxek': 4117, 'sazowuft_htjrunsz': 4118, 'znyijvpg_kjqhrwlv': 4119, 'ocgkpayl_tzadqijk': 4120, 'lzqbyner_jyncfahz': 4121, 'activity.': 4122, 'dpurliet_ujlmdfac': 4123, 'bioanvcz_zgfiahyo': 4124, 'htoqbljx_dkbatgus': 4125, 'gwkjrobm_wrsznjmx': 4126, 'technologist.': 4127, 'lqipwdeg_dkbmjnvl': 4128, 'successfully.': 4129, 'tovracdn_tjnvswrq': 4130, 'advisor': 4131, 'czenblfs_ochjndta': 4132, 'amylzuog_irtsuqey': 4133, 'make.': 4134, 'cvqnstgu_ofnimlwx': 4135, 'svnptdwu_zopxaqib': 4136, 'qmpyjfbn_zlyiwtch': 4137, 'xeakyiqt_knhjogel': 4138, 'nkryuvct_jqvcxdrt': 4139, 'general.': 4140, 'mnlvhtug_imvetgoa': 4141, 'blast': 4142, 'pnhlrfao_ivjxlyfz': 4143, 'eqwaiphc_qxwfeuth': 4144, 'fqhlvcxn_zdfymgjp': 4145, 'sync.': 4146, 'xpzsygkb_vbualmpr': 4147, 'xbfcitlh_ntulmcpq': 4148, 'hpakdzyj_lkrtvosz': 4149, 'ypcudwsf_phvatzje': 4150, 'bqdlegnp_lnphmsco': 4151, 'draft': 4152, 'pkzthgea_kgvsdmpj': 4153, 'cloud': 4154, 'receipt.': 4155, 'esaqztby_mhnbqiyc': 4156, 'dtnhwjve_tqdhvazx': 4157, 'mjsetabg_oiurnzaq': 4158, 'refresh.': 4159, 'dypabsjm_nuzvhjik': 4160, 'fhxsowau_nfybhaxg': 4161, 'lukibasy_bqufyozk': 4162, 'dbfrevtj_wbrpdxnj': 4163, 'ljztkmds_ltjkirwy': 4164, 'ymepzlno_eobardlm': 4165, 'muqdlobv_qflsdahg': 4166, 'trust': 4167, 'relationship': 4168, 'woxrljif_qymrszdk': 4169, 'hcyemunl_lnecsgpd': 4170, 'compatibility': 4171, 'tohxswej_pmnlxyrv': 4172, 'pwvtoemq_ugnxwfoe': 4173, 'ptyxefvk_fhazbrwn': 4174, 'development.': 4175, 'pwkrlqbc_zslqfmka': 4176, 'opzuciql_muedfkhz': 4177, 'iftldbmu_fujslwby': 4178, 'oewrjvcx_abjpdkcu': 4179, 'rudiment': 4180, 'weekend': 4181, 'weekday': 4182, 'pacvbetl_yptglhoe': 4183, 'khaibsvt_lkvfxzpj': 4184, 'limitation': 4185, 'htzauevc_nhxlvkta': 4186, 'registry': 4187, 'operate.': 4188, 'identification': 4189, 'pgeknaxy_usokqprd': 4190, 'ksxjcvze_ognyetrp': 4191, 'person.': 4192, 'vqefplhm_mfpjaleo': 4193, 'edrglpvu_ihpzqksy': 4194, 'wauhocsk_vxuikqaf': 4195, 'ecpkblrs_buzgjypk': 4196, 'ljodkepq_dsifumxl': 4197, 'doxiqkws_uvrzcqmf': 4198, 'pftsgqmc_zcqiwatg': 4199, 'fydosbih_lafdsumb': 4200, 'fkdazsmi_yecbrofv': 4201, 'west': 4202, 'coast': 4203, 'grab': 4204, 'sojwqapz_okihatrb': 4205, 'axdyfojg_nyjlxbsk': 4206, 'tmopbken_ibzougsd': 4207, 'ability': 4208, 'ovpuqfaj_pqruovit': 4209, 'sab': 4210, 'fmzdkyqv_dbrslnhe': 4211, 'giatndok_wlzxridu': 4212, 'omiwzbue_auvolfhp': 4213, 'esmvgkhb_crybuied': 4214, 'aqritplu_beuflorc': 4215, 'gqhfieys_pkwcdbrv': 4216, 'question.': 4217, 'zxvjsipd_jbzmgyvd': 4218, 'genuine': 4219, 'emjalxih_bcetgmhr': 4220, 'cgxhmrvu_dbwspjet': 4221, 'potential': 4222, 'cyxieuwk_rekwlqmu': 4223, 'qdczywsh_ofzvapwn': 4224, 'pqbnkgtc_yhcfqozs': 4225, 'uzchtpxo_ksvendorjir': 4226, 'vebizknu_qlknijvb': 4227, 'ixefmkyb_bkyfisxz': 4228, 'bdgklrnj_phwmkldy': 4229, 'jzfboqgc_zhmqwxgd': 4230, 'xqyjztnm_onfusvlz': 4231, 'spxjnwir_pjlcoqds': 4232, 'piewoyqx_bivcmwlh': 4233, 'regard.': 4234, 'pay': 4235, 'slip': 4236, 'sal': 4237, 'payroll.': 4238, 'mnakehrf_mvunqihf': 4239, 'rlmbxeso_ulmkxdfi': 4240, 'oslzvpgk_nhwsxgpb': 4241, 'frhqlxst_gedzxkry': 4242, 'another.': 4243, 'gwptzvxm_rhozsfty': 4244, 'amiodlfy_gmcoruwp': 4245, 'gvmqopuz_vbpsxdhf': 4246, 'rend': 4247, 'dhraxivp_enmfvuqb': 4248, 'udzkgbwl_bgpedtqc': 4249, 'attention.': 4250, 'mwjcsiug_fbwthoca': 4251, 'compliance.': 4252, 'metalworking': 4253, 'wkqjcfgy_vsknlfri': 4254, 'bsxvtpke_vbfcashd': 4255, 'courage': 4256, 'saerpwno_qsdfmakc': 4257, 'aqdjcuhn_lagfitkz': 4258, 'jclrangd_kjlnearz': 4259, 'zjuciaxv_przcfied': 4260, 'activate.': 4261, 'mtzjkhpi_sfcmyjzx': 4262, 'vmdwslkj_exvcknbp': 4263, 'khyzsgnv_aletvocx': 4264, 'answer': 4265, 'woaiypxu_dxslkbif': 4266, 'hie': 4267, 'schule': 4268, 'xbsckemt_durnfyxb': 4269, 'suyighpt_wifujdvq': 4270, 'mxifcasu_cxsembup': 4271, 'freeze.': 4272, 'nivqoxyt_ivrhjmnx': 4273, 'enterprise.': 4274, 'fjohugzb_fhagjskd': 4275, 'umkpayhc_adflvbxg': 4276, 'ybplwrez_lqcyehbf': 4277, 'yxvqdtmk_kbicqjrp': 4278, 'fro': 4279, 'yimwfntl_rkdwohas': 4280, 'vrxkdhib_sqtvbvkm': 4281, 'aqwdfvrb_oiajztbq': 4282, 'ibsywxpc_icxhsbfv': 4283, 'gxaudkip_pgkuwtlv': 4284, 'wqfpkcgh_vxtqeris': 4285, 'nxvbtfui_hjickwyd': 4286, 'syclwnxe_jhgdesun': 4287, 'qtgefsdk_bytvlnca': 4288, 'ihozauxs_ohdqmipz': 4289, 'mwebfhdz_csndrxgi': 4290, 'heuvlktj_ulzcsyvi': 4291, 'pizcefdg_wkyxbgda': 4292, 'xbgwfmvj_oemxazyl': 4293, 'vanteksj_astelnqw': 4294, 'infrastructure.': 4295, 'zhwktnia_dfhormwk': 4296, 'rjwbntef_nmuikjgo': 4297, 'vitpjxgm_zxiqkrns': 4298, 'qjeymnzs_wgpelvyn': 4299, 'bslwfqcv_xqaheoim': 4300, 'vcyktjxp_uxdojvrq': 4301, 'needful': 4302, 'store': 4303, 'tpflxnhz_bdjiosrp': 4304, 'pinovmqw_icafkqmw': 4305, 'tut': 4306, 'uprmwlgb_kirvecja': 4307, 'nwzhlktu_plktredg': 4308, 'jmxqhrfa_vawptbfl': 4309, 'rcivkdxo_hlyrieck': 4310, 'yzbjhmpw_vzrulkog': 4311, 'manger': 4312, 'vzrbocfl_wxtpoyez': 4313, 'sign.': 4314, 'isfadulo_etkyjabn': 4315, 'cqlehowf_aosqelnr': 4316, 'constant': 4317, 'ubkgydpw_pqljsube': 4318, 'xrqnyzhb_oblghuyf': 4319, 'unslcdbo_jfwqcira': 4320, 'keqvyfzw_qwbohdxg': 4321, 'private': 4322, 'hprdlbxf_nozjtgwi': 4323, 'fbwqocvh_olapczwf': 4324, 'vewdsifl_zjdmftkv': 4325, 'etlfrucw_ziewxqof': 4326, 'ebldwvth_qzsfkyuw': 4327, 'dont': 4328, 'portion.': 4329, 'tqnbkjgu_xyedbsnm': 4330, 'qhisflec_okxaytiv': 4331, 'xiaurwpz_hzusljmc': 4332, 'nzaghmdr_sgdlajvw': 4333, 'ethical': 4334, 'qfwijzbd_gmkiatjs': 4335, 'hire': 4336, 'eahkpnbm_uptiveok': 4337, 'wjsfbpuv_lcpdfihr': 4338, 'uplmtybe_pdmwyoil': 4339, 'pfmcnahv_ofzlusri': 4340, 'college': 4341, 'fort': 4342, 'dubpgacz_kjzhilng': 4343, 'jmxrabzy_dpyvjcxr': 4344, 'pyeothbl_agfxelwz': 4345, 'xernsfqa_uzvsnlbd': 4346, 'jmsaopew_dnuvpfci': 4347, 'explain': 4348, 'jartombc_ghnxkmsl': 4349}\n",
            "Vocab Size: 4350\n",
            "\n",
            "Split train and test data\n",
            "Training data size: 19200\n",
            "Test data size: 4800\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbmF7dMwnM2m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LSTM_Model2 = tf.keras.models.Sequential([\n",
        "              tf.keras.layers.Embedding(vocabulary_size, output_dim=100, input_length=maxlen),\n",
        "              tf.keras.layers.LSTM(64, return_sequences=True,dropout=0.2),\n",
        "              tf.keras.layers.BatchNormalization(),\n",
        "              tf.keras.layers.TimeDistributed(Dense(32, activation='relu')),\n",
        "              tf.keras.layers.Flatten(),\n",
        "              tf.keras.layers.Dense(24, activation='softmax')])\n",
        "\n",
        "optimiser = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
        "LSTM_Model2.compile(optimizer=optimiser,loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])\n",
        "LSTM_Model2.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jd-5FTwRnAFr",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUBUBWk3fMty",
        "colab_type": "code",
        "outputId": "f62817e2-6eac-4d85-8e4e-48f72101a46d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# checkpoint for validation accuracy\n",
        "LSTM_Model2.load_weights(\"LSTM_Model2_Weights.best.hdf5\")\n",
        "filepath=\"LSTM_Model2_Weights.best.hdf5\"\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True,mode='max')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "# Fit the model\n",
        "LSTM_Model2.fit(X_train, y_train, validation_split=0.2, epochs=100, batch_size=100,  shuffle=True, callbacks=callbacks_list, verbose=1)\n",
        "\n",
        "# Save Model and Weights locally\n",
        "LSTM_Model2.save(\"LSTM_Model2.h5\")\n",
        "print(\"LSTM_Model2 and weights to disk\")"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "151/154 [============================>.] - ETA: 0s - loss: 0.3277 - accuracy: 0.8729\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.87865, saving model to LSTM_Model2_Weights.best.hdf5\n",
            "154/154 [==============================] - 2s 14ms/step - loss: 0.3266 - accuracy: 0.8731 - val_loss: 0.3798 - val_accuracy: 0.8786\n",
            "Epoch 2/100\n",
            "152/154 [============================>.] - ETA: 0s - loss: 0.2302 - accuracy: 0.9013\n",
            "Epoch 00002: val_accuracy did not improve from 0.87865\n",
            "154/154 [==============================] - 2s 12ms/step - loss: 0.2302 - accuracy: 0.9012 - val_loss: 0.3643 - val_accuracy: 0.8755\n",
            "Epoch 3/100\n",
            "154/154 [==============================] - ETA: 0s - loss: 0.2205 - accuracy: 0.9046\n",
            "Epoch 00003: val_accuracy improved from 0.87865 to 0.88047, saving model to LSTM_Model2_Weights.best.hdf5\n",
            "154/154 [==============================] - 2s 12ms/step - loss: 0.2205 - accuracy: 0.9046 - val_loss: 0.3680 - val_accuracy: 0.8805\n",
            "Epoch 4/100\n",
            "151/154 [============================>.] - ETA: 0s - loss: 0.2192 - accuracy: 0.9053\n",
            "Epoch 00004: val_accuracy improved from 0.88047 to 0.88255, saving model to LSTM_Model2_Weights.best.hdf5\n",
            "154/154 [==============================] - 2s 12ms/step - loss: 0.2191 - accuracy: 0.9053 - val_loss: 0.3600 - val_accuracy: 0.8826\n",
            "Epoch 5/100\n",
            "154/154 [==============================] - ETA: 0s - loss: 0.2181 - accuracy: 0.9045\n",
            "Epoch 00005: val_accuracy improved from 0.88255 to 0.88490, saving model to LSTM_Model2_Weights.best.hdf5\n",
            "154/154 [==============================] - 2s 13ms/step - loss: 0.2181 - accuracy: 0.9045 - val_loss: 0.3591 - val_accuracy: 0.8849\n",
            "Epoch 6/100\n",
            "149/154 [============================>.] - ETA: 0s - loss: 0.2186 - accuracy: 0.9060\n",
            "Epoch 00006: val_accuracy did not improve from 0.88490\n",
            "154/154 [==============================] - 2s 11ms/step - loss: 0.2190 - accuracy: 0.9059 - val_loss: 0.3610 - val_accuracy: 0.8846\n",
            "Epoch 7/100\n",
            "154/154 [==============================] - ETA: 0s - loss: 0.2176 - accuracy: 0.9051\n",
            "Epoch 00007: val_accuracy did not improve from 0.88490\n",
            "154/154 [==============================] - 2s 12ms/step - loss: 0.2176 - accuracy: 0.9051 - val_loss: 0.3650 - val_accuracy: 0.8846\n",
            "Epoch 8/100\n",
            "154/154 [==============================] - ETA: 0s - loss: 0.2176 - accuracy: 0.9031\n",
            "Epoch 00008: val_accuracy improved from 0.88490 to 0.88568, saving model to LSTM_Model2_Weights.best.hdf5\n",
            "154/154 [==============================] - 2s 12ms/step - loss: 0.2176 - accuracy: 0.9031 - val_loss: 0.3624 - val_accuracy: 0.8857\n",
            "Epoch 9/100\n",
            "151/154 [============================>.] - ETA: 0s - loss: 0.2181 - accuracy: 0.9048\n",
            "Epoch 00009: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 11ms/step - loss: 0.2174 - accuracy: 0.9050 - val_loss: 0.3826 - val_accuracy: 0.8844\n",
            "Epoch 10/100\n",
            "153/154 [============================>.] - ETA: 0s - loss: 0.2169 - accuracy: 0.9063\n",
            "Epoch 00010: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 12ms/step - loss: 0.2168 - accuracy: 0.9063 - val_loss: 0.3780 - val_accuracy: 0.8836\n",
            "Epoch 11/100\n",
            "149/154 [============================>.] - ETA: 0s - loss: 0.2174 - accuracy: 0.9059\n",
            "Epoch 00011: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 12ms/step - loss: 0.2180 - accuracy: 0.9059 - val_loss: 0.3711 - val_accuracy: 0.8857\n",
            "Epoch 12/100\n",
            "151/154 [============================>.] - ETA: 0s - loss: 0.2177 - accuracy: 0.9046\n",
            "Epoch 00012: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 12ms/step - loss: 0.2177 - accuracy: 0.9043 - val_loss: 0.3759 - val_accuracy: 0.8846\n",
            "Epoch 13/100\n",
            "152/154 [============================>.] - ETA: 0s - loss: 0.2175 - accuracy: 0.9060\n",
            "Epoch 00013: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 12ms/step - loss: 0.2173 - accuracy: 0.9061 - val_loss: 0.3883 - val_accuracy: 0.8828\n",
            "Epoch 14/100\n",
            "149/154 [============================>.] - ETA: 0s - loss: 0.2179 - accuracy: 0.9052\n",
            "Epoch 00014: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 11ms/step - loss: 0.2181 - accuracy: 0.9054 - val_loss: 0.3749 - val_accuracy: 0.8846\n",
            "Epoch 15/100\n",
            "153/154 [============================>.] - ETA: 0s - loss: 0.2171 - accuracy: 0.9056\n",
            "Epoch 00015: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 12ms/step - loss: 0.2169 - accuracy: 0.9057 - val_loss: 0.3802 - val_accuracy: 0.8844\n",
            "Epoch 16/100\n",
            "153/154 [============================>.] - ETA: 0s - loss: 0.2176 - accuracy: 0.9059\n",
            "Epoch 00016: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 11ms/step - loss: 0.2173 - accuracy: 0.9061 - val_loss: 0.3866 - val_accuracy: 0.8797\n",
            "Epoch 17/100\n",
            "154/154 [==============================] - ETA: 0s - loss: 0.2177 - accuracy: 0.9055\n",
            "Epoch 00017: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 11ms/step - loss: 0.2177 - accuracy: 0.9055 - val_loss: 0.3814 - val_accuracy: 0.8849\n",
            "Epoch 18/100\n",
            "150/154 [============================>.] - ETA: 0s - loss: 0.2176 - accuracy: 0.9055\n",
            "Epoch 00018: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 12ms/step - loss: 0.2171 - accuracy: 0.9054 - val_loss: 0.3879 - val_accuracy: 0.8826\n",
            "Epoch 19/100\n",
            "154/154 [==============================] - ETA: 0s - loss: 0.2171 - accuracy: 0.9058\n",
            "Epoch 00019: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 12ms/step - loss: 0.2171 - accuracy: 0.9058 - val_loss: 0.3869 - val_accuracy: 0.8852\n",
            "Epoch 20/100\n",
            "153/154 [============================>.] - ETA: 0s - loss: 0.2175 - accuracy: 0.9051\n",
            "Epoch 00020: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 12ms/step - loss: 0.2175 - accuracy: 0.9051 - val_loss: 0.3886 - val_accuracy: 0.8831\n",
            "Epoch 21/100\n",
            "152/154 [============================>.] - ETA: 0s - loss: 0.2194 - accuracy: 0.9053\n",
            "Epoch 00021: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 12ms/step - loss: 0.2188 - accuracy: 0.9053 - val_loss: 0.4213 - val_accuracy: 0.8776\n",
            "Epoch 22/100\n",
            "152/154 [============================>.] - ETA: 0s - loss: 0.2233 - accuracy: 0.9047\n",
            "Epoch 00022: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 11ms/step - loss: 0.2238 - accuracy: 0.9045 - val_loss: 0.4159 - val_accuracy: 0.8810\n",
            "Epoch 23/100\n",
            "151/154 [============================>.] - ETA: 0s - loss: 0.2267 - accuracy: 0.9038\n",
            "Epoch 00023: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 12ms/step - loss: 0.2260 - accuracy: 0.9037 - val_loss: 0.3839 - val_accuracy: 0.8810\n",
            "Epoch 24/100\n",
            "151/154 [============================>.] - ETA: 0s - loss: 0.2187 - accuracy: 0.9053\n",
            "Epoch 00024: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 12ms/step - loss: 0.2191 - accuracy: 0.9049 - val_loss: 0.3968 - val_accuracy: 0.8802\n",
            "Epoch 25/100\n",
            "154/154 [==============================] - ETA: 0s - loss: 0.2173 - accuracy: 0.9070\n",
            "Epoch 00025: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 11ms/step - loss: 0.2173 - accuracy: 0.9070 - val_loss: 0.3992 - val_accuracy: 0.8839\n",
            "Epoch 26/100\n",
            "150/154 [============================>.] - ETA: 0s - loss: 0.2175 - accuracy: 0.9046\n",
            "Epoch 00026: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 11ms/step - loss: 0.2173 - accuracy: 0.9044 - val_loss: 0.3995 - val_accuracy: 0.8789\n",
            "Epoch 27/100\n",
            "151/154 [============================>.] - ETA: 0s - loss: 0.2165 - accuracy: 0.9043\n",
            "Epoch 00027: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 11ms/step - loss: 0.2172 - accuracy: 0.9041 - val_loss: 0.3975 - val_accuracy: 0.8839\n",
            "Epoch 28/100\n",
            "154/154 [==============================] - ETA: 0s - loss: 0.2173 - accuracy: 0.9070\n",
            "Epoch 00028: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 11ms/step - loss: 0.2173 - accuracy: 0.9070 - val_loss: 0.3972 - val_accuracy: 0.8802\n",
            "Epoch 29/100\n",
            "153/154 [============================>.] - ETA: 0s - loss: 0.2167 - accuracy: 0.9059\n",
            "Epoch 00029: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 12ms/step - loss: 0.2170 - accuracy: 0.9059 - val_loss: 0.4202 - val_accuracy: 0.8844\n",
            "Epoch 30/100\n",
            "152/154 [============================>.] - ETA: 0s - loss: 0.2172 - accuracy: 0.9053\n",
            "Epoch 00030: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 11ms/step - loss: 0.2174 - accuracy: 0.9053 - val_loss: 0.4044 - val_accuracy: 0.8794\n",
            "Epoch 31/100\n",
            "153/154 [============================>.] - ETA: 0s - loss: 0.2177 - accuracy: 0.9058\n",
            "Epoch 00031: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 12ms/step - loss: 0.2172 - accuracy: 0.9059 - val_loss: 0.4116 - val_accuracy: 0.8823\n",
            "Epoch 32/100\n",
            "150/154 [============================>.] - ETA: 0s - loss: 0.2176 - accuracy: 0.9047\n",
            "Epoch 00032: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 12ms/step - loss: 0.2166 - accuracy: 0.9049 - val_loss: 0.4083 - val_accuracy: 0.8833\n",
            "Epoch 33/100\n",
            "150/154 [============================>.] - ETA: 0s - loss: 0.2170 - accuracy: 0.9053\n",
            "Epoch 00033: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 12ms/step - loss: 0.2168 - accuracy: 0.9054 - val_loss: 0.4076 - val_accuracy: 0.8823\n",
            "Epoch 34/100\n",
            "150/154 [============================>.] - ETA: 0s - loss: 0.2164 - accuracy: 0.9070\n",
            "Epoch 00034: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 11ms/step - loss: 0.2168 - accuracy: 0.9066 - val_loss: 0.4097 - val_accuracy: 0.8802\n",
            "Epoch 35/100\n",
            "153/154 [============================>.] - ETA: 0s - loss: 0.2163 - accuracy: 0.9052\n",
            "Epoch 00035: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 11ms/step - loss: 0.2167 - accuracy: 0.9052 - val_loss: 0.4114 - val_accuracy: 0.8810\n",
            "Epoch 36/100\n",
            "153/154 [============================>.] - ETA: 0s - loss: 0.2168 - accuracy: 0.9062\n",
            "Epoch 00036: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 12ms/step - loss: 0.2170 - accuracy: 0.9061 - val_loss: 0.4051 - val_accuracy: 0.8846\n",
            "Epoch 37/100\n",
            "153/154 [============================>.] - ETA: 0s - loss: 0.2164 - accuracy: 0.9059\n",
            "Epoch 00037: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 12ms/step - loss: 0.2161 - accuracy: 0.9061 - val_loss: 0.4089 - val_accuracy: 0.8839\n",
            "Epoch 38/100\n",
            "149/154 [============================>.] - ETA: 0s - loss: 0.2177 - accuracy: 0.9058\n",
            "Epoch 00038: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 11ms/step - loss: 0.2165 - accuracy: 0.9063 - val_loss: 0.4035 - val_accuracy: 0.8797\n",
            "Epoch 39/100\n",
            "150/154 [============================>.] - ETA: 0s - loss: 0.2186 - accuracy: 0.9063\n",
            "Epoch 00039: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 12ms/step - loss: 0.2199 - accuracy: 0.9066 - val_loss: 0.4224 - val_accuracy: 0.8802\n",
            "Epoch 40/100\n",
            "152/154 [============================>.] - ETA: 0s - loss: 0.2216 - accuracy: 0.9044\n",
            "Epoch 00040: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 12ms/step - loss: 0.2221 - accuracy: 0.9043 - val_loss: 0.4196 - val_accuracy: 0.8852\n",
            "Epoch 41/100\n",
            "151/154 [============================>.] - ETA: 0s - loss: 0.2175 - accuracy: 0.9054\n",
            "Epoch 00041: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 12ms/step - loss: 0.2182 - accuracy: 0.9053 - val_loss: 0.4126 - val_accuracy: 0.8849\n",
            "Epoch 42/100\n",
            "151/154 [============================>.] - ETA: 0s - loss: 0.2187 - accuracy: 0.9062\n",
            "Epoch 00042: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 12ms/step - loss: 0.2191 - accuracy: 0.9061 - val_loss: 0.4325 - val_accuracy: 0.8807\n",
            "Epoch 43/100\n",
            "152/154 [============================>.] - ETA: 0s - loss: 0.2182 - accuracy: 0.9054\n",
            "Epoch 00043: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 11ms/step - loss: 0.2178 - accuracy: 0.9056 - val_loss: 0.4028 - val_accuracy: 0.8846\n",
            "Epoch 44/100\n",
            "153/154 [============================>.] - ETA: 0s - loss: 0.2182 - accuracy: 0.9050\n",
            "Epoch 00044: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 12ms/step - loss: 0.2175 - accuracy: 0.9052 - val_loss: 0.3985 - val_accuracy: 0.8857\n",
            "Epoch 45/100\n",
            "152/154 [============================>.] - ETA: 0s - loss: 0.2167 - accuracy: 0.9066\n",
            "Epoch 00045: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 11ms/step - loss: 0.2175 - accuracy: 0.9062 - val_loss: 0.4194 - val_accuracy: 0.8849\n",
            "Epoch 46/100\n",
            "153/154 [============================>.] - ETA: 0s - loss: 0.2165 - accuracy: 0.9067\n",
            "Epoch 00046: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 11ms/step - loss: 0.2167 - accuracy: 0.9068 - val_loss: 0.4311 - val_accuracy: 0.8823\n",
            "Epoch 47/100\n",
            "153/154 [============================>.] - ETA: 0s - loss: 0.2161 - accuracy: 0.9044\n",
            "Epoch 00047: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 11ms/step - loss: 0.2171 - accuracy: 0.9042 - val_loss: 0.4212 - val_accuracy: 0.8846\n",
            "Epoch 48/100\n",
            "154/154 [==============================] - ETA: 0s - loss: 0.2185 - accuracy: 0.9053\n",
            "Epoch 00048: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 11ms/step - loss: 0.2185 - accuracy: 0.9053 - val_loss: 0.3896 - val_accuracy: 0.8857\n",
            "Epoch 49/100\n",
            "150/154 [============================>.] - ETA: 0s - loss: 0.2183 - accuracy: 0.9050\n",
            "Epoch 00049: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 11ms/step - loss: 0.2182 - accuracy: 0.9052 - val_loss: 0.4114 - val_accuracy: 0.8857\n",
            "Epoch 50/100\n",
            "154/154 [==============================] - ETA: 0s - loss: 0.2167 - accuracy: 0.9062\n",
            "Epoch 00050: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 12ms/step - loss: 0.2167 - accuracy: 0.9062 - val_loss: 0.4117 - val_accuracy: 0.8846\n",
            "Epoch 51/100\n",
            "153/154 [============================>.] - ETA: 0s - loss: 0.2167 - accuracy: 0.9048\n",
            "Epoch 00051: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 11ms/step - loss: 0.2170 - accuracy: 0.9048 - val_loss: 0.4238 - val_accuracy: 0.8854\n",
            "Epoch 52/100\n",
            "154/154 [==============================] - ETA: 0s - loss: 0.2168 - accuracy: 0.9070\n",
            "Epoch 00052: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 12ms/step - loss: 0.2168 - accuracy: 0.9070 - val_loss: 0.4159 - val_accuracy: 0.8839\n",
            "Epoch 53/100\n",
            "150/154 [============================>.] - ETA: 0s - loss: 0.2158 - accuracy: 0.9067\n",
            "Epoch 00053: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 12ms/step - loss: 0.2165 - accuracy: 0.9062 - val_loss: 0.4202 - val_accuracy: 0.8841\n",
            "Epoch 54/100\n",
            "153/154 [============================>.] - ETA: 0s - loss: 0.2155 - accuracy: 0.9069\n",
            "Epoch 00054: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 12ms/step - loss: 0.2168 - accuracy: 0.9066 - val_loss: 0.4241 - val_accuracy: 0.8789\n",
            "Epoch 55/100\n",
            "151/154 [============================>.] - ETA: 0s - loss: 0.2191 - accuracy: 0.9048\n",
            "Epoch 00055: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 11ms/step - loss: 0.2188 - accuracy: 0.9048 - val_loss: 0.4198 - val_accuracy: 0.8841\n",
            "Epoch 56/100\n",
            "152/154 [============================>.] - ETA: 0s - loss: 0.2239 - accuracy: 0.9045\n",
            "Epoch 00056: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 11ms/step - loss: 0.2247 - accuracy: 0.9043 - val_loss: 0.4389 - val_accuracy: 0.8833\n",
            "Epoch 57/100\n",
            "150/154 [============================>.] - ETA: 0s - loss: 0.2175 - accuracy: 0.9053\n",
            "Epoch 00057: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 11ms/step - loss: 0.2197 - accuracy: 0.9047 - val_loss: 0.4451 - val_accuracy: 0.8828\n",
            "Epoch 58/100\n",
            "150/154 [============================>.] - ETA: 0s - loss: 0.2208 - accuracy: 0.9063\n",
            "Epoch 00058: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 12ms/step - loss: 0.2198 - accuracy: 0.9068 - val_loss: 0.4727 - val_accuracy: 0.8771\n",
            "Epoch 59/100\n",
            "154/154 [==============================] - ETA: 0s - loss: 0.2167 - accuracy: 0.9045\n",
            "Epoch 00059: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 11ms/step - loss: 0.2167 - accuracy: 0.9045 - val_loss: 0.4347 - val_accuracy: 0.8831\n",
            "Epoch 60/100\n",
            "153/154 [============================>.] - ETA: 0s - loss: 0.2168 - accuracy: 0.9055\n",
            "Epoch 00060: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 12ms/step - loss: 0.2170 - accuracy: 0.9054 - val_loss: 0.4605 - val_accuracy: 0.8802\n",
            "Epoch 61/100\n",
            "153/154 [============================>.] - ETA: 0s - loss: 0.2161 - accuracy: 0.9060\n",
            "Epoch 00061: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 11ms/step - loss: 0.2165 - accuracy: 0.9057 - val_loss: 0.4449 - val_accuracy: 0.8818\n",
            "Epoch 62/100\n",
            "152/154 [============================>.] - ETA: 0s - loss: 0.2165 - accuracy: 0.9063\n",
            "Epoch 00062: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 11ms/step - loss: 0.2159 - accuracy: 0.9064 - val_loss: 0.4466 - val_accuracy: 0.8818\n",
            "Epoch 63/100\n",
            "151/154 [============================>.] - ETA: 0s - loss: 0.2181 - accuracy: 0.9050\n",
            "Epoch 00063: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 12ms/step - loss: 0.2164 - accuracy: 0.9055 - val_loss: 0.4565 - val_accuracy: 0.8818\n",
            "Epoch 64/100\n",
            "150/154 [============================>.] - ETA: 0s - loss: 0.2157 - accuracy: 0.9075\n",
            "Epoch 00064: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 11ms/step - loss: 0.2167 - accuracy: 0.9069 - val_loss: 0.4502 - val_accuracy: 0.8818\n",
            "Epoch 65/100\n",
            "150/154 [============================>.] - ETA: 0s - loss: 0.2170 - accuracy: 0.9056\n",
            "Epoch 00065: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 12ms/step - loss: 0.2167 - accuracy: 0.9057 - val_loss: 0.4498 - val_accuracy: 0.8820\n",
            "Epoch 66/100\n",
            "153/154 [============================>.] - ETA: 0s - loss: 0.2158 - accuracy: 0.9059\n",
            "Epoch 00066: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 11ms/step - loss: 0.2161 - accuracy: 0.9059 - val_loss: 0.4605 - val_accuracy: 0.8792\n",
            "Epoch 67/100\n",
            "154/154 [==============================] - ETA: 0s - loss: 0.2163 - accuracy: 0.9057\n",
            "Epoch 00067: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 12ms/step - loss: 0.2163 - accuracy: 0.9057 - val_loss: 0.4611 - val_accuracy: 0.8815\n",
            "Epoch 68/100\n",
            "153/154 [============================>.] - ETA: 0s - loss: 0.2161 - accuracy: 0.9063\n",
            "Epoch 00068: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 12ms/step - loss: 0.2161 - accuracy: 0.9062 - val_loss: 0.4579 - val_accuracy: 0.8810\n",
            "Epoch 69/100\n",
            "150/154 [============================>.] - ETA: 0s - loss: 0.2164 - accuracy: 0.9053\n",
            "Epoch 00069: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 11ms/step - loss: 0.2167 - accuracy: 0.9052 - val_loss: 0.4577 - val_accuracy: 0.8805\n",
            "Epoch 70/100\n",
            "152/154 [============================>.] - ETA: 0s - loss: 0.2157 - accuracy: 0.9055\n",
            "Epoch 00070: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 12ms/step - loss: 0.2158 - accuracy: 0.9052 - val_loss: 0.4545 - val_accuracy: 0.8813\n",
            "Epoch 71/100\n",
            "150/154 [============================>.] - ETA: 0s - loss: 0.2172 - accuracy: 0.9066\n",
            "Epoch 00071: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 12ms/step - loss: 0.2162 - accuracy: 0.9071 - val_loss: 0.4482 - val_accuracy: 0.8828\n",
            "Epoch 72/100\n",
            "154/154 [==============================] - ETA: 0s - loss: 0.2159 - accuracy: 0.9068\n",
            "Epoch 00072: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 11ms/step - loss: 0.2159 - accuracy: 0.9068 - val_loss: 0.4544 - val_accuracy: 0.8836\n",
            "Epoch 73/100\n",
            "152/154 [============================>.] - ETA: 0s - loss: 0.2171 - accuracy: 0.9055\n",
            "Epoch 00073: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 12ms/step - loss: 0.2163 - accuracy: 0.9058 - val_loss: 0.4561 - val_accuracy: 0.8820\n",
            "Epoch 74/100\n",
            "150/154 [============================>.] - ETA: 0s - loss: 0.2173 - accuracy: 0.9065\n",
            "Epoch 00074: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 12ms/step - loss: 0.2174 - accuracy: 0.9062 - val_loss: 0.4755 - val_accuracy: 0.8797\n",
            "Epoch 75/100\n",
            "153/154 [============================>.] - ETA: 0s - loss: 0.2176 - accuracy: 0.9065\n",
            "Epoch 00075: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 12ms/step - loss: 0.2193 - accuracy: 0.9061 - val_loss: 0.4705 - val_accuracy: 0.8797\n",
            "Epoch 76/100\n",
            "153/154 [============================>.] - ETA: 0s - loss: 0.2176 - accuracy: 0.9061\n",
            "Epoch 00076: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 12ms/step - loss: 0.2172 - accuracy: 0.9062 - val_loss: 0.5459 - val_accuracy: 0.8753\n",
            "Epoch 77/100\n",
            "150/154 [============================>.] - ETA: 0s - loss: 0.2170 - accuracy: 0.9061\n",
            "Epoch 00077: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 11ms/step - loss: 0.2177 - accuracy: 0.9061 - val_loss: 0.4956 - val_accuracy: 0.8799\n",
            "Epoch 78/100\n",
            "153/154 [============================>.] - ETA: 0s - loss: 0.2160 - accuracy: 0.9057\n",
            "Epoch 00078: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 11ms/step - loss: 0.2161 - accuracy: 0.9057 - val_loss: 0.4836 - val_accuracy: 0.8813\n",
            "Epoch 79/100\n",
            "150/154 [============================>.] - ETA: 0s - loss: 0.2169 - accuracy: 0.9071\n",
            "Epoch 00079: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 11ms/step - loss: 0.2164 - accuracy: 0.9071 - val_loss: 0.4885 - val_accuracy: 0.8807\n",
            "Epoch 80/100\n",
            "153/154 [============================>.] - ETA: 0s - loss: 0.2164 - accuracy: 0.9075\n",
            "Epoch 00080: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 12ms/step - loss: 0.2153 - accuracy: 0.9078 - val_loss: 0.5034 - val_accuracy: 0.8760\n",
            "Epoch 81/100\n",
            "150/154 [============================>.] - ETA: 0s - loss: 0.2158 - accuracy: 0.9059\n",
            "Epoch 00081: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 12ms/step - loss: 0.2159 - accuracy: 0.9056 - val_loss: 0.4952 - val_accuracy: 0.8792\n",
            "Epoch 82/100\n",
            "152/154 [============================>.] - ETA: 0s - loss: 0.2158 - accuracy: 0.9070\n",
            "Epoch 00082: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 11ms/step - loss: 0.2165 - accuracy: 0.9070 - val_loss: 0.5018 - val_accuracy: 0.8799\n",
            "Epoch 83/100\n",
            "154/154 [==============================] - ETA: 0s - loss: 0.2165 - accuracy: 0.9062\n",
            "Epoch 00083: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 12ms/step - loss: 0.2165 - accuracy: 0.9062 - val_loss: 0.4892 - val_accuracy: 0.8805\n",
            "Epoch 84/100\n",
            "152/154 [============================>.] - ETA: 0s - loss: 0.2163 - accuracy: 0.9072\n",
            "Epoch 00084: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 12ms/step - loss: 0.2166 - accuracy: 0.9070 - val_loss: 0.5133 - val_accuracy: 0.8792\n",
            "Epoch 85/100\n",
            "154/154 [==============================] - ETA: 0s - loss: 0.2158 - accuracy: 0.9066\n",
            "Epoch 00085: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 12ms/step - loss: 0.2158 - accuracy: 0.9066 - val_loss: 0.5165 - val_accuracy: 0.8802\n",
            "Epoch 86/100\n",
            "151/154 [============================>.] - ETA: 0s - loss: 0.2165 - accuracy: 0.9065\n",
            "Epoch 00086: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 12ms/step - loss: 0.2167 - accuracy: 0.9065 - val_loss: 0.5096 - val_accuracy: 0.8792\n",
            "Epoch 87/100\n",
            "150/154 [============================>.] - ETA: 0s - loss: 0.2185 - accuracy: 0.9051\n",
            "Epoch 00087: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 12ms/step - loss: 0.2176 - accuracy: 0.9059 - val_loss: 0.4848 - val_accuracy: 0.8818\n",
            "Epoch 88/100\n",
            "154/154 [==============================] - ETA: 0s - loss: 0.2158 - accuracy: 0.9051\n",
            "Epoch 00088: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 12ms/step - loss: 0.2158 - accuracy: 0.9051 - val_loss: 0.5018 - val_accuracy: 0.8786\n",
            "Epoch 89/100\n",
            "152/154 [============================>.] - ETA: 0s - loss: 0.2165 - accuracy: 0.9065\n",
            "Epoch 00089: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 11ms/step - loss: 0.2161 - accuracy: 0.9066 - val_loss: 0.5178 - val_accuracy: 0.8799\n",
            "Epoch 90/100\n",
            "153/154 [============================>.] - ETA: 0s - loss: 0.2168 - accuracy: 0.9052\n",
            "Epoch 00090: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 11ms/step - loss: 0.2162 - accuracy: 0.9054 - val_loss: 0.5062 - val_accuracy: 0.8797\n",
            "Epoch 91/100\n",
            "153/154 [============================>.] - ETA: 0s - loss: 0.2171 - accuracy: 0.9049\n",
            "Epoch 00091: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 12ms/step - loss: 0.2168 - accuracy: 0.9051 - val_loss: 0.4952 - val_accuracy: 0.8776\n",
            "Epoch 92/100\n",
            "151/154 [============================>.] - ETA: 0s - loss: 0.2172 - accuracy: 0.9066\n",
            "Epoch 00092: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 12ms/step - loss: 0.2165 - accuracy: 0.9070 - val_loss: 0.4981 - val_accuracy: 0.8815\n",
            "Epoch 93/100\n",
            "152/154 [============================>.] - ETA: 0s - loss: 0.2224 - accuracy: 0.9052\n",
            "Epoch 00093: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 12ms/step - loss: 0.2227 - accuracy: 0.9051 - val_loss: 0.5071 - val_accuracy: 0.8789\n",
            "Epoch 94/100\n",
            "154/154 [==============================] - ETA: 0s - loss: 0.2271 - accuracy: 0.9040\n",
            "Epoch 00094: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 12ms/step - loss: 0.2271 - accuracy: 0.9040 - val_loss: 0.5189 - val_accuracy: 0.8799\n",
            "Epoch 95/100\n",
            "150/154 [============================>.] - ETA: 0s - loss: 0.2164 - accuracy: 0.9067\n",
            "Epoch 00095: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 11ms/step - loss: 0.2169 - accuracy: 0.9064 - val_loss: 0.5033 - val_accuracy: 0.8794\n",
            "Epoch 96/100\n",
            "151/154 [============================>.] - ETA: 0s - loss: 0.2144 - accuracy: 0.9058\n",
            "Epoch 00096: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 12ms/step - loss: 0.2166 - accuracy: 0.9049 - val_loss: 0.5141 - val_accuracy: 0.8799\n",
            "Epoch 97/100\n",
            "152/154 [============================>.] - ETA: 0s - loss: 0.2165 - accuracy: 0.9059\n",
            "Epoch 00097: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 12ms/step - loss: 0.2163 - accuracy: 0.9057 - val_loss: 0.5074 - val_accuracy: 0.8802\n",
            "Epoch 98/100\n",
            "150/154 [============================>.] - ETA: 0s - loss: 0.2150 - accuracy: 0.9073\n",
            "Epoch 00098: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 13ms/step - loss: 0.2163 - accuracy: 0.9068 - val_loss: 0.5061 - val_accuracy: 0.8802\n",
            "Epoch 99/100\n",
            "154/154 [==============================] - ETA: 0s - loss: 0.2163 - accuracy: 0.9061\n",
            "Epoch 00099: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 12ms/step - loss: 0.2163 - accuracy: 0.9061 - val_loss: 0.4970 - val_accuracy: 0.8813\n",
            "Epoch 100/100\n",
            "151/154 [============================>.] - ETA: 0s - loss: 0.2159 - accuracy: 0.9064\n",
            "Epoch 00100: val_accuracy did not improve from 0.88568\n",
            "154/154 [==============================] - 2s 12ms/step - loss: 0.2156 - accuracy: 0.9064 - val_loss: 0.5024 - val_accuracy: 0.8776\n",
            "LSTM_Model2 and weights to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tqx_qKgWCwds",
        "colab_type": "code",
        "outputId": "cde36cfd-4fac-487c-c463-f3d17479273c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# evaluate the model\n",
        "scores = LSTM_Model2 .evaluate(X_test, y_test, batch_size=64, verbose=1)\n",
        "test_accuracy = round(scores[1],2)\n",
        "print(\"Test %s received:%0.2f\" % (LSTM_Model2.metrics_names[1],test_accuracy))\n",
        "\n",
        "loc = result_df[result_df['Model']=='LSTM'].index\n",
        "result_df['Test_Accuracy'][loc] = test_accuracy\n",
        "\n",
        "# Predicting Ticket Category/Group\n",
        "y_pred = LSTM_Model2 .predict(X,batch_size=64,verbose=0)\n",
        "df_v2['Predicted_Group'] = y_pred"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "75/75 [==============================] - 0s 3ms/step - loss: 0.4910 - accuracy: 0.8808\n",
            "Test accuracy received:0.88\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aueWMw6mPdXp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "outputId": "c3a43398-a508-40cb-deef-b66ee50c4642"
      },
      "source": [
        "y_predicted = np.argmax(y_pred, axis=1)\n",
        "group_cm = confusion_matrix(y, y_predicted) \n",
        "df_cm = pd.DataFrame(group_cm, range(24), range(24)) \n",
        "cm_report = classification_report(y, y_predicted) \n",
        "print(cm_report)"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.85      0.91      1000\n",
            "           1       0.99      0.84      0.91      1000\n",
            "           2       0.96      0.94      0.95      1000\n",
            "           3       0.99      0.97      0.98      1000\n",
            "           4       0.99      0.97      0.98      1000\n",
            "           5       0.99      1.00      1.00      1000\n",
            "           6       1.00      1.00      1.00      1000\n",
            "           7       1.00      0.95      0.97      1000\n",
            "           8       0.98      0.99      0.99      1000\n",
            "           9       0.97      0.98      0.97      1000\n",
            "          10       0.99      1.00      1.00      1000\n",
            "          11       0.99      1.00      1.00      1000\n",
            "          12       0.99      1.00      1.00      1000\n",
            "          13       0.99      0.98      0.98      1000\n",
            "          14       0.97      0.98      0.98      1000\n",
            "          15       1.00      1.00      1.00      1000\n",
            "          16       0.99      1.00      1.00      1000\n",
            "          17       1.00      0.99      0.99      1000\n",
            "          18       0.98      1.00      0.99      1000\n",
            "          19       0.32      0.86      0.47      1000\n",
            "          20       1.00      0.36      0.53      1000\n",
            "          21       0.99      1.00      1.00      1000\n",
            "          22       0.98      0.45      0.62      1000\n",
            "          23       0.48      0.40      0.44      1000\n",
            "\n",
            "    accuracy                           0.90     24000\n",
            "   macro avg       0.94      0.90      0.90     24000\n",
            "weighted avg       0.94      0.90      0.90     24000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vq3n9vd7_fS4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "2fbe9842-ad37-41a1-99c2-98a98a598a1e"
      },
      "source": [
        "print(\"\\n\" + \"*\"*65 + \"\\n\")\n",
        "print(\"-------------------------  MODELS RESULT  ----------------------\")\n",
        "print(result_df)\n",
        "print(\"\\n\" + \"*\"*65 + \"\\n\")\n",
        "\n",
        "# Model Comparison - For Training Accuracy\n",
        "plt.figure(1)\n",
        "plt.subplots(figsize=(15,6))\n",
        "sns.barplot(x=\"Model\", y=\"Test_Accuracy\",data=result_df,palette='cool',edgecolor=sns.color_palette('dark',7))\n",
        "plt.xticks(rotation=45)\n",
        "plt.title('Model Test Accuracy Comparison', fontsize=20)\n",
        "plt.show()\n",
        "# plt.xlabel(result_df[\"Model\"], fontsize=18)\n"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "*****************************************************************\n",
            "\n",
            "-------------------------  MODELS RESULT  ----------------------\n",
            "               Model Test_Accuracy\n",
            "0                SVM           0.6\n",
            "1   Bagging_Ensemble           0.6\n",
            "2  Boosting_Ensemble           0.6\n",
            "3               LSTM          0.88\n",
            "\n",
            "*****************************************************************\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZcX-w9JNWDy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}